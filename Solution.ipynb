{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04de22e8",
   "metadata": {},
   "source": [
    "## Исследование таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f67ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    flag\n",
       "id      \n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импорт данных\n",
    "import pandas as pd\n",
    "train_target = pd.read_csv(\"train_target.csv\", index_col=\"id\")\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0476b83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2893558\n",
       "1     106442\n",
       "Name: flag, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подсчет кол-ва уникальных значений\n",
    "train_target[\"flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43ae2b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка на пустые значения\n",
    "train_target[\"flag\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ad5ee",
   "metadata": {},
   "source": [
    "## Эксперименты с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4fd3b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Импорт данных\n",
    "df = pd.read_parquet(\"train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "24a59b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_paym_21</th>\n",
       "      <th>enc_paym_22</th>\n",
       "      <th>enc_paym_23</th>\n",
       "      <th>enc_paym_24</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>enc_loans_credit_status</th>\n",
       "      <th>enc_loans_credit_type</th>\n",
       "      <th>enc_loans_account_cur</th>\n",
       "      <th>pclose_flag</th>\n",
       "      <th>fclose_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  pre_fterm  \\\n",
       "0   0   1                18                    9          2          3   \n",
       "1   0   2                18                    9         14         14   \n",
       "2   0   3                18                    9          4          8   \n",
       "3   0   4                 4                    1          9         12   \n",
       "4   0   5                 5                   12         15          2   \n",
       "\n",
       "   pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "0               16               10                      11   \n",
       "1               12               12                       0   \n",
       "2                1               11                      11   \n",
       "3               16                7                      12   \n",
       "4               11               12                      10   \n",
       "\n",
       "   pre_loans_next_pay_summ  ...  enc_paym_21  enc_paym_22  enc_paym_23  \\\n",
       "0                        3  ...            3            3            3   \n",
       "1                        3  ...            0            0            0   \n",
       "2                        0  ...            0            0            0   \n",
       "3                        2  ...            3            3            3   \n",
       "4                        2  ...            3            3            3   \n",
       "\n",
       "   enc_paym_24  enc_loans_account_holder_type  enc_loans_credit_status  \\\n",
       "0            4                              1                        3   \n",
       "1            4                              1                        3   \n",
       "2            4                              1                        2   \n",
       "3            4                              1                        3   \n",
       "4            4                              1                        3   \n",
       "\n",
       "   enc_loans_credit_type  enc_loans_account_cur  pclose_flag  fclose_flag  \n",
       "0                      4                      1            0            0  \n",
       "1                      4                      1            0            0  \n",
       "2                      3                      1            1            1  \n",
       "3                      1                      1            0            0  \n",
       "4                      4                      1            0            0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aa306803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                               0\n",
       "rn                               0\n",
       "pre_since_opened                 0\n",
       "pre_since_confirmed              0\n",
       "pre_pterm                        0\n",
       "pre_fterm                        0\n",
       "pre_till_pclose                  0\n",
       "pre_till_fclose                  0\n",
       "pre_loans_credit_limit           0\n",
       "pre_loans_next_pay_summ          0\n",
       "pre_loans_outstanding            0\n",
       "pre_loans_total_overdue          0\n",
       "pre_loans_max_overdue_sum        0\n",
       "pre_loans_credit_cost_rate       0\n",
       "pre_loans5                       0\n",
       "pre_loans530                     0\n",
       "pre_loans3060                    0\n",
       "pre_loans6090                    0\n",
       "pre_loans90                      0\n",
       "is_zero_loans5                   0\n",
       "is_zero_loans530                 0\n",
       "is_zero_loans3060                0\n",
       "is_zero_loans6090                0\n",
       "is_zero_loans90                  0\n",
       "pre_util                         0\n",
       "pre_over2limit                   0\n",
       "pre_maxover2limit                0\n",
       "is_zero_util                     0\n",
       "is_zero_over2limit               0\n",
       "is_zero_maxover2limit            0\n",
       "enc_paym_0                       0\n",
       "enc_paym_1                       0\n",
       "enc_paym_2                       0\n",
       "enc_paym_3                       0\n",
       "enc_paym_4                       0\n",
       "enc_paym_5                       0\n",
       "enc_paym_6                       0\n",
       "enc_paym_7                       0\n",
       "enc_paym_8                       0\n",
       "enc_paym_9                       0\n",
       "enc_paym_10                      0\n",
       "enc_paym_11                      0\n",
       "enc_paym_12                      0\n",
       "enc_paym_13                      0\n",
       "enc_paym_14                      0\n",
       "enc_paym_15                      0\n",
       "enc_paym_16                      0\n",
       "enc_paym_17                      0\n",
       "enc_paym_18                      0\n",
       "enc_paym_19                      0\n",
       "enc_paym_20                      0\n",
       "enc_paym_21                      0\n",
       "enc_paym_22                      0\n",
       "enc_paym_23                      0\n",
       "enc_paym_24                      0\n",
       "enc_loans_account_holder_type    0\n",
       "enc_loans_credit_status          0\n",
       "enc_loans_credit_type            0\n",
       "enc_loans_account_cur            0\n",
       "pclose_flag                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка на пустые значения\n",
    "df.iloc[:, :60].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "745b9846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка на дубликаты\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b542a",
   "metadata": {},
   "source": [
    "### Эксперимент 1\n",
    "Здесь мы опираемся на здравый смысл и преобразуем признаки, исходя из собственных соображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3794d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Эти фичи представляют число просрочек в разных интервалах. \n",
    "#Вместо использования отдельных признаков, можно объединить их в один признак, который представляет общее количество просрочек.\n",
    "df[\"total_overdue_count\"] = df[\"pre_loans5\"] + df[\"pre_loans530\"] + df[\"pre_loans3060\"] + df[\"pre_loans6090\"] + df[\"pre_loans90\"]\n",
    "df.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee425b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Можно объединить их в один признак, который указывает, есть ли просрочки в любом из интервалов.\n",
    "df[\"has_overdue_flag\"] = 1 - (df[\"is_zero_loans5\"] & df[\"is_zero_loans530\"] & df[\"is_zero_loans3060\"] & df[\"is_zero_loans6090\"] & df[\"is_zero_loans90\"])\n",
    "df.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b8884695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Можно объединить в один признак, который указывает на отсутствие любой задолженности.\n",
    "df[\"has_no_debt_flag\"] = df[\"is_zero_util\"] & df[\"is_zero_over2limit\"] & df[\"is_zero_maxover2limit\"]\n",
    "df.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "12cd3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Можно создать новые признаки, которые отражают разницу между плановыми и фактическими сроками.\n",
    "df[\"term_difference\"] = df[\"pre_fterm\"] - df[\"pre_pterm\"]\n",
    "df[\"close_difference\"] = df[\"pre_till_fclose\"] - df[\"pre_till_pclose\"]\n",
    "df.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e12fd758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'rn', 'pre_since_opened', 'pre_since_confirmed',\n",
       "       'pre_loans_credit_limit', 'pre_loans_next_pay_summ',\n",
       "       'pre_loans_outstanding', 'pre_loans_total_overdue',\n",
       "       'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_util',\n",
       "       'pre_over2limit', 'pre_maxover2limit', 'enc_paym_0', 'enc_paym_1',\n",
       "       'enc_paym_2', 'enc_paym_3', 'enc_paym_4', 'enc_paym_5', 'enc_paym_6',\n",
       "       'enc_paym_7', 'enc_paym_8', 'enc_paym_9', 'enc_paym_10', 'enc_paym_11',\n",
       "       'enc_paym_12', 'enc_paym_13', 'enc_paym_14', 'enc_paym_15',\n",
       "       'enc_paym_16', 'enc_paym_17', 'enc_paym_18', 'enc_paym_19',\n",
       "       'enc_paym_20', 'enc_paym_21', 'enc_paym_22', 'enc_paym_23',\n",
       "       'enc_paym_24', 'enc_loans_account_holder_type',\n",
       "       'enc_loans_credit_status', 'enc_loans_credit_type',\n",
       "       'enc_loans_account_cur', 'pclose_flag', 'fclose_flag',\n",
       "       'total_overdue_count', 'has_overdue_flag', 'has_no_debt_flag',\n",
       "       'term_difference', 'close_difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ca097d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'enc_paym_11', 'enc_paym_20', 'enc_paym_24' имеют диапазон от 1 до 4, остальные от 0 до 3, \n",
    "# поэтому для удобства подсчёта перевожу их в один диапазон\n",
    "value_mapping = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3\n",
    "}\n",
    "\n",
    "columns_to_transform = ['enc_paym_11', 'enc_paym_20', 'enc_paym_24']\n",
    "\n",
    "for column in columns_to_transform:\n",
    "    df[column] = df[column].replace(value_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a2adc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_paym_columns = [f'enc_paym_{i}' for i in range(25)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b64b29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчитывают кол-во статусов во всех enc_paym_N\n",
    "import numpy as np\n",
    "df[f'status_0'] = np.sum(df[enc_paym_columns].values == 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0a83eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'status_1'] = np.sum(df[enc_paym_columns].values == 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a23d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'status_2'] = np.sum(df[enc_paym_columns].values == 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bf719991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'status_3'] = np.sum(df[enc_paym_columns].values == 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b08d3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(enc_paym_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7a22da63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>pre_loans_credit_cost_rate</th>\n",
       "      <th>pre_util</th>\n",
       "      <th>pre_over2limit</th>\n",
       "      <th>pre_maxover2limit</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>...</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>total_overdue_count</th>\n",
       "      <th>has_overdue_flag</th>\n",
       "      <th>has_no_debt_flag</th>\n",
       "      <th>term_difference</th>\n",
       "      <th>close_difference</th>\n",
       "      <th>status_0</th>\n",
       "      <th>status_1</th>\n",
       "      <th>status_2</th>\n",
       "      <th>status_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rn  pre_since_opened  pre_since_confirmed  pre_loans_next_pay_summ  \\\n",
       "0   0   1                18                    9                        3   \n",
       "1   0   2                18                    9                        3   \n",
       "2   0   3                18                    9                        0   \n",
       "3   0   4                 4                    1                        2   \n",
       "4   0   5                 5                   12                        2   \n",
       "\n",
       "   pre_loans_credit_cost_rate  pre_util  pre_over2limit  pre_maxover2limit  \\\n",
       "0                          11        16               2                 17   \n",
       "1                          11        16               2                 17   \n",
       "2                           8        15               2                 17   \n",
       "3                           4        16               2                 17   \n",
       "4                           4        16               2                 17   \n",
       "\n",
       "   enc_loans_account_holder_type  ...  fclose_flag  total_overdue_count  \\\n",
       "0                              1  ...            0                   39   \n",
       "1                              1  ...            0                   39   \n",
       "2                              1  ...            1                   39   \n",
       "3                              1  ...            0                   39   \n",
       "4                              1  ...            0                   39   \n",
       "\n",
       "   has_overdue_flag  has_no_debt_flag  term_difference  close_difference  \\\n",
       "0                 0                 1                1                -6   \n",
       "1                 0                 1                0                 0   \n",
       "2                 0                 0                4                10   \n",
       "3                 1                 1                3                -9   \n",
       "4                 0                 1              -13                 1   \n",
       "\n",
       "   status_0  status_1  status_2  status_3  \n",
       "0         2         0         0        23  \n",
       "1        24         0         0         1  \n",
       "2        24         0         0         1  \n",
       "3        11         1         0        13  \n",
       "4         7         0         0        18  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "572cda80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'rn', 'pre_since_opened', 'pre_since_confirmed',\n",
       "       'pre_loans_next_pay_summ', 'pre_loans_credit_cost_rate', 'pre_util',\n",
       "       'pre_over2limit', 'pre_maxover2limit', 'enc_loans_account_holder_type',\n",
       "       'enc_loans_credit_status', 'enc_loans_credit_type',\n",
       "       'enc_loans_account_cur', 'pclose_flag', 'fclose_flag',\n",
       "       'total_overdue_count', 'has_overdue_flag', 'has_no_debt_flag',\n",
       "       'term_difference', 'close_difference', 'status_0', 'status_1',\n",
       "       'status_2', 'status_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7c402468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяю как аггрегировать\n",
    "aggregations = {\n",
    "    'rn': 'max', \n",
    "    'pre_since_opened': 'mean',\n",
    "    'pre_since_confirmed': 'median', \n",
    "    'pre_loans_next_pay_summ': 'median',\n",
    "    'pre_loans_credit_cost_rate': 'median',\n",
    "    'pre_util': 'median',\n",
    "    'pre_over2limit': 'median',\n",
    "    'pre_maxover2limit': 'median',\n",
    "    'enc_loans_account_holder_type': 'median',\n",
    "    'enc_loans_credit_status': 'median',\n",
    "    'enc_loans_credit_type': 'median',\n",
    "    'enc_loans_account_cur': 'median',\n",
    "    'pclose_flag': 'median',\n",
    "    'fclose_flag': 'median',\n",
    "    'total_overdue_count': 'median',\n",
    "    'has_overdue_flag': 'mean',\n",
    "    'has_no_debt_flag': 'mean',\n",
    "    'term_difference': 'mean',\n",
    "    'close_difference': 'mean',\n",
    "    'status_0': 'median',\n",
    "    'status_1': 'median',\n",
    "    'status_2': 'median',\n",
    "    'status_3': 'median'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "35a19075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группирую с аггрегацией\n",
    "grouped_df = df.groupby('id').agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "98fbebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чекпоинт данных\n",
    "grouped_df.to_csv(\"grouped_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ba871ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>pre_loans_credit_cost_rate</th>\n",
       "      <th>pre_util</th>\n",
       "      <th>pre_over2limit</th>\n",
       "      <th>pre_maxover2limit</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>...</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>total_overdue_count</th>\n",
       "      <th>has_overdue_flag</th>\n",
       "      <th>has_no_debt_flag</th>\n",
       "      <th>term_difference</th>\n",
       "      <th>close_difference</th>\n",
       "      <th>status_0</th>\n",
       "      <th>status_1</th>\n",
       "      <th>status_2</th>\n",
       "      <th>status_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>-3.071429</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999995</td>\n",
       "      <td>11</td>\n",
       "      <td>8.818182</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999996</td>\n",
       "      <td>13</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999997</td>\n",
       "      <td>10</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999998</td>\n",
       "      <td>5</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2999999</td>\n",
       "      <td>12</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  rn  pre_since_opened  pre_since_confirmed  \\\n",
       "0              0  10          8.100000                  9.0   \n",
       "1              1  14         11.428571                  7.0   \n",
       "2              2   3          8.333333                  9.0   \n",
       "3              3  15          7.000000                  9.0   \n",
       "4              4   1         12.000000                  9.0   \n",
       "...          ...  ..               ...                  ...   \n",
       "2999995  2999995  11          8.818182                  9.0   \n",
       "2999996  2999996  13          8.000000                 11.0   \n",
       "2999997  2999997  10          8.100000                  7.0   \n",
       "2999998  2999998   5         11.600000                  9.0   \n",
       "2999999  2999999  12          6.416667                  8.5   \n",
       "\n",
       "         pre_loans_next_pay_summ  pre_loans_credit_cost_rate  pre_util  \\\n",
       "0                            3.0                         9.5      16.0   \n",
       "1                            2.0                         4.0      16.0   \n",
       "2                            1.0                         4.0       6.0   \n",
       "3                            2.0                         4.0      16.0   \n",
       "4                            1.0                         0.0      16.0   \n",
       "...                          ...                         ...       ...   \n",
       "2999995                      2.0                         4.0      16.0   \n",
       "2999996                      2.0                         2.0      16.0   \n",
       "2999997                      2.0                         5.0      16.0   \n",
       "2999998                      2.0                         4.0       9.0   \n",
       "2999999                      2.0                         2.5      16.0   \n",
       "\n",
       "         pre_over2limit  pre_maxover2limit  enc_loans_account_holder_type  \\\n",
       "0                   2.0               17.0                            1.0   \n",
       "1                   2.0               17.0                            1.0   \n",
       "2                   2.0               17.0                            1.0   \n",
       "3                   2.0               17.0                            1.0   \n",
       "4                   2.0               17.0                            1.0   \n",
       "...                 ...                ...                            ...   \n",
       "2999995             2.0               17.0                            1.0   \n",
       "2999996             2.0               17.0                            1.0   \n",
       "2999997             2.0               17.0                            1.0   \n",
       "2999998             2.0               17.0                            1.0   \n",
       "2999999             2.0               17.0                            1.0   \n",
       "\n",
       "         ...  fclose_flag  total_overdue_count  has_overdue_flag  \\\n",
       "0        ...          0.0                 39.0          0.100000   \n",
       "1        ...          0.0                 39.0          0.571429   \n",
       "2        ...          1.0                 39.0          0.333333   \n",
       "3        ...          0.0                 39.0          0.000000   \n",
       "4        ...          1.0                 39.0          0.000000   \n",
       "...      ...          ...                  ...               ...   \n",
       "2999995  ...          0.0                 39.0          0.727273   \n",
       "2999996  ...          0.0                 39.0          0.076923   \n",
       "2999997  ...          0.0                 39.0          0.400000   \n",
       "2999998  ...          0.0                 39.0          0.200000   \n",
       "2999999  ...          0.0                 39.0          0.416667   \n",
       "\n",
       "         has_no_debt_flag  term_difference  close_difference  status_0  \\\n",
       "0                0.600000         0.400000         -0.700000       9.5   \n",
       "1                0.714286         1.285714         -3.071429       8.5   \n",
       "2                0.333333        -1.000000          4.000000      10.0   \n",
       "3                0.533333         0.200000          2.933333      14.0   \n",
       "4                1.000000         4.000000         10.000000       0.0   \n",
       "...                   ...              ...               ...       ...   \n",
       "2999995          0.545455         0.000000          0.000000      13.0   \n",
       "2999996          0.692308        -0.538462          0.538462      12.0   \n",
       "2999997          0.500000        -0.700000          0.900000      10.0   \n",
       "2999998          0.200000         1.600000          1.800000       4.0   \n",
       "2999999          0.583333         1.833333          0.500000      14.5   \n",
       "\n",
       "         status_1  status_2  status_3  \n",
       "0             0.0       0.0      15.0  \n",
       "1             0.0       0.0      15.5  \n",
       "2             0.0       0.0      15.0  \n",
       "3             0.0       0.0      11.0  \n",
       "4             0.0       0.0      25.0  \n",
       "...           ...       ...       ...  \n",
       "2999995       2.0       0.0      12.0  \n",
       "2999996       0.0       0.0      13.0  \n",
       "2999997       0.0       0.0      14.0  \n",
       "2999998       0.0       0.0      21.0  \n",
       "2999999       0.0       0.0       8.5  \n",
       "\n",
       "[3000000 rows x 24 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c00ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = pd.read_csv(\"grouped_features.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73afc2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>pre_loans_credit_cost_rate</th>\n",
       "      <th>pre_util</th>\n",
       "      <th>pre_over2limit</th>\n",
       "      <th>pre_maxover2limit</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>...</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>total_overdue_count</th>\n",
       "      <th>has_overdue_flag</th>\n",
       "      <th>has_no_debt_flag</th>\n",
       "      <th>term_difference</th>\n",
       "      <th>close_difference</th>\n",
       "      <th>status_0</th>\n",
       "      <th>status_1</th>\n",
       "      <th>status_2</th>\n",
       "      <th>status_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>-3.071429</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rn  pre_since_opened  pre_since_confirmed  pre_loans_next_pay_summ  \\\n",
       "0   0  10          8.100000                  9.0                      3.0   \n",
       "1   1  14         11.428571                  7.0                      2.0   \n",
       "2   2   3          8.333333                  9.0                      1.0   \n",
       "3   3  15          7.000000                  9.0                      2.0   \n",
       "4   4   1         12.000000                  9.0                      1.0   \n",
       "\n",
       "   pre_loans_credit_cost_rate  pre_util  pre_over2limit  pre_maxover2limit  \\\n",
       "0                         9.5      16.0             2.0               17.0   \n",
       "1                         4.0      16.0             2.0               17.0   \n",
       "2                         4.0       6.0             2.0               17.0   \n",
       "3                         4.0      16.0             2.0               17.0   \n",
       "4                         0.0      16.0             2.0               17.0   \n",
       "\n",
       "   enc_loans_account_holder_type  ...  fclose_flag  total_overdue_count  \\\n",
       "0                            1.0  ...          0.0                 39.0   \n",
       "1                            1.0  ...          0.0                 39.0   \n",
       "2                            1.0  ...          1.0                 39.0   \n",
       "3                            1.0  ...          0.0                 39.0   \n",
       "4                            1.0  ...          1.0                 39.0   \n",
       "\n",
       "   has_overdue_flag  has_no_debt_flag  term_difference  close_difference  \\\n",
       "0          0.100000          0.600000         0.400000         -0.700000   \n",
       "1          0.571429          0.714286         1.285714         -3.071429   \n",
       "2          0.333333          0.333333        -1.000000          4.000000   \n",
       "3          0.000000          0.533333         0.200000          2.933333   \n",
       "4          0.000000          1.000000         4.000000         10.000000   \n",
       "\n",
       "   status_0  status_1  status_2  status_3  \n",
       "0       9.5       0.0       0.0      15.0  \n",
       "1       8.5       0.0       0.0      15.5  \n",
       "2      10.0       0.0       0.0      15.0  \n",
       "3      14.0       0.0       0.0      11.0  \n",
       "4       0.0       0.0       0.0      25.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a539b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение с таргетом\n",
    "final_df = grouped_df.merge(train_target, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5bfa9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>pre_loans_credit_cost_rate</th>\n",
       "      <th>pre_util</th>\n",
       "      <th>pre_over2limit</th>\n",
       "      <th>pre_maxover2limit</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>...</th>\n",
       "      <th>total_overdue_count</th>\n",
       "      <th>has_overdue_flag</th>\n",
       "      <th>has_no_debt_flag</th>\n",
       "      <th>term_difference</th>\n",
       "      <th>close_difference</th>\n",
       "      <th>status_0</th>\n",
       "      <th>status_1</th>\n",
       "      <th>status_2</th>\n",
       "      <th>status_3</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>-3.071429</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rn  pre_since_opened  pre_since_confirmed  pre_loans_next_pay_summ  \\\n",
       "0   0  10          8.100000                  9.0                      3.0   \n",
       "1   1  14         11.428571                  7.0                      2.0   \n",
       "2   2   3          8.333333                  9.0                      1.0   \n",
       "3   3  15          7.000000                  9.0                      2.0   \n",
       "4   4   1         12.000000                  9.0                      1.0   \n",
       "\n",
       "   pre_loans_credit_cost_rate  pre_util  pre_over2limit  pre_maxover2limit  \\\n",
       "0                         9.5      16.0             2.0               17.0   \n",
       "1                         4.0      16.0             2.0               17.0   \n",
       "2                         4.0       6.0             2.0               17.0   \n",
       "3                         4.0      16.0             2.0               17.0   \n",
       "4                         0.0      16.0             2.0               17.0   \n",
       "\n",
       "   enc_loans_account_holder_type  ...  total_overdue_count  has_overdue_flag  \\\n",
       "0                            1.0  ...                 39.0          0.100000   \n",
       "1                            1.0  ...                 39.0          0.571429   \n",
       "2                            1.0  ...                 39.0          0.333333   \n",
       "3                            1.0  ...                 39.0          0.000000   \n",
       "4                            1.0  ...                 39.0          0.000000   \n",
       "\n",
       "   has_no_debt_flag  term_difference  close_difference  status_0  status_1  \\\n",
       "0          0.600000         0.400000         -0.700000       9.5       0.0   \n",
       "1          0.714286         1.285714         -3.071429       8.5       0.0   \n",
       "2          0.333333        -1.000000          4.000000      10.0       0.0   \n",
       "3          0.533333         0.200000          2.933333      14.0       0.0   \n",
       "4          1.000000         4.000000         10.000000       0.0       0.0   \n",
       "\n",
       "   status_2  status_3  flag  \n",
       "0       0.0      15.0     0  \n",
       "1       0.0      15.5     0  \n",
       "2       0.0      15.0     0  \n",
       "3       0.0      11.0     0  \n",
       "4       0.0      25.0     0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91cffc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_no_debt_flag  pre_util            0.627119\n",
       "pre_util          has_no_debt_flag    0.627119\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотрим на все корелляции выше 0.6. Не очень сильная корелляция, поэтому оставим эти признаки.\n",
    "correlation_matrix = final_df.corr()\n",
    "correlation_pairs = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "correlation_pairs = correlation_pairs[correlation_pairs < 1]\n",
    "high_correlation = correlation_pairs[correlation_pairs > 0.6]\n",
    "high_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a16071b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем значения на X, y, train/test и стандартизируем их.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = final_df.drop(columns=['id', 'flag'])\n",
    "y = final_df['flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27ebeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-18 09:06:15,096] A new study created in memory with name: no-name-1b97861d-d1d5-4d70-b4b6-5537589aac67\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:08:25,908] Trial 0 finished with value: 0.6891391701556918 and parameters: {'iterations': 658, 'learning_rate': 0.001487526733448147, 'depth': 10, 'l2_leaf_reg': 1}. Best is trial 0 with value: 0.6891391701556918.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:08:50,106] Trial 1 finished with value: 0.6828546756345869 and parameters: {'iterations': 921, 'learning_rate': 6.155447542948876e-05, 'depth': 9, 'l2_leaf_reg': 9}. Best is trial 0 with value: 0.6891391701556918.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:09:08,545] Trial 2 finished with value: 0.6822818359179362 and parameters: {'iterations': 631, 'learning_rate': 5.455209764961053e-05, 'depth': 9, 'l2_leaf_reg': 5}. Best is trial 0 with value: 0.6891391701556918.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:09:22,831] Trial 3 finished with value: 0.6758578681176186 and parameters: {'iterations': 126, 'learning_rate': 0.002760370052975072, 'depth': 5, 'l2_leaf_reg': 3}. Best is trial 0 with value: 0.6891391701556918.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:10:42,382] Trial 4 finished with value: 0.7024164211632169 and parameters: {'iterations': 698, 'learning_rate': 0.040668444700415675, 'depth': 6, 'l2_leaf_reg': 1}. Best is trial 4 with value: 0.7024164211632169.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:10:55,097] Trial 5 finished with value: 0.669323769551935 and parameters: {'iterations': 772, 'learning_rate': 3.747923989857688e-05, 'depth': 4, 'l2_leaf_reg': 7}. Best is trial 4 with value: 0.7024164211632169.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:11:44,407] Trial 6 finished with value: 0.6862124883282007 and parameters: {'iterations': 423, 'learning_rate': 0.004432243473624748, 'depth': 6, 'l2_leaf_reg': 8}. Best is trial 4 with value: 0.7024164211632169.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:13:21,442] Trial 7 finished with value: 0.6803498762369808 and parameters: {'iterations': 840, 'learning_rate': 0.0007262449169123334, 'depth': 6, 'l2_leaf_reg': 8}. Best is trial 4 with value: 0.7024164211632169.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:14:10,052] Trial 8 finished with value: 0.6769315450189122 and parameters: {'iterations': 482, 'learning_rate': 0.0020030771424485437, 'depth': 4, 'l2_leaf_reg': 7}. Best is trial 4 with value: 0.7024164211632169.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11508\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:14:33,747] Trial 9 finished with value: 0.6828329103799373 and parameters: {'iterations': 766, 'learning_rate': 2.728243964972653e-05, 'depth': 9, 'l2_leaf_reg': 5}. Best is trial 4 with value: 0.7024164211632169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'iterations': 698, 'learning_rate': 0.040668444700415675, 'depth': 6, 'l2_leaf_reg': 1}\n",
      "Лучший ROC-AUC: 0.7024164211632169\n",
      "0:\tlearn: 0.6325000\ttotal: 83.5ms\tremaining: 58.2s\n",
      "1:\tlearn: 0.5768237\ttotal: 167ms\tremaining: 58.2s\n",
      "2:\tlearn: 0.5286970\ttotal: 247ms\tremaining: 57.2s\n",
      "3:\tlearn: 0.4869436\ttotal: 316ms\tremaining: 54.8s\n",
      "4:\tlearn: 0.4498116\ttotal: 385ms\tremaining: 53.4s\n",
      "5:\tlearn: 0.4159709\ttotal: 461ms\tremaining: 53.1s\n",
      "6:\tlearn: 0.3867466\ttotal: 532ms\tremaining: 52.5s\n",
      "7:\tlearn: 0.3602850\ttotal: 610ms\tremaining: 52.6s\n",
      "8:\tlearn: 0.3369039\ttotal: 684ms\tremaining: 52.4s\n",
      "9:\tlearn: 0.3162234\ttotal: 762ms\tremaining: 52.4s\n",
      "10:\tlearn: 0.2982364\ttotal: 835ms\tremaining: 52.1s\n",
      "11:\tlearn: 0.2824142\ttotal: 916ms\tremaining: 52.4s\n",
      "12:\tlearn: 0.2686754\ttotal: 980ms\tremaining: 51.7s\n",
      "13:\tlearn: 0.2558643\ttotal: 1.06s\tremaining: 51.8s\n",
      "14:\tlearn: 0.2446729\ttotal: 1.13s\tremaining: 51.4s\n",
      "15:\tlearn: 0.2343439\ttotal: 1.21s\tremaining: 51.6s\n",
      "16:\tlearn: 0.2253417\ttotal: 1.29s\tremaining: 51.6s\n",
      "17:\tlearn: 0.2172924\ttotal: 1.36s\tremaining: 51.5s\n",
      "18:\tlearn: 0.2106174\ttotal: 1.44s\tremaining: 51.3s\n",
      "19:\tlearn: 0.2044664\ttotal: 1.5s\tremaining: 51s\n",
      "20:\tlearn: 0.1989393\ttotal: 1.58s\tremaining: 50.8s\n",
      "21:\tlearn: 0.1941754\ttotal: 1.64s\tremaining: 50.4s\n",
      "22:\tlearn: 0.1896577\ttotal: 1.71s\tremaining: 50.3s\n",
      "23:\tlearn: 0.1854974\ttotal: 1.79s\tremaining: 50.2s\n",
      "24:\tlearn: 0.1819313\ttotal: 1.86s\tremaining: 50.2s\n",
      "25:\tlearn: 0.1785964\ttotal: 1.94s\tremaining: 50.3s\n",
      "26:\tlearn: 0.1755078\ttotal: 2.02s\tremaining: 50.2s\n",
      "27:\tlearn: 0.1730342\ttotal: 2.09s\tremaining: 50s\n",
      "28:\tlearn: 0.1706205\ttotal: 2.17s\tremaining: 50s\n",
      "29:\tlearn: 0.1684071\ttotal: 2.24s\tremaining: 50s\n",
      "30:\tlearn: 0.1664073\ttotal: 2.33s\tremaining: 50.1s\n",
      "31:\tlearn: 0.1647465\ttotal: 2.4s\tremaining: 49.9s\n",
      "32:\tlearn: 0.1630855\ttotal: 2.47s\tremaining: 49.8s\n",
      "33:\tlearn: 0.1615896\ttotal: 2.55s\tremaining: 49.8s\n",
      "34:\tlearn: 0.1602689\ttotal: 2.63s\tremaining: 49.7s\n",
      "35:\tlearn: 0.1590468\ttotal: 2.71s\tremaining: 49.8s\n",
      "36:\tlearn: 0.1579868\ttotal: 2.78s\tremaining: 49.7s\n",
      "37:\tlearn: 0.1569124\ttotal: 2.86s\tremaining: 49.6s\n",
      "38:\tlearn: 0.1559333\ttotal: 2.94s\tremaining: 49.7s\n",
      "39:\tlearn: 0.1550407\ttotal: 3.02s\tremaining: 49.7s\n",
      "40:\tlearn: 0.1542117\ttotal: 3.1s\tremaining: 49.7s\n",
      "41:\tlearn: 0.1535985\ttotal: 3.17s\tremaining: 49.6s\n",
      "42:\tlearn: 0.1529237\ttotal: 3.25s\tremaining: 49.5s\n",
      "43:\tlearn: 0.1523337\ttotal: 3.33s\tremaining: 49.4s\n",
      "44:\tlearn: 0.1518405\ttotal: 3.4s\tremaining: 49.3s\n",
      "45:\tlearn: 0.1512932\ttotal: 3.48s\tremaining: 49.4s\n",
      "46:\tlearn: 0.1508186\ttotal: 3.56s\tremaining: 49.4s\n",
      "47:\tlearn: 0.1504413\ttotal: 3.64s\tremaining: 49.3s\n",
      "48:\tlearn: 0.1500145\ttotal: 3.72s\tremaining: 49.3s\n",
      "49:\tlearn: 0.1496482\ttotal: 3.8s\tremaining: 49.2s\n",
      "50:\tlearn: 0.1493647\ttotal: 3.88s\tremaining: 49.2s\n",
      "51:\tlearn: 0.1491117\ttotal: 3.95s\tremaining: 49.1s\n",
      "52:\tlearn: 0.1488204\ttotal: 4.03s\tremaining: 49.1s\n",
      "53:\tlearn: 0.1485948\ttotal: 4.12s\tremaining: 49.1s\n",
      "54:\tlearn: 0.1483634\ttotal: 4.19s\tremaining: 49s\n",
      "55:\tlearn: 0.1481757\ttotal: 4.27s\tremaining: 49s\n",
      "56:\tlearn: 0.1479824\ttotal: 4.34s\tremaining: 48.8s\n",
      "57:\tlearn: 0.1477696\ttotal: 4.42s\tremaining: 48.8s\n",
      "58:\tlearn: 0.1475573\ttotal: 4.51s\tremaining: 48.8s\n",
      "59:\tlearn: 0.1473835\ttotal: 4.59s\tremaining: 48.8s\n",
      "60:\tlearn: 0.1472212\ttotal: 4.67s\tremaining: 48.8s\n",
      "61:\tlearn: 0.1470555\ttotal: 4.76s\tremaining: 48.8s\n",
      "62:\tlearn: 0.1469098\ttotal: 4.84s\tremaining: 48.8s\n",
      "63:\tlearn: 0.1467750\ttotal: 4.92s\tremaining: 48.8s\n",
      "64:\tlearn: 0.1466575\ttotal: 5s\tremaining: 48.7s\n",
      "65:\tlearn: 0.1465421\ttotal: 5.09s\tremaining: 48.7s\n",
      "66:\tlearn: 0.1464535\ttotal: 5.16s\tremaining: 48.6s\n",
      "67:\tlearn: 0.1463540\ttotal: 5.24s\tremaining: 48.6s\n",
      "68:\tlearn: 0.1462553\ttotal: 5.32s\tremaining: 48.5s\n",
      "69:\tlearn: 0.1461623\ttotal: 5.4s\tremaining: 48.5s\n",
      "70:\tlearn: 0.1460833\ttotal: 5.48s\tremaining: 48.4s\n",
      "71:\tlearn: 0.1460236\ttotal: 5.55s\tremaining: 48.3s\n",
      "72:\tlearn: 0.1459632\ttotal: 5.64s\tremaining: 48.3s\n",
      "73:\tlearn: 0.1459160\ttotal: 5.71s\tremaining: 48.1s\n",
      "74:\tlearn: 0.1458470\ttotal: 5.79s\tremaining: 48.1s\n",
      "75:\tlearn: 0.1457682\ttotal: 5.87s\tremaining: 48.1s\n",
      "76:\tlearn: 0.1457162\ttotal: 5.95s\tremaining: 48s\n",
      "77:\tlearn: 0.1456617\ttotal: 6.03s\tremaining: 47.9s\n",
      "78:\tlearn: 0.1456148\ttotal: 6.11s\tremaining: 47.9s\n",
      "79:\tlearn: 0.1455684\ttotal: 6.18s\tremaining: 47.8s\n",
      "80:\tlearn: 0.1455243\ttotal: 6.27s\tremaining: 47.7s\n",
      "81:\tlearn: 0.1454787\ttotal: 6.35s\tremaining: 47.7s\n",
      "82:\tlearn: 0.1454351\ttotal: 6.42s\tremaining: 47.6s\n",
      "83:\tlearn: 0.1454017\ttotal: 6.51s\tremaining: 47.6s\n",
      "84:\tlearn: 0.1453589\ttotal: 6.59s\tremaining: 47.5s\n",
      "85:\tlearn: 0.1453317\ttotal: 6.67s\tremaining: 47.5s\n",
      "86:\tlearn: 0.1453089\ttotal: 6.75s\tremaining: 47.4s\n",
      "87:\tlearn: 0.1452695\ttotal: 6.84s\tremaining: 47.4s\n",
      "88:\tlearn: 0.1452246\ttotal: 6.92s\tremaining: 47.4s\n",
      "89:\tlearn: 0.1452039\ttotal: 7.01s\tremaining: 47.3s\n",
      "90:\tlearn: 0.1451747\ttotal: 7.09s\tremaining: 47.3s\n",
      "91:\tlearn: 0.1451393\ttotal: 7.17s\tremaining: 47.2s\n",
      "92:\tlearn: 0.1451133\ttotal: 7.25s\tremaining: 47.2s\n",
      "93:\tlearn: 0.1450880\ttotal: 7.34s\tremaining: 47.1s\n",
      "94:\tlearn: 0.1450658\ttotal: 7.42s\tremaining: 47.1s\n",
      "95:\tlearn: 0.1450462\ttotal: 7.5s\tremaining: 47s\n",
      "96:\tlearn: 0.1450274\ttotal: 7.58s\tremaining: 47s\n",
      "97:\tlearn: 0.1450105\ttotal: 7.66s\tremaining: 46.9s\n",
      "98:\tlearn: 0.1449920\ttotal: 7.74s\tremaining: 46.8s\n",
      "99:\tlearn: 0.1449746\ttotal: 7.82s\tremaining: 46.8s\n",
      "100:\tlearn: 0.1449624\ttotal: 7.9s\tremaining: 46.7s\n",
      "101:\tlearn: 0.1449393\ttotal: 7.98s\tremaining: 46.7s\n",
      "102:\tlearn: 0.1449194\ttotal: 8.1s\tremaining: 46.8s\n",
      "103:\tlearn: 0.1448966\ttotal: 8.19s\tremaining: 46.8s\n",
      "104:\tlearn: 0.1448807\ttotal: 8.26s\tremaining: 46.7s\n",
      "105:\tlearn: 0.1448595\ttotal: 8.34s\tremaining: 46.6s\n",
      "106:\tlearn: 0.1448429\ttotal: 8.41s\tremaining: 46.5s\n",
      "107:\tlearn: 0.1448305\ttotal: 8.49s\tremaining: 46.4s\n",
      "108:\tlearn: 0.1448122\ttotal: 8.61s\tremaining: 46.5s\n",
      "109:\tlearn: 0.1447959\ttotal: 8.69s\tremaining: 46.4s\n",
      "110:\tlearn: 0.1447788\ttotal: 8.76s\tremaining: 46.3s\n",
      "111:\tlearn: 0.1447702\ttotal: 8.85s\tremaining: 46.3s\n",
      "112:\tlearn: 0.1447579\ttotal: 8.93s\tremaining: 46.2s\n",
      "113:\tlearn: 0.1447392\ttotal: 9.01s\tremaining: 46.2s\n",
      "114:\tlearn: 0.1447256\ttotal: 9.1s\tremaining: 46.1s\n",
      "115:\tlearn: 0.1447078\ttotal: 9.18s\tremaining: 46.1s\n",
      "116:\tlearn: 0.1447003\ttotal: 9.26s\tremaining: 46s\n",
      "117:\tlearn: 0.1446770\ttotal: 9.34s\tremaining: 45.9s\n",
      "118:\tlearn: 0.1446665\ttotal: 9.42s\tremaining: 45.8s\n",
      "119:\tlearn: 0.1446524\ttotal: 9.49s\tremaining: 45.7s\n",
      "120:\tlearn: 0.1446466\ttotal: 9.57s\tremaining: 45.6s\n",
      "121:\tlearn: 0.1446329\ttotal: 9.65s\tremaining: 45.5s\n",
      "122:\tlearn: 0.1446239\ttotal: 9.72s\tremaining: 45.5s\n",
      "123:\tlearn: 0.1446142\ttotal: 9.8s\tremaining: 45.4s\n",
      "124:\tlearn: 0.1446034\ttotal: 9.87s\tremaining: 45.3s\n",
      "125:\tlearn: 0.1445883\ttotal: 9.96s\tremaining: 45.2s\n",
      "126:\tlearn: 0.1445775\ttotal: 10s\tremaining: 45.1s\n",
      "127:\tlearn: 0.1445629\ttotal: 10.1s\tremaining: 45s\n",
      "128:\tlearn: 0.1445555\ttotal: 10.2s\tremaining: 44.9s\n",
      "129:\tlearn: 0.1445389\ttotal: 10.3s\tremaining: 44.9s\n",
      "130:\tlearn: 0.1445278\ttotal: 10.3s\tremaining: 44.8s\n",
      "131:\tlearn: 0.1445199\ttotal: 10.4s\tremaining: 44.7s\n",
      "132:\tlearn: 0.1445057\ttotal: 10.5s\tremaining: 44.6s\n",
      "133:\tlearn: 0.1445005\ttotal: 10.6s\tremaining: 44.5s\n",
      "134:\tlearn: 0.1444917\ttotal: 10.7s\tremaining: 44.4s\n",
      "135:\tlearn: 0.1444857\ttotal: 10.7s\tremaining: 44.3s\n",
      "136:\tlearn: 0.1444756\ttotal: 10.8s\tremaining: 44.3s\n",
      "137:\tlearn: 0.1444647\ttotal: 10.9s\tremaining: 44.2s\n",
      "138:\tlearn: 0.1444543\ttotal: 11s\tremaining: 44.1s\n",
      "139:\tlearn: 0.1444413\ttotal: 11s\tremaining: 44s\n",
      "140:\tlearn: 0.1444326\ttotal: 11.1s\tremaining: 43.9s\n",
      "141:\tlearn: 0.1444211\ttotal: 11.2s\tremaining: 43.9s\n",
      "142:\tlearn: 0.1444105\ttotal: 11.3s\tremaining: 43.8s\n",
      "143:\tlearn: 0.1444026\ttotal: 11.4s\tremaining: 43.7s\n",
      "144:\tlearn: 0.1443919\ttotal: 11.4s\tremaining: 43.6s\n",
      "145:\tlearn: 0.1443825\ttotal: 11.5s\tremaining: 43.5s\n",
      "146:\tlearn: 0.1443749\ttotal: 11.6s\tremaining: 43.5s\n",
      "147:\tlearn: 0.1443665\ttotal: 11.7s\tremaining: 43.4s\n",
      "148:\tlearn: 0.1443601\ttotal: 11.8s\tremaining: 43.3s\n",
      "149:\tlearn: 0.1443534\ttotal: 11.8s\tremaining: 43.2s\n",
      "150:\tlearn: 0.1443465\ttotal: 11.9s\tremaining: 43.2s\n",
      "151:\tlearn: 0.1443396\ttotal: 12s\tremaining: 43.1s\n",
      "152:\tlearn: 0.1443360\ttotal: 12.1s\tremaining: 43s\n",
      "153:\tlearn: 0.1443301\ttotal: 12.1s\tremaining: 42.9s\n",
      "154:\tlearn: 0.1443234\ttotal: 12.2s\tremaining: 42.8s\n",
      "155:\tlearn: 0.1443178\ttotal: 12.3s\tremaining: 42.7s\n",
      "156:\tlearn: 0.1443112\ttotal: 12.4s\tremaining: 42.6s\n",
      "157:\tlearn: 0.1443045\ttotal: 12.5s\tremaining: 42.6s\n",
      "158:\tlearn: 0.1442976\ttotal: 12.5s\tremaining: 42.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.1442905\ttotal: 12.6s\tremaining: 42.4s\n",
      "160:\tlearn: 0.1442830\ttotal: 12.7s\tremaining: 42.3s\n",
      "161:\tlearn: 0.1442751\ttotal: 12.8s\tremaining: 42.3s\n",
      "162:\tlearn: 0.1442685\ttotal: 12.9s\tremaining: 42.2s\n",
      "163:\tlearn: 0.1442629\ttotal: 12.9s\tremaining: 42.1s\n",
      "164:\tlearn: 0.1442567\ttotal: 13s\tremaining: 42s\n",
      "165:\tlearn: 0.1442509\ttotal: 13.1s\tremaining: 42s\n",
      "166:\tlearn: 0.1442451\ttotal: 13.2s\tremaining: 41.9s\n",
      "167:\tlearn: 0.1442390\ttotal: 13.2s\tremaining: 41.8s\n",
      "168:\tlearn: 0.1442306\ttotal: 13.3s\tremaining: 41.7s\n",
      "169:\tlearn: 0.1442253\ttotal: 13.4s\tremaining: 41.6s\n",
      "170:\tlearn: 0.1442191\ttotal: 13.5s\tremaining: 41.5s\n",
      "171:\tlearn: 0.1442113\ttotal: 13.6s\tremaining: 41.4s\n",
      "172:\tlearn: 0.1442019\ttotal: 13.6s\tremaining: 41.4s\n",
      "173:\tlearn: 0.1441950\ttotal: 13.7s\tremaining: 41.3s\n",
      "174:\tlearn: 0.1441912\ttotal: 13.8s\tremaining: 41.2s\n",
      "175:\tlearn: 0.1441855\ttotal: 13.9s\tremaining: 41.1s\n",
      "176:\tlearn: 0.1441817\ttotal: 13.9s\tremaining: 41s\n",
      "177:\tlearn: 0.1441755\ttotal: 14s\tremaining: 40.9s\n",
      "178:\tlearn: 0.1441689\ttotal: 14.1s\tremaining: 40.9s\n",
      "179:\tlearn: 0.1441596\ttotal: 14.2s\tremaining: 40.8s\n",
      "180:\tlearn: 0.1441573\ttotal: 14.3s\tremaining: 40.7s\n",
      "181:\tlearn: 0.1441541\ttotal: 14.3s\tremaining: 40.6s\n",
      "182:\tlearn: 0.1441474\ttotal: 14.4s\tremaining: 40.5s\n",
      "183:\tlearn: 0.1441431\ttotal: 14.5s\tremaining: 40.5s\n",
      "184:\tlearn: 0.1441361\ttotal: 14.6s\tremaining: 40.4s\n",
      "185:\tlearn: 0.1441313\ttotal: 14.6s\tremaining: 40.3s\n",
      "186:\tlearn: 0.1441223\ttotal: 14.7s\tremaining: 40.2s\n",
      "187:\tlearn: 0.1441147\ttotal: 14.8s\tremaining: 40.1s\n",
      "188:\tlearn: 0.1441080\ttotal: 14.9s\tremaining: 40.1s\n",
      "189:\tlearn: 0.1441023\ttotal: 15s\tremaining: 40s\n",
      "190:\tlearn: 0.1440969\ttotal: 15s\tremaining: 39.9s\n",
      "191:\tlearn: 0.1440897\ttotal: 15.1s\tremaining: 39.8s\n",
      "192:\tlearn: 0.1440796\ttotal: 15.2s\tremaining: 39.8s\n",
      "193:\tlearn: 0.1440749\ttotal: 15.3s\tremaining: 39.7s\n",
      "194:\tlearn: 0.1440709\ttotal: 15.4s\tremaining: 39.6s\n",
      "195:\tlearn: 0.1440687\ttotal: 15.4s\tremaining: 39.5s\n",
      "196:\tlearn: 0.1440644\ttotal: 15.5s\tremaining: 39.4s\n",
      "197:\tlearn: 0.1440616\ttotal: 15.6s\tremaining: 39.3s\n",
      "198:\tlearn: 0.1440568\ttotal: 15.6s\tremaining: 39.2s\n",
      "199:\tlearn: 0.1440531\ttotal: 15.7s\tremaining: 39.1s\n",
      "200:\tlearn: 0.1440480\ttotal: 15.8s\tremaining: 39.1s\n",
      "201:\tlearn: 0.1440423\ttotal: 15.9s\tremaining: 39s\n",
      "202:\tlearn: 0.1440377\ttotal: 16s\tremaining: 38.9s\n",
      "203:\tlearn: 0.1440325\ttotal: 16s\tremaining: 38.8s\n",
      "204:\tlearn: 0.1440298\ttotal: 16.1s\tremaining: 38.7s\n",
      "205:\tlearn: 0.1440237\ttotal: 16.2s\tremaining: 38.7s\n",
      "206:\tlearn: 0.1440192\ttotal: 16.3s\tremaining: 38.6s\n",
      "207:\tlearn: 0.1440148\ttotal: 16.3s\tremaining: 38.5s\n",
      "208:\tlearn: 0.1440102\ttotal: 16.4s\tremaining: 38.4s\n",
      "209:\tlearn: 0.1440053\ttotal: 16.5s\tremaining: 38.3s\n",
      "210:\tlearn: 0.1439994\ttotal: 16.6s\tremaining: 38.2s\n",
      "211:\tlearn: 0.1439948\ttotal: 16.6s\tremaining: 38.2s\n",
      "212:\tlearn: 0.1439911\ttotal: 16.7s\tremaining: 38.1s\n",
      "213:\tlearn: 0.1439876\ttotal: 16.8s\tremaining: 38s\n",
      "214:\tlearn: 0.1439823\ttotal: 16.9s\tremaining: 37.9s\n",
      "215:\tlearn: 0.1439791\ttotal: 17s\tremaining: 37.9s\n",
      "216:\tlearn: 0.1439759\ttotal: 17s\tremaining: 37.8s\n",
      "217:\tlearn: 0.1439715\ttotal: 17.1s\tremaining: 37.7s\n",
      "218:\tlearn: 0.1439621\ttotal: 17.2s\tremaining: 37.6s\n",
      "219:\tlearn: 0.1439586\ttotal: 17.3s\tremaining: 37.5s\n",
      "220:\tlearn: 0.1439542\ttotal: 17.4s\tremaining: 37.5s\n",
      "221:\tlearn: 0.1439506\ttotal: 17.4s\tremaining: 37.4s\n",
      "222:\tlearn: 0.1439455\ttotal: 17.5s\tremaining: 37.3s\n",
      "223:\tlearn: 0.1439421\ttotal: 17.6s\tremaining: 37.2s\n",
      "224:\tlearn: 0.1439376\ttotal: 17.7s\tremaining: 37.1s\n",
      "225:\tlearn: 0.1439349\ttotal: 17.7s\tremaining: 37s\n",
      "226:\tlearn: 0.1439328\ttotal: 17.8s\tremaining: 36.9s\n",
      "227:\tlearn: 0.1439306\ttotal: 17.9s\tremaining: 36.8s\n",
      "228:\tlearn: 0.1439274\ttotal: 17.9s\tremaining: 36.8s\n",
      "229:\tlearn: 0.1439221\ttotal: 18s\tremaining: 36.7s\n",
      "230:\tlearn: 0.1439170\ttotal: 18.1s\tremaining: 36.6s\n",
      "231:\tlearn: 0.1439138\ttotal: 18.2s\tremaining: 36.5s\n",
      "232:\tlearn: 0.1439097\ttotal: 18.3s\tremaining: 36.4s\n",
      "233:\tlearn: 0.1439053\ttotal: 18.3s\tremaining: 36.3s\n",
      "234:\tlearn: 0.1439004\ttotal: 18.4s\tremaining: 36.3s\n",
      "235:\tlearn: 0.1438967\ttotal: 18.5s\tremaining: 36.2s\n",
      "236:\tlearn: 0.1438913\ttotal: 18.6s\tremaining: 36.1s\n",
      "237:\tlearn: 0.1438889\ttotal: 18.6s\tremaining: 36s\n",
      "238:\tlearn: 0.1438843\ttotal: 18.7s\tremaining: 35.9s\n",
      "239:\tlearn: 0.1438813\ttotal: 18.8s\tremaining: 35.9s\n",
      "240:\tlearn: 0.1438764\ttotal: 18.9s\tremaining: 35.8s\n",
      "241:\tlearn: 0.1438711\ttotal: 18.9s\tremaining: 35.7s\n",
      "242:\tlearn: 0.1438669\ttotal: 19s\tremaining: 35.6s\n",
      "243:\tlearn: 0.1438625\ttotal: 19.1s\tremaining: 35.5s\n",
      "244:\tlearn: 0.1438596\ttotal: 19.2s\tremaining: 35.4s\n",
      "245:\tlearn: 0.1438554\ttotal: 19.2s\tremaining: 35.4s\n",
      "246:\tlearn: 0.1438525\ttotal: 19.3s\tremaining: 35.3s\n",
      "247:\tlearn: 0.1438493\ttotal: 19.4s\tremaining: 35.2s\n",
      "248:\tlearn: 0.1438452\ttotal: 19.5s\tremaining: 35.1s\n",
      "249:\tlearn: 0.1438409\ttotal: 19.5s\tremaining: 35s\n",
      "250:\tlearn: 0.1438344\ttotal: 19.6s\tremaining: 35s\n",
      "251:\tlearn: 0.1438311\ttotal: 19.7s\tremaining: 34.9s\n",
      "252:\tlearn: 0.1438285\ttotal: 19.8s\tremaining: 34.8s\n",
      "253:\tlearn: 0.1438258\ttotal: 19.9s\tremaining: 34.7s\n",
      "254:\tlearn: 0.1438219\ttotal: 19.9s\tremaining: 34.6s\n",
      "255:\tlearn: 0.1438180\ttotal: 20s\tremaining: 34.6s\n",
      "256:\tlearn: 0.1438151\ttotal: 20.1s\tremaining: 34.5s\n",
      "257:\tlearn: 0.1438120\ttotal: 20.2s\tremaining: 34.4s\n",
      "258:\tlearn: 0.1438092\ttotal: 20.3s\tremaining: 34.3s\n",
      "259:\tlearn: 0.1438063\ttotal: 20.3s\tremaining: 34.2s\n",
      "260:\tlearn: 0.1438037\ttotal: 20.4s\tremaining: 34.2s\n",
      "261:\tlearn: 0.1437998\ttotal: 20.5s\tremaining: 34.1s\n",
      "262:\tlearn: 0.1437971\ttotal: 20.6s\tremaining: 34s\n",
      "263:\tlearn: 0.1437883\ttotal: 20.6s\tremaining: 33.9s\n",
      "264:\tlearn: 0.1437868\ttotal: 20.7s\tremaining: 33.8s\n",
      "265:\tlearn: 0.1437842\ttotal: 20.8s\tremaining: 33.8s\n",
      "266:\tlearn: 0.1437814\ttotal: 20.9s\tremaining: 33.7s\n",
      "267:\tlearn: 0.1437789\ttotal: 20.9s\tremaining: 33.6s\n",
      "268:\tlearn: 0.1437749\ttotal: 21s\tremaining: 33.5s\n",
      "269:\tlearn: 0.1437723\ttotal: 21.1s\tremaining: 33.4s\n",
      "270:\tlearn: 0.1437698\ttotal: 21.2s\tremaining: 33.4s\n",
      "271:\tlearn: 0.1437662\ttotal: 21.3s\tremaining: 33.3s\n",
      "272:\tlearn: 0.1437619\ttotal: 21.3s\tremaining: 33.2s\n",
      "273:\tlearn: 0.1437595\ttotal: 21.4s\tremaining: 33.1s\n",
      "274:\tlearn: 0.1437546\ttotal: 21.5s\tremaining: 33.1s\n",
      "275:\tlearn: 0.1437528\ttotal: 21.6s\tremaining: 33s\n",
      "276:\tlearn: 0.1437495\ttotal: 21.6s\tremaining: 32.9s\n",
      "277:\tlearn: 0.1437442\ttotal: 21.7s\tremaining: 32.8s\n",
      "278:\tlearn: 0.1437406\ttotal: 21.8s\tremaining: 32.7s\n",
      "279:\tlearn: 0.1437381\ttotal: 21.9s\tremaining: 32.7s\n",
      "280:\tlearn: 0.1437359\ttotal: 22s\tremaining: 32.6s\n",
      "281:\tlearn: 0.1437341\ttotal: 22s\tremaining: 32.5s\n",
      "282:\tlearn: 0.1437310\ttotal: 22.1s\tremaining: 32.4s\n",
      "283:\tlearn: 0.1437281\ttotal: 22.2s\tremaining: 32.3s\n",
      "284:\tlearn: 0.1437259\ttotal: 22.3s\tremaining: 32.3s\n",
      "285:\tlearn: 0.1437226\ttotal: 22.3s\tremaining: 32.2s\n",
      "286:\tlearn: 0.1437194\ttotal: 22.4s\tremaining: 32.1s\n",
      "287:\tlearn: 0.1437152\ttotal: 22.5s\tremaining: 32s\n",
      "288:\tlearn: 0.1437123\ttotal: 22.6s\tremaining: 31.9s\n",
      "289:\tlearn: 0.1437086\ttotal: 22.6s\tremaining: 31.9s\n",
      "290:\tlearn: 0.1437064\ttotal: 22.7s\tremaining: 31.8s\n",
      "291:\tlearn: 0.1437052\ttotal: 22.8s\tremaining: 31.7s\n",
      "292:\tlearn: 0.1437029\ttotal: 22.9s\tremaining: 31.6s\n",
      "293:\tlearn: 0.1437022\ttotal: 22.9s\tremaining: 31.5s\n",
      "294:\tlearn: 0.1436995\ttotal: 23s\tremaining: 31.4s\n",
      "295:\tlearn: 0.1436967\ttotal: 23.1s\tremaining: 31.4s\n",
      "296:\tlearn: 0.1436927\ttotal: 23.2s\tremaining: 31.3s\n",
      "297:\tlearn: 0.1436877\ttotal: 23.2s\tremaining: 31.2s\n",
      "298:\tlearn: 0.1436858\ttotal: 23.3s\tremaining: 31.1s\n",
      "299:\tlearn: 0.1436844\ttotal: 23.4s\tremaining: 31s\n",
      "300:\tlearn: 0.1436817\ttotal: 23.5s\tremaining: 30.9s\n",
      "301:\tlearn: 0.1436781\ttotal: 23.5s\tremaining: 30.9s\n",
      "302:\tlearn: 0.1436748\ttotal: 23.6s\tremaining: 30.8s\n",
      "303:\tlearn: 0.1436727\ttotal: 23.7s\tremaining: 30.7s\n",
      "304:\tlearn: 0.1436706\ttotal: 23.8s\tremaining: 30.6s\n",
      "305:\tlearn: 0.1436683\ttotal: 23.9s\tremaining: 30.6s\n",
      "306:\tlearn: 0.1436659\ttotal: 23.9s\tremaining: 30.5s\n",
      "307:\tlearn: 0.1436625\ttotal: 24s\tremaining: 30.4s\n",
      "308:\tlearn: 0.1436608\ttotal: 24.1s\tremaining: 30.3s\n",
      "309:\tlearn: 0.1436594\ttotal: 24.1s\tremaining: 30.2s\n",
      "310:\tlearn: 0.1436571\ttotal: 24.2s\tremaining: 30.1s\n",
      "311:\tlearn: 0.1436541\ttotal: 24.3s\tremaining: 30.1s\n",
      "312:\tlearn: 0.1436488\ttotal: 24.4s\tremaining: 30s\n",
      "313:\tlearn: 0.1436459\ttotal: 24.5s\tremaining: 29.9s\n",
      "314:\tlearn: 0.1436416\ttotal: 24.5s\tremaining: 29.8s\n",
      "315:\tlearn: 0.1436396\ttotal: 24.6s\tremaining: 29.8s\n",
      "316:\tlearn: 0.1436384\ttotal: 24.7s\tremaining: 29.7s\n",
      "317:\tlearn: 0.1436348\ttotal: 24.8s\tremaining: 29.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318:\tlearn: 0.1436318\ttotal: 24.9s\tremaining: 29.5s\n",
      "319:\tlearn: 0.1436292\ttotal: 24.9s\tremaining: 29.4s\n",
      "320:\tlearn: 0.1436270\ttotal: 25s\tremaining: 29.4s\n",
      "321:\tlearn: 0.1436215\ttotal: 25.1s\tremaining: 29.3s\n",
      "322:\tlearn: 0.1436198\ttotal: 25.2s\tremaining: 29.2s\n",
      "323:\tlearn: 0.1436179\ttotal: 25.2s\tremaining: 29.1s\n",
      "324:\tlearn: 0.1436136\ttotal: 25.3s\tremaining: 29.1s\n",
      "325:\tlearn: 0.1436114\ttotal: 25.4s\tremaining: 29s\n",
      "326:\tlearn: 0.1436081\ttotal: 25.5s\tremaining: 28.9s\n",
      "327:\tlearn: 0.1436052\ttotal: 25.6s\tremaining: 28.8s\n",
      "328:\tlearn: 0.1436028\ttotal: 25.6s\tremaining: 28.7s\n",
      "329:\tlearn: 0.1435993\ttotal: 25.7s\tremaining: 28.7s\n",
      "330:\tlearn: 0.1435969\ttotal: 25.8s\tremaining: 28.6s\n",
      "331:\tlearn: 0.1435934\ttotal: 25.9s\tremaining: 28.5s\n",
      "332:\tlearn: 0.1435905\ttotal: 25.9s\tremaining: 28.4s\n",
      "333:\tlearn: 0.1435884\ttotal: 26s\tremaining: 28.4s\n",
      "334:\tlearn: 0.1435853\ttotal: 26.1s\tremaining: 28.3s\n",
      "335:\tlearn: 0.1435817\ttotal: 26.2s\tremaining: 28.2s\n",
      "336:\tlearn: 0.1435764\ttotal: 26.3s\tremaining: 28.1s\n",
      "337:\tlearn: 0.1435750\ttotal: 26.3s\tremaining: 28s\n",
      "338:\tlearn: 0.1435733\ttotal: 26.4s\tremaining: 28s\n",
      "339:\tlearn: 0.1435702\ttotal: 26.5s\tremaining: 27.9s\n",
      "340:\tlearn: 0.1435679\ttotal: 26.6s\tremaining: 27.8s\n",
      "341:\tlearn: 0.1435651\ttotal: 26.6s\tremaining: 27.7s\n",
      "342:\tlearn: 0.1435626\ttotal: 26.7s\tremaining: 27.6s\n",
      "343:\tlearn: 0.1435599\ttotal: 26.8s\tremaining: 27.6s\n",
      "344:\tlearn: 0.1435564\ttotal: 26.9s\tremaining: 27.5s\n",
      "345:\tlearn: 0.1435518\ttotal: 27s\tremaining: 27.4s\n",
      "346:\tlearn: 0.1435497\ttotal: 27s\tremaining: 27.3s\n",
      "347:\tlearn: 0.1435472\ttotal: 27.1s\tremaining: 27.3s\n",
      "348:\tlearn: 0.1435447\ttotal: 27.2s\tremaining: 27.2s\n",
      "349:\tlearn: 0.1435430\ttotal: 27.3s\tremaining: 27.1s\n",
      "350:\tlearn: 0.1435409\ttotal: 27.3s\tremaining: 27s\n",
      "351:\tlearn: 0.1435389\ttotal: 27.4s\tremaining: 26.9s\n",
      "352:\tlearn: 0.1435370\ttotal: 27.5s\tremaining: 26.9s\n",
      "353:\tlearn: 0.1435345\ttotal: 27.6s\tremaining: 26.8s\n",
      "354:\tlearn: 0.1435309\ttotal: 27.6s\tremaining: 26.7s\n",
      "355:\tlearn: 0.1435297\ttotal: 27.7s\tremaining: 26.6s\n",
      "356:\tlearn: 0.1435256\ttotal: 27.8s\tremaining: 26.5s\n",
      "357:\tlearn: 0.1435193\ttotal: 27.9s\tremaining: 26.5s\n",
      "358:\tlearn: 0.1435165\ttotal: 28s\tremaining: 26.4s\n",
      "359:\tlearn: 0.1435154\ttotal: 28s\tremaining: 26.3s\n",
      "360:\tlearn: 0.1435138\ttotal: 28.1s\tremaining: 26.2s\n",
      "361:\tlearn: 0.1435112\ttotal: 28.2s\tremaining: 26.2s\n",
      "362:\tlearn: 0.1435076\ttotal: 28.3s\tremaining: 26.1s\n",
      "363:\tlearn: 0.1435050\ttotal: 28.3s\tremaining: 26s\n",
      "364:\tlearn: 0.1435029\ttotal: 28.4s\tremaining: 25.9s\n",
      "365:\tlearn: 0.1435007\ttotal: 28.5s\tremaining: 25.8s\n",
      "366:\tlearn: 0.1434979\ttotal: 28.6s\tremaining: 25.8s\n",
      "367:\tlearn: 0.1434944\ttotal: 28.7s\tremaining: 25.7s\n",
      "368:\tlearn: 0.1434924\ttotal: 28.7s\tremaining: 25.6s\n",
      "369:\tlearn: 0.1434899\ttotal: 28.8s\tremaining: 25.5s\n",
      "370:\tlearn: 0.1434880\ttotal: 28.9s\tremaining: 25.4s\n",
      "371:\tlearn: 0.1434854\ttotal: 29s\tremaining: 25.4s\n",
      "372:\tlearn: 0.1434811\ttotal: 29s\tremaining: 25.3s\n",
      "373:\tlearn: 0.1434780\ttotal: 29.1s\tremaining: 25.2s\n",
      "374:\tlearn: 0.1434761\ttotal: 29.2s\tremaining: 25.1s\n",
      "375:\tlearn: 0.1434728\ttotal: 29.3s\tremaining: 25.1s\n",
      "376:\tlearn: 0.1434703\ttotal: 29.3s\tremaining: 25s\n",
      "377:\tlearn: 0.1434653\ttotal: 29.4s\tremaining: 24.9s\n",
      "378:\tlearn: 0.1434607\ttotal: 29.5s\tremaining: 24.8s\n",
      "379:\tlearn: 0.1434576\ttotal: 29.6s\tremaining: 24.8s\n",
      "380:\tlearn: 0.1434557\ttotal: 29.7s\tremaining: 24.7s\n",
      "381:\tlearn: 0.1434530\ttotal: 29.7s\tremaining: 24.6s\n",
      "382:\tlearn: 0.1434510\ttotal: 29.8s\tremaining: 24.5s\n",
      "383:\tlearn: 0.1434489\ttotal: 29.9s\tremaining: 24.4s\n",
      "384:\tlearn: 0.1434466\ttotal: 30s\tremaining: 24.4s\n",
      "385:\tlearn: 0.1434447\ttotal: 30s\tremaining: 24.3s\n",
      "386:\tlearn: 0.1434415\ttotal: 30.1s\tremaining: 24.2s\n",
      "387:\tlearn: 0.1434390\ttotal: 30.2s\tremaining: 24.1s\n",
      "388:\tlearn: 0.1434346\ttotal: 30.3s\tremaining: 24s\n",
      "389:\tlearn: 0.1434318\ttotal: 30.4s\tremaining: 24s\n",
      "390:\tlearn: 0.1434285\ttotal: 30.4s\tremaining: 23.9s\n",
      "391:\tlearn: 0.1434261\ttotal: 30.5s\tremaining: 23.8s\n",
      "392:\tlearn: 0.1434242\ttotal: 30.6s\tremaining: 23.7s\n",
      "393:\tlearn: 0.1434226\ttotal: 30.7s\tremaining: 23.7s\n",
      "394:\tlearn: 0.1434192\ttotal: 30.7s\tremaining: 23.6s\n",
      "395:\tlearn: 0.1434168\ttotal: 30.8s\tremaining: 23.5s\n",
      "396:\tlearn: 0.1434152\ttotal: 30.9s\tremaining: 23.4s\n",
      "397:\tlearn: 0.1434122\ttotal: 31s\tremaining: 23.3s\n",
      "398:\tlearn: 0.1434098\ttotal: 31s\tremaining: 23.3s\n",
      "399:\tlearn: 0.1434062\ttotal: 31.1s\tremaining: 23.2s\n",
      "400:\tlearn: 0.1434036\ttotal: 31.2s\tremaining: 23.1s\n",
      "401:\tlearn: 0.1434019\ttotal: 31.3s\tremaining: 23s\n",
      "402:\tlearn: 0.1433997\ttotal: 31.4s\tremaining: 23s\n",
      "403:\tlearn: 0.1433987\ttotal: 31.4s\tremaining: 22.9s\n",
      "404:\tlearn: 0.1433967\ttotal: 31.5s\tremaining: 22.8s\n",
      "405:\tlearn: 0.1433944\ttotal: 31.6s\tremaining: 22.7s\n",
      "406:\tlearn: 0.1433922\ttotal: 31.6s\tremaining: 22.6s\n",
      "407:\tlearn: 0.1433902\ttotal: 31.7s\tremaining: 22.5s\n",
      "408:\tlearn: 0.1433855\ttotal: 31.8s\tremaining: 22.5s\n",
      "409:\tlearn: 0.1433834\ttotal: 31.9s\tremaining: 22.4s\n",
      "410:\tlearn: 0.1433808\ttotal: 32s\tremaining: 22.3s\n",
      "411:\tlearn: 0.1433757\ttotal: 32s\tremaining: 22.2s\n",
      "412:\tlearn: 0.1433719\ttotal: 32.1s\tremaining: 22.2s\n",
      "413:\tlearn: 0.1433697\ttotal: 32.2s\tremaining: 22.1s\n",
      "414:\tlearn: 0.1433662\ttotal: 32.3s\tremaining: 22s\n",
      "415:\tlearn: 0.1433634\ttotal: 32.4s\tremaining: 21.9s\n",
      "416:\tlearn: 0.1433619\ttotal: 32.4s\tremaining: 21.9s\n",
      "417:\tlearn: 0.1433606\ttotal: 32.5s\tremaining: 21.8s\n",
      "418:\tlearn: 0.1433583\ttotal: 32.6s\tremaining: 21.7s\n",
      "419:\tlearn: 0.1433555\ttotal: 32.7s\tremaining: 21.6s\n",
      "420:\tlearn: 0.1433535\ttotal: 32.7s\tremaining: 21.5s\n",
      "421:\tlearn: 0.1433515\ttotal: 32.8s\tremaining: 21.5s\n",
      "422:\tlearn: 0.1433498\ttotal: 32.9s\tremaining: 21.4s\n",
      "423:\tlearn: 0.1433477\ttotal: 33s\tremaining: 21.3s\n",
      "424:\tlearn: 0.1433463\ttotal: 33s\tremaining: 21.2s\n",
      "425:\tlearn: 0.1433445\ttotal: 33.1s\tremaining: 21.1s\n",
      "426:\tlearn: 0.1433425\ttotal: 33.2s\tremaining: 21.1s\n",
      "427:\tlearn: 0.1433411\ttotal: 33.3s\tremaining: 21s\n",
      "428:\tlearn: 0.1433399\ttotal: 33.3s\tremaining: 20.9s\n",
      "429:\tlearn: 0.1433382\ttotal: 33.4s\tremaining: 20.8s\n",
      "430:\tlearn: 0.1433373\ttotal: 33.5s\tremaining: 20.7s\n",
      "431:\tlearn: 0.1433345\ttotal: 33.6s\tremaining: 20.7s\n",
      "432:\tlearn: 0.1433320\ttotal: 33.6s\tremaining: 20.6s\n",
      "433:\tlearn: 0.1433285\ttotal: 33.7s\tremaining: 20.5s\n",
      "434:\tlearn: 0.1433274\ttotal: 33.8s\tremaining: 20.4s\n",
      "435:\tlearn: 0.1433254\ttotal: 33.9s\tremaining: 20.4s\n",
      "436:\tlearn: 0.1433236\ttotal: 33.9s\tremaining: 20.3s\n",
      "437:\tlearn: 0.1433209\ttotal: 34s\tremaining: 20.2s\n",
      "438:\tlearn: 0.1433179\ttotal: 34.1s\tremaining: 20.1s\n",
      "439:\tlearn: 0.1433147\ttotal: 34.2s\tremaining: 20s\n",
      "440:\tlearn: 0.1433109\ttotal: 34.3s\tremaining: 20s\n",
      "441:\tlearn: 0.1433094\ttotal: 34.3s\tremaining: 19.9s\n",
      "442:\tlearn: 0.1433077\ttotal: 34.4s\tremaining: 19.8s\n",
      "443:\tlearn: 0.1433060\ttotal: 34.5s\tremaining: 19.7s\n",
      "444:\tlearn: 0.1433044\ttotal: 34.5s\tremaining: 19.6s\n",
      "445:\tlearn: 0.1433032\ttotal: 34.6s\tremaining: 19.6s\n",
      "446:\tlearn: 0.1433013\ttotal: 34.7s\tremaining: 19.5s\n",
      "447:\tlearn: 0.1432996\ttotal: 34.8s\tremaining: 19.4s\n",
      "448:\tlearn: 0.1432951\ttotal: 34.8s\tremaining: 19.3s\n",
      "449:\tlearn: 0.1432933\ttotal: 34.9s\tremaining: 19.2s\n",
      "450:\tlearn: 0.1432906\ttotal: 35s\tremaining: 19.2s\n",
      "451:\tlearn: 0.1432884\ttotal: 35.1s\tremaining: 19.1s\n",
      "452:\tlearn: 0.1432854\ttotal: 35.2s\tremaining: 19s\n",
      "453:\tlearn: 0.1432821\ttotal: 35.2s\tremaining: 18.9s\n",
      "454:\tlearn: 0.1432802\ttotal: 35.3s\tremaining: 18.9s\n",
      "455:\tlearn: 0.1432785\ttotal: 35.4s\tremaining: 18.8s\n",
      "456:\tlearn: 0.1432772\ttotal: 35.5s\tremaining: 18.7s\n",
      "457:\tlearn: 0.1432753\ttotal: 35.5s\tremaining: 18.6s\n",
      "458:\tlearn: 0.1432736\ttotal: 35.6s\tremaining: 18.5s\n",
      "459:\tlearn: 0.1432711\ttotal: 35.7s\tremaining: 18.5s\n",
      "460:\tlearn: 0.1432691\ttotal: 35.8s\tremaining: 18.4s\n",
      "461:\tlearn: 0.1432661\ttotal: 35.9s\tremaining: 18.3s\n",
      "462:\tlearn: 0.1432637\ttotal: 35.9s\tremaining: 18.2s\n",
      "463:\tlearn: 0.1432610\ttotal: 36s\tremaining: 18.2s\n",
      "464:\tlearn: 0.1432594\ttotal: 36.1s\tremaining: 18.1s\n",
      "465:\tlearn: 0.1432573\ttotal: 36.2s\tremaining: 18s\n",
      "466:\tlearn: 0.1432544\ttotal: 36.2s\tremaining: 17.9s\n",
      "467:\tlearn: 0.1432535\ttotal: 36.3s\tremaining: 17.8s\n",
      "468:\tlearn: 0.1432516\ttotal: 36.4s\tremaining: 17.8s\n",
      "469:\tlearn: 0.1432492\ttotal: 36.5s\tremaining: 17.7s\n",
      "470:\tlearn: 0.1432472\ttotal: 36.5s\tremaining: 17.6s\n",
      "471:\tlearn: 0.1432448\ttotal: 36.6s\tremaining: 17.5s\n",
      "472:\tlearn: 0.1432433\ttotal: 36.7s\tremaining: 17.5s\n",
      "473:\tlearn: 0.1432410\ttotal: 36.8s\tremaining: 17.4s\n",
      "474:\tlearn: 0.1432397\ttotal: 36.8s\tremaining: 17.3s\n",
      "475:\tlearn: 0.1432380\ttotal: 36.9s\tremaining: 17.2s\n",
      "476:\tlearn: 0.1432367\ttotal: 37s\tremaining: 17.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477:\tlearn: 0.1432344\ttotal: 37.1s\tremaining: 17.1s\n",
      "478:\tlearn: 0.1432329\ttotal: 37.2s\tremaining: 17s\n",
      "479:\tlearn: 0.1432294\ttotal: 37.2s\tremaining: 16.9s\n",
      "480:\tlearn: 0.1432279\ttotal: 37.3s\tremaining: 16.8s\n",
      "481:\tlearn: 0.1432264\ttotal: 37.4s\tremaining: 16.8s\n",
      "482:\tlearn: 0.1432247\ttotal: 37.5s\tremaining: 16.7s\n",
      "483:\tlearn: 0.1432228\ttotal: 37.5s\tremaining: 16.6s\n",
      "484:\tlearn: 0.1432214\ttotal: 37.6s\tremaining: 16.5s\n",
      "485:\tlearn: 0.1432195\ttotal: 37.7s\tremaining: 16.4s\n",
      "486:\tlearn: 0.1432167\ttotal: 37.8s\tremaining: 16.4s\n",
      "487:\tlearn: 0.1432136\ttotal: 37.8s\tremaining: 16.3s\n",
      "488:\tlearn: 0.1432124\ttotal: 37.9s\tremaining: 16.2s\n",
      "489:\tlearn: 0.1432099\ttotal: 38s\tremaining: 16.1s\n",
      "490:\tlearn: 0.1432082\ttotal: 38.1s\tremaining: 16.1s\n",
      "491:\tlearn: 0.1432048\ttotal: 38.2s\tremaining: 16s\n",
      "492:\tlearn: 0.1432034\ttotal: 38.3s\tremaining: 15.9s\n",
      "493:\tlearn: 0.1432021\ttotal: 38.3s\tremaining: 15.8s\n",
      "494:\tlearn: 0.1432006\ttotal: 38.4s\tremaining: 15.8s\n",
      "495:\tlearn: 0.1431988\ttotal: 38.5s\tremaining: 15.7s\n",
      "496:\tlearn: 0.1431973\ttotal: 38.6s\tremaining: 15.6s\n",
      "497:\tlearn: 0.1431942\ttotal: 38.6s\tremaining: 15.5s\n",
      "498:\tlearn: 0.1431931\ttotal: 38.7s\tremaining: 15.4s\n",
      "499:\tlearn: 0.1431912\ttotal: 38.8s\tremaining: 15.4s\n",
      "500:\tlearn: 0.1431903\ttotal: 38.9s\tremaining: 15.3s\n",
      "501:\tlearn: 0.1431889\ttotal: 38.9s\tremaining: 15.2s\n",
      "502:\tlearn: 0.1431875\ttotal: 39s\tremaining: 15.1s\n",
      "503:\tlearn: 0.1431843\ttotal: 39.1s\tremaining: 15s\n",
      "504:\tlearn: 0.1431818\ttotal: 39.1s\tremaining: 15s\n",
      "505:\tlearn: 0.1431804\ttotal: 39.2s\tremaining: 14.9s\n",
      "506:\tlearn: 0.1431789\ttotal: 39.3s\tremaining: 14.8s\n",
      "507:\tlearn: 0.1431776\ttotal: 39.4s\tremaining: 14.7s\n",
      "508:\tlearn: 0.1431763\ttotal: 39.4s\tremaining: 14.6s\n",
      "509:\tlearn: 0.1431739\ttotal: 39.5s\tremaining: 14.6s\n",
      "510:\tlearn: 0.1431709\ttotal: 39.6s\tremaining: 14.5s\n",
      "511:\tlearn: 0.1431696\ttotal: 39.7s\tremaining: 14.4s\n",
      "512:\tlearn: 0.1431680\ttotal: 39.7s\tremaining: 14.3s\n",
      "513:\tlearn: 0.1431669\ttotal: 39.8s\tremaining: 14.3s\n",
      "514:\tlearn: 0.1431658\ttotal: 39.9s\tremaining: 14.2s\n",
      "515:\tlearn: 0.1431635\ttotal: 40s\tremaining: 14.1s\n",
      "516:\tlearn: 0.1431621\ttotal: 40s\tremaining: 14s\n",
      "517:\tlearn: 0.1431614\ttotal: 40.1s\tremaining: 13.9s\n",
      "518:\tlearn: 0.1431578\ttotal: 40.2s\tremaining: 13.9s\n",
      "519:\tlearn: 0.1431558\ttotal: 40.3s\tremaining: 13.8s\n",
      "520:\tlearn: 0.1431532\ttotal: 40.3s\tremaining: 13.7s\n",
      "521:\tlearn: 0.1431505\ttotal: 40.4s\tremaining: 13.6s\n",
      "522:\tlearn: 0.1431487\ttotal: 40.5s\tremaining: 13.6s\n",
      "523:\tlearn: 0.1431470\ttotal: 40.6s\tremaining: 13.5s\n",
      "524:\tlearn: 0.1431457\ttotal: 40.6s\tremaining: 13.4s\n",
      "525:\tlearn: 0.1431442\ttotal: 40.7s\tremaining: 13.3s\n",
      "526:\tlearn: 0.1431427\ttotal: 40.8s\tremaining: 13.2s\n",
      "527:\tlearn: 0.1431418\ttotal: 40.9s\tremaining: 13.2s\n",
      "528:\tlearn: 0.1431382\ttotal: 40.9s\tremaining: 13.1s\n",
      "529:\tlearn: 0.1431356\ttotal: 41s\tremaining: 13s\n",
      "530:\tlearn: 0.1431335\ttotal: 41.1s\tremaining: 12.9s\n",
      "531:\tlearn: 0.1431306\ttotal: 41.2s\tremaining: 12.8s\n",
      "532:\tlearn: 0.1431281\ttotal: 41.3s\tremaining: 12.8s\n",
      "533:\tlearn: 0.1431260\ttotal: 41.3s\tremaining: 12.7s\n",
      "534:\tlearn: 0.1431243\ttotal: 41.4s\tremaining: 12.6s\n",
      "535:\tlearn: 0.1431225\ttotal: 41.5s\tremaining: 12.5s\n",
      "536:\tlearn: 0.1431208\ttotal: 41.6s\tremaining: 12.5s\n",
      "537:\tlearn: 0.1431171\ttotal: 41.6s\tremaining: 12.4s\n",
      "538:\tlearn: 0.1431150\ttotal: 41.7s\tremaining: 12.3s\n",
      "539:\tlearn: 0.1431136\ttotal: 41.8s\tremaining: 12.2s\n",
      "540:\tlearn: 0.1431116\ttotal: 41.9s\tremaining: 12.1s\n",
      "541:\tlearn: 0.1431100\ttotal: 41.9s\tremaining: 12.1s\n",
      "542:\tlearn: 0.1431083\ttotal: 42s\tremaining: 12s\n",
      "543:\tlearn: 0.1431057\ttotal: 42.1s\tremaining: 11.9s\n",
      "544:\tlearn: 0.1431041\ttotal: 42.2s\tremaining: 11.8s\n",
      "545:\tlearn: 0.1431028\ttotal: 42.2s\tremaining: 11.8s\n",
      "546:\tlearn: 0.1431017\ttotal: 42.3s\tremaining: 11.7s\n",
      "547:\tlearn: 0.1430996\ttotal: 42.4s\tremaining: 11.6s\n",
      "548:\tlearn: 0.1430974\ttotal: 42.5s\tremaining: 11.5s\n",
      "549:\tlearn: 0.1430955\ttotal: 42.5s\tremaining: 11.4s\n",
      "550:\tlearn: 0.1430926\ttotal: 42.6s\tremaining: 11.4s\n",
      "551:\tlearn: 0.1430906\ttotal: 42.7s\tremaining: 11.3s\n",
      "552:\tlearn: 0.1430894\ttotal: 42.8s\tremaining: 11.2s\n",
      "553:\tlearn: 0.1430877\ttotal: 42.8s\tremaining: 11.1s\n",
      "554:\tlearn: 0.1430862\ttotal: 42.9s\tremaining: 11.1s\n",
      "555:\tlearn: 0.1430848\ttotal: 43s\tremaining: 11s\n",
      "556:\tlearn: 0.1430834\ttotal: 43.1s\tremaining: 10.9s\n",
      "557:\tlearn: 0.1430823\ttotal: 43.1s\tremaining: 10.8s\n",
      "558:\tlearn: 0.1430805\ttotal: 43.2s\tremaining: 10.7s\n",
      "559:\tlearn: 0.1430792\ttotal: 43.3s\tremaining: 10.7s\n",
      "560:\tlearn: 0.1430772\ttotal: 43.4s\tremaining: 10.6s\n",
      "561:\tlearn: 0.1430760\ttotal: 43.4s\tremaining: 10.5s\n",
      "562:\tlearn: 0.1430733\ttotal: 43.5s\tremaining: 10.4s\n",
      "563:\tlearn: 0.1430710\ttotal: 43.6s\tremaining: 10.4s\n",
      "564:\tlearn: 0.1430698\ttotal: 43.7s\tremaining: 10.3s\n",
      "565:\tlearn: 0.1430687\ttotal: 43.7s\tremaining: 10.2s\n",
      "566:\tlearn: 0.1430669\ttotal: 43.8s\tremaining: 10.1s\n",
      "567:\tlearn: 0.1430649\ttotal: 43.9s\tremaining: 10s\n",
      "568:\tlearn: 0.1430637\ttotal: 44s\tremaining: 9.97s\n",
      "569:\tlearn: 0.1430618\ttotal: 44s\tremaining: 9.89s\n",
      "570:\tlearn: 0.1430604\ttotal: 44.1s\tremaining: 9.81s\n",
      "571:\tlearn: 0.1430581\ttotal: 44.2s\tremaining: 9.73s\n",
      "572:\tlearn: 0.1430567\ttotal: 44.3s\tremaining: 9.65s\n",
      "573:\tlearn: 0.1430548\ttotal: 44.3s\tremaining: 9.58s\n",
      "574:\tlearn: 0.1430529\ttotal: 44.4s\tremaining: 9.5s\n",
      "575:\tlearn: 0.1430506\ttotal: 44.5s\tremaining: 9.42s\n",
      "576:\tlearn: 0.1430487\ttotal: 44.6s\tremaining: 9.34s\n",
      "577:\tlearn: 0.1430460\ttotal: 44.6s\tremaining: 9.27s\n",
      "578:\tlearn: 0.1430446\ttotal: 44.7s\tremaining: 9.19s\n",
      "579:\tlearn: 0.1430430\ttotal: 44.8s\tremaining: 9.11s\n",
      "580:\tlearn: 0.1430412\ttotal: 44.9s\tremaining: 9.03s\n",
      "581:\tlearn: 0.1430397\ttotal: 44.9s\tremaining: 8.96s\n",
      "582:\tlearn: 0.1430384\ttotal: 45s\tremaining: 8.88s\n",
      "583:\tlearn: 0.1430370\ttotal: 45.1s\tremaining: 8.8s\n",
      "584:\tlearn: 0.1430351\ttotal: 45.2s\tremaining: 8.72s\n",
      "585:\tlearn: 0.1430327\ttotal: 45.2s\tremaining: 8.65s\n",
      "586:\tlearn: 0.1430308\ttotal: 45.3s\tremaining: 8.57s\n",
      "587:\tlearn: 0.1430292\ttotal: 45.4s\tremaining: 8.49s\n",
      "588:\tlearn: 0.1430255\ttotal: 45.5s\tremaining: 8.42s\n",
      "589:\tlearn: 0.1430246\ttotal: 45.6s\tremaining: 8.34s\n",
      "590:\tlearn: 0.1430236\ttotal: 45.6s\tremaining: 8.26s\n",
      "591:\tlearn: 0.1430218\ttotal: 45.7s\tremaining: 8.18s\n",
      "592:\tlearn: 0.1430206\ttotal: 45.8s\tremaining: 8.1s\n",
      "593:\tlearn: 0.1430176\ttotal: 45.9s\tremaining: 8.03s\n",
      "594:\tlearn: 0.1430163\ttotal: 45.9s\tremaining: 7.95s\n",
      "595:\tlearn: 0.1430143\ttotal: 46s\tremaining: 7.87s\n",
      "596:\tlearn: 0.1430116\ttotal: 46.1s\tremaining: 7.79s\n",
      "597:\tlearn: 0.1430101\ttotal: 46.2s\tremaining: 7.72s\n",
      "598:\tlearn: 0.1430082\ttotal: 46.2s\tremaining: 7.64s\n",
      "599:\tlearn: 0.1430064\ttotal: 46.3s\tremaining: 7.56s\n",
      "600:\tlearn: 0.1430033\ttotal: 46.4s\tremaining: 7.49s\n",
      "601:\tlearn: 0.1430017\ttotal: 46.5s\tremaining: 7.41s\n",
      "602:\tlearn: 0.1430004\ttotal: 46.5s\tremaining: 7.33s\n",
      "603:\tlearn: 0.1429986\ttotal: 46.6s\tremaining: 7.25s\n",
      "604:\tlearn: 0.1429967\ttotal: 46.7s\tremaining: 7.18s\n",
      "605:\tlearn: 0.1429951\ttotal: 46.8s\tremaining: 7.1s\n",
      "606:\tlearn: 0.1429938\ttotal: 46.8s\tremaining: 7.02s\n",
      "607:\tlearn: 0.1429920\ttotal: 46.9s\tremaining: 6.94s\n",
      "608:\tlearn: 0.1429905\ttotal: 47s\tremaining: 6.87s\n",
      "609:\tlearn: 0.1429882\ttotal: 47.1s\tremaining: 6.79s\n",
      "610:\tlearn: 0.1429869\ttotal: 47.1s\tremaining: 6.71s\n",
      "611:\tlearn: 0.1429847\ttotal: 47.2s\tremaining: 6.64s\n",
      "612:\tlearn: 0.1429837\ttotal: 47.3s\tremaining: 6.56s\n",
      "613:\tlearn: 0.1429826\ttotal: 47.4s\tremaining: 6.48s\n",
      "614:\tlearn: 0.1429801\ttotal: 47.4s\tremaining: 6.4s\n",
      "615:\tlearn: 0.1429791\ttotal: 47.5s\tremaining: 6.33s\n",
      "616:\tlearn: 0.1429764\ttotal: 47.6s\tremaining: 6.25s\n",
      "617:\tlearn: 0.1429753\ttotal: 47.7s\tremaining: 6.17s\n",
      "618:\tlearn: 0.1429734\ttotal: 47.7s\tremaining: 6.09s\n",
      "619:\tlearn: 0.1429702\ttotal: 47.8s\tremaining: 6.02s\n",
      "620:\tlearn: 0.1429676\ttotal: 47.9s\tremaining: 5.94s\n",
      "621:\tlearn: 0.1429644\ttotal: 48s\tremaining: 5.86s\n",
      "622:\tlearn: 0.1429635\ttotal: 48.1s\tremaining: 5.79s\n",
      "623:\tlearn: 0.1429623\ttotal: 48.1s\tremaining: 5.71s\n",
      "624:\tlearn: 0.1429613\ttotal: 48.2s\tremaining: 5.63s\n",
      "625:\tlearn: 0.1429598\ttotal: 48.3s\tremaining: 5.55s\n",
      "626:\tlearn: 0.1429577\ttotal: 48.4s\tremaining: 5.48s\n",
      "627:\tlearn: 0.1429554\ttotal: 48.4s\tremaining: 5.4s\n",
      "628:\tlearn: 0.1429543\ttotal: 48.5s\tremaining: 5.32s\n",
      "629:\tlearn: 0.1429530\ttotal: 48.6s\tremaining: 5.24s\n",
      "630:\tlearn: 0.1429506\ttotal: 48.7s\tremaining: 5.17s\n",
      "631:\tlearn: 0.1429489\ttotal: 48.7s\tremaining: 5.09s\n",
      "632:\tlearn: 0.1429463\ttotal: 48.8s\tremaining: 5.01s\n",
      "633:\tlearn: 0.1429436\ttotal: 48.9s\tremaining: 4.93s\n",
      "634:\tlearn: 0.1429422\ttotal: 49s\tremaining: 4.86s\n",
      "635:\tlearn: 0.1429400\ttotal: 49s\tremaining: 4.78s\n",
      "636:\tlearn: 0.1429388\ttotal: 49.1s\tremaining: 4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637:\tlearn: 0.1429375\ttotal: 49.2s\tremaining: 4.63s\n",
      "638:\tlearn: 0.1429368\ttotal: 49.3s\tremaining: 4.55s\n",
      "639:\tlearn: 0.1429353\ttotal: 49.4s\tremaining: 4.47s\n",
      "640:\tlearn: 0.1429345\ttotal: 49.4s\tremaining: 4.39s\n",
      "641:\tlearn: 0.1429335\ttotal: 49.5s\tremaining: 4.32s\n",
      "642:\tlearn: 0.1429321\ttotal: 49.6s\tremaining: 4.24s\n",
      "643:\tlearn: 0.1429300\ttotal: 49.7s\tremaining: 4.16s\n",
      "644:\tlearn: 0.1429279\ttotal: 49.7s\tremaining: 4.09s\n",
      "645:\tlearn: 0.1429261\ttotal: 49.8s\tremaining: 4.01s\n",
      "646:\tlearn: 0.1429238\ttotal: 49.9s\tremaining: 3.93s\n",
      "647:\tlearn: 0.1429215\ttotal: 50s\tremaining: 3.86s\n",
      "648:\tlearn: 0.1429199\ttotal: 50s\tremaining: 3.78s\n",
      "649:\tlearn: 0.1429188\ttotal: 50.1s\tremaining: 3.7s\n",
      "650:\tlearn: 0.1429164\ttotal: 50.2s\tremaining: 3.62s\n",
      "651:\tlearn: 0.1429146\ttotal: 50.3s\tremaining: 3.55s\n",
      "652:\tlearn: 0.1429127\ttotal: 50.4s\tremaining: 3.47s\n",
      "653:\tlearn: 0.1429114\ttotal: 50.4s\tremaining: 3.39s\n",
      "654:\tlearn: 0.1429098\ttotal: 50.5s\tremaining: 3.31s\n",
      "655:\tlearn: 0.1429078\ttotal: 50.6s\tremaining: 3.24s\n",
      "656:\tlearn: 0.1429058\ttotal: 50.6s\tremaining: 3.16s\n",
      "657:\tlearn: 0.1429046\ttotal: 50.7s\tremaining: 3.08s\n",
      "658:\tlearn: 0.1429033\ttotal: 50.8s\tremaining: 3s\n",
      "659:\tlearn: 0.1429022\ttotal: 50.9s\tremaining: 2.93s\n",
      "660:\tlearn: 0.1429013\ttotal: 50.9s\tremaining: 2.85s\n",
      "661:\tlearn: 0.1428992\ttotal: 51s\tremaining: 2.77s\n",
      "662:\tlearn: 0.1428980\ttotal: 51.1s\tremaining: 2.69s\n",
      "663:\tlearn: 0.1428966\ttotal: 51.1s\tremaining: 2.62s\n",
      "664:\tlearn: 0.1428954\ttotal: 51.2s\tremaining: 2.54s\n",
      "665:\tlearn: 0.1428947\ttotal: 51.3s\tremaining: 2.46s\n",
      "666:\tlearn: 0.1428928\ttotal: 51.4s\tremaining: 2.39s\n",
      "667:\tlearn: 0.1428906\ttotal: 51.4s\tremaining: 2.31s\n",
      "668:\tlearn: 0.1428900\ttotal: 51.5s\tremaining: 2.23s\n",
      "669:\tlearn: 0.1428882\ttotal: 51.6s\tremaining: 2.16s\n",
      "670:\tlearn: 0.1428859\ttotal: 51.7s\tremaining: 2.08s\n",
      "671:\tlearn: 0.1428838\ttotal: 51.7s\tremaining: 2s\n",
      "672:\tlearn: 0.1428829\ttotal: 51.8s\tremaining: 1.92s\n",
      "673:\tlearn: 0.1428809\ttotal: 51.9s\tremaining: 1.85s\n",
      "674:\tlearn: 0.1428798\ttotal: 52s\tremaining: 1.77s\n",
      "675:\tlearn: 0.1428791\ttotal: 52s\tremaining: 1.69s\n",
      "676:\tlearn: 0.1428773\ttotal: 52.1s\tremaining: 1.62s\n",
      "677:\tlearn: 0.1428763\ttotal: 52.2s\tremaining: 1.54s\n",
      "678:\tlearn: 0.1428750\ttotal: 52.2s\tremaining: 1.46s\n",
      "679:\tlearn: 0.1428734\ttotal: 52.3s\tremaining: 1.39s\n",
      "680:\tlearn: 0.1428724\ttotal: 52.4s\tremaining: 1.31s\n",
      "681:\tlearn: 0.1428709\ttotal: 52.5s\tremaining: 1.23s\n",
      "682:\tlearn: 0.1428685\ttotal: 52.5s\tremaining: 1.15s\n",
      "683:\tlearn: 0.1428650\ttotal: 52.6s\tremaining: 1.08s\n",
      "684:\tlearn: 0.1428628\ttotal: 52.7s\tremaining: 1s\n",
      "685:\tlearn: 0.1428607\ttotal: 52.8s\tremaining: 923ms\n",
      "686:\tlearn: 0.1428597\ttotal: 52.8s\tremaining: 846ms\n",
      "687:\tlearn: 0.1428580\ttotal: 52.9s\tremaining: 769ms\n",
      "688:\tlearn: 0.1428563\ttotal: 53s\tremaining: 692ms\n",
      "689:\tlearn: 0.1428552\ttotal: 53.1s\tremaining: 615ms\n",
      "690:\tlearn: 0.1428544\ttotal: 53.1s\tremaining: 538ms\n",
      "691:\tlearn: 0.1428535\ttotal: 53.2s\tremaining: 461ms\n",
      "692:\tlearn: 0.1428522\ttotal: 53.3s\tremaining: 384ms\n",
      "693:\tlearn: 0.1428507\ttotal: 53.4s\tremaining: 308ms\n",
      "694:\tlearn: 0.1428494\ttotal: 53.4s\tremaining: 231ms\n",
      "695:\tlearn: 0.1428469\ttotal: 53.5s\tremaining: 154ms\n",
      "696:\tlearn: 0.1428452\ttotal: 53.6s\tremaining: 76.9ms\n",
      "697:\tlearn: 0.1428432\ttotal: 53.7s\tremaining: 0us\n",
      "Финальный ROC-AUC: 0.7006790899890878\n"
     ]
    }
   ],
   "source": [
    "# Тестируем на CatBoostClassifier, подбирая параметры с помощью optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,\n",
    "        'class_weights': class_weights_dict\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "final_preds = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, final_preds)\n",
    "print(\"Финальный ROC-AUC:\", final_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215daeb",
   "metadata": {},
   "source": [
    "Итог 0.7006790899890878"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899146d",
   "metadata": {},
   "source": [
    "### Эксперимент 2\n",
    "Здесь мы попробуем не преобразовывать признаки и аггрегировать их как есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0318244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем данные\n",
    "df = pd.read_parquet(\"train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5adbc2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'rn', 'pre_since_opened', 'pre_since_confirmed', 'pre_pterm',\n",
       "       'pre_fterm', 'pre_till_pclose', 'pre_till_fclose',\n",
       "       'pre_loans_credit_limit', 'pre_loans_next_pay_summ',\n",
       "       'pre_loans_outstanding', 'pre_loans_total_overdue',\n",
       "       'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_loans5',\n",
       "       'pre_loans530', 'pre_loans3060', 'pre_loans6090', 'pre_loans90',\n",
       "       'is_zero_loans5', 'is_zero_loans530', 'is_zero_loans3060',\n",
       "       'is_zero_loans6090', 'is_zero_loans90', 'pre_util', 'pre_over2limit',\n",
       "       'pre_maxover2limit', 'is_zero_util', 'is_zero_over2limit',\n",
       "       'is_zero_maxover2limit', 'enc_paym_0', 'enc_paym_1', 'enc_paym_2',\n",
       "       'enc_paym_3', 'enc_paym_4', 'enc_paym_5', 'enc_paym_6', 'enc_paym_7',\n",
       "       'enc_paym_8', 'enc_paym_9', 'enc_paym_10', 'enc_paym_11', 'enc_paym_12',\n",
       "       'enc_paym_13', 'enc_paym_14', 'enc_paym_15', 'enc_paym_16',\n",
       "       'enc_paym_17', 'enc_paym_18', 'enc_paym_19', 'enc_paym_20',\n",
       "       'enc_paym_21', 'enc_paym_22', 'enc_paym_23', 'enc_paym_24',\n",
       "       'enc_loans_account_holder_type', 'enc_loans_credit_status',\n",
       "       'enc_loans_credit_type', 'enc_loans_account_cur', 'pclose_flag',\n",
       "       'fclose_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем аггрегации и группируем\n",
    "aggregations = {\n",
    "    'rn': 'max', \n",
    "    'pre_since_opened': 'median',\n",
    "    'pre_since_confirmed': 'median', \n",
    "    'pre_pterm': 'median',\n",
    "    'pre_fterm': 'median',\n",
    "    'pre_till_pclose': 'median',\n",
    "    'pre_till_fclose': 'median',\n",
    "    'pre_loans_credit_limit': 'median',\n",
    "    'pre_loans_next_pay_summ': 'median',\n",
    "    'pre_loans_outstanding': 'median',\n",
    "    'pre_loans_total_overdue': 'median',\n",
    "    'pre_loans_max_overdue_sum': 'median',\n",
    "    'pre_loans_credit_cost_rate': 'median',\n",
    "    'pre_loans5': 'median',\n",
    "    'pre_loans530': 'median',\n",
    "    'pre_loans3060': 'median',\n",
    "    'pre_loans6090': 'median',\n",
    "    'pre_loans90': 'median',\n",
    "    'is_zero_loans5': 'mean',\n",
    "    'is_zero_loans530': 'mean',\n",
    "    'is_zero_loans3060': 'mean',\n",
    "    'is_zero_loans6090': 'mean',\n",
    "    'is_zero_loans90': 'mean',\n",
    "    'pre_util': 'median',\n",
    "    'pre_over2limit': 'median',\n",
    "    'pre_maxover2limit': 'median',\n",
    "    'is_zero_util': 'mean',\n",
    "    'is_zero_over2limit': 'mean',\n",
    "    'is_zero_maxover2limit': 'mean',\n",
    "    'enc_loans_account_holder_type': 'median',\n",
    "    'enc_loans_credit_status': 'median',\n",
    "    'enc_loans_account_cur': 'median',\n",
    "    'enc_loans_credit_type': 'median',\n",
    "    'pclose_flag': 'median',\n",
    "    'fclose_flag': 'median',\n",
    "    'enc_paym_0': 'median',\n",
    "    'enc_paym_1': 'median',\n",
    "    'enc_paym_2': 'median',\n",
    "    'enc_paym_3': 'median',\n",
    "    'enc_paym_4': 'median',\n",
    "    'enc_paym_5': 'median',\n",
    "    'enc_paym_6': 'median',\n",
    "    'enc_paym_7': 'median',\n",
    "    'enc_paym_8': 'median',\n",
    "    'enc_paym_9': 'median',\n",
    "    'enc_paym_10': 'median',\n",
    "    'enc_paym_11': 'median',\n",
    "    'enc_paym_12': 'median',\n",
    "    'enc_paym_13': 'median',\n",
    "    'enc_paym_14': 'median',\n",
    "    'enc_paym_15': 'median',\n",
    "    'enc_paym_16': 'median',\n",
    "    'enc_paym_17': 'median',\n",
    "    'enc_paym_18': 'median',\n",
    "    'enc_paym_19': 'median',\n",
    "    'enc_paym_20': 'median',\n",
    "    'enc_paym_21': 'median',\n",
    "    'enc_paym_22': 'median',\n",
    "    'enc_paym_23': 'median',\n",
    "    'enc_paym_24': 'median'\n",
    "}\n",
    "grouped_df = df.groupby('id').agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94339de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединяем с таргетом\n",
    "final_df = grouped_df.merge(train_target, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa7b124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_paym_16</th>\n",
       "      <th>enc_paym_17</th>\n",
       "      <th>enc_paym_18</th>\n",
       "      <th>enc_paym_19</th>\n",
       "      <th>enc_paym_20</th>\n",
       "      <th>enc_paym_21</th>\n",
       "      <th>enc_paym_22</th>\n",
       "      <th>enc_paym_23</th>\n",
       "      <th>enc_paym_24</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074279</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>-0.003865</td>\n",
       "      <td>-0.012971</td>\n",
       "      <td>-0.022741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010049</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rn</th>\n",
       "      <td>0.074279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022856</td>\n",
       "      <td>-0.011241</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>-0.016063</td>\n",
       "      <td>0.073501</td>\n",
       "      <td>-0.055806</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>-0.200790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158870</td>\n",
       "      <td>0.164487</td>\n",
       "      <td>0.170377</td>\n",
       "      <td>0.174816</td>\n",
       "      <td>0.176665</td>\n",
       "      <td>0.178037</td>\n",
       "      <td>0.179105</td>\n",
       "      <td>0.180341</td>\n",
       "      <td>0.158081</td>\n",
       "      <td>-0.014138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_since_opened</th>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.022856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015967</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>-0.032863</td>\n",
       "      <td>-0.054148</td>\n",
       "      <td>-0.006013</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035592</td>\n",
       "      <td>-0.044443</td>\n",
       "      <td>-0.046777</td>\n",
       "      <td>-0.043951</td>\n",
       "      <td>-0.039876</td>\n",
       "      <td>-0.036881</td>\n",
       "      <td>-0.037089</td>\n",
       "      <td>-0.040171</td>\n",
       "      <td>-0.038730</td>\n",
       "      <td>0.011584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <td>0.012538</td>\n",
       "      <td>-0.011241</td>\n",
       "      <td>-0.015967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025293</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.021289</td>\n",
       "      <td>-0.071005</td>\n",
       "      <td>-0.010780</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>-0.024848</td>\n",
       "      <td>-0.022593</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.019905</td>\n",
       "      <td>-0.018877</td>\n",
       "      <td>-0.017182</td>\n",
       "      <td>-0.015935</td>\n",
       "      <td>-0.006572</td>\n",
       "      <td>-0.006152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_pterm</th>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.025293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083474</td>\n",
       "      <td>0.275438</td>\n",
       "      <td>-0.071958</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>-0.058705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081110</td>\n",
       "      <td>0.084519</td>\n",
       "      <td>0.088255</td>\n",
       "      <td>0.092226</td>\n",
       "      <td>0.093451</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.095662</td>\n",
       "      <td>0.096543</td>\n",
       "      <td>0.046033</td>\n",
       "      <td>-0.007316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_paym_21</th>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.178037</td>\n",
       "      <td>-0.036881</td>\n",
       "      <td>-0.018877</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>-0.100247</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>-0.017802</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>-0.030261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>0.790044</td>\n",
       "      <td>0.841635</td>\n",
       "      <td>0.893177</td>\n",
       "      <td>0.943114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942422</td>\n",
       "      <td>0.890901</td>\n",
       "      <td>0.668388</td>\n",
       "      <td>0.023949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_paym_22</th>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.179105</td>\n",
       "      <td>-0.037089</td>\n",
       "      <td>-0.017182</td>\n",
       "      <td>0.095662</td>\n",
       "      <td>-0.093724</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>-0.018339</td>\n",
       "      <td>0.037563</td>\n",
       "      <td>-0.030415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705873</td>\n",
       "      <td>0.749616</td>\n",
       "      <td>0.798934</td>\n",
       "      <td>0.847878</td>\n",
       "      <td>0.894455</td>\n",
       "      <td>0.942422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939453</td>\n",
       "      <td>0.705367</td>\n",
       "      <td>0.022085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_paym_23</th>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.180341</td>\n",
       "      <td>-0.040171</td>\n",
       "      <td>-0.015935</td>\n",
       "      <td>0.096543</td>\n",
       "      <td>-0.086521</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>-0.018804</td>\n",
       "      <td>0.036420</td>\n",
       "      <td>-0.031091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666947</td>\n",
       "      <td>0.708543</td>\n",
       "      <td>0.755604</td>\n",
       "      <td>0.802060</td>\n",
       "      <td>0.846045</td>\n",
       "      <td>0.890901</td>\n",
       "      <td>0.939453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747841</td>\n",
       "      <td>0.020732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_paym_24</th>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.158081</td>\n",
       "      <td>-0.038730</td>\n",
       "      <td>-0.006572</td>\n",
       "      <td>0.046033</td>\n",
       "      <td>-0.041839</td>\n",
       "      <td>-0.061665</td>\n",
       "      <td>-0.006396</td>\n",
       "      <td>0.023948</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496182</td>\n",
       "      <td>0.527952</td>\n",
       "      <td>0.564167</td>\n",
       "      <td>0.599843</td>\n",
       "      <td>0.633579</td>\n",
       "      <td>0.668388</td>\n",
       "      <td>0.705367</td>\n",
       "      <td>0.747841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.014138</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.013389</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>0.030328</td>\n",
       "      <td>0.028888</td>\n",
       "      <td>0.027337</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>0.020732</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id        rn  pre_since_opened  \\\n",
       "id                   1.000000  0.074279          0.041197   \n",
       "rn                   0.074279  1.000000          0.022856   \n",
       "pre_since_opened     0.041197  0.022856          1.000000   \n",
       "pre_since_confirmed  0.012538 -0.011241         -0.015967   \n",
       "pre_pterm            0.012521  0.027872          0.000199   \n",
       "...                       ...       ...               ...   \n",
       "enc_paym_21          0.010184  0.178037         -0.036881   \n",
       "enc_paym_22          0.012385  0.179105         -0.037089   \n",
       "enc_paym_23          0.013781  0.180341         -0.040171   \n",
       "enc_paym_24         -0.010858  0.158081         -0.038730   \n",
       "flag                -0.000037 -0.014138          0.011584   \n",
       "\n",
       "                     pre_since_confirmed  pre_pterm  pre_fterm  \\\n",
       "id                              0.012538   0.012521   0.008800   \n",
       "rn                             -0.011241   0.027872  -0.016063   \n",
       "pre_since_opened               -0.015967   0.000199   0.018226   \n",
       "pre_since_confirmed             1.000000  -0.025293   0.016467   \n",
       "pre_pterm                      -0.025293   1.000000   0.083474   \n",
       "...                                  ...        ...        ...   \n",
       "enc_paym_21                    -0.018877   0.094822  -0.100247   \n",
       "enc_paym_22                    -0.017182   0.095662  -0.093724   \n",
       "enc_paym_23                    -0.015935   0.096543  -0.086521   \n",
       "enc_paym_24                    -0.006572   0.046033  -0.041839   \n",
       "flag                           -0.006152  -0.007316  -0.013389   \n",
       "\n",
       "                     pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "id                          0.014166        -0.003865               -0.012971   \n",
       "rn                          0.073501        -0.055806                0.016918   \n",
       "pre_since_opened           -0.032863        -0.054148               -0.006013   \n",
       "pre_since_confirmed         0.021289        -0.071005               -0.010780   \n",
       "pre_pterm                   0.275438        -0.071958                0.016123   \n",
       "...                              ...              ...                     ...   \n",
       "enc_paym_21                 0.002081        -0.017802                0.039268   \n",
       "enc_paym_22                 0.002365        -0.018339                0.037563   \n",
       "enc_paym_23                 0.002936        -0.018804                0.036420   \n",
       "enc_paym_24                -0.061665        -0.006396                0.023948   \n",
       "flag                        0.003658         0.002761                0.019402   \n",
       "\n",
       "                     pre_loans_next_pay_summ  ...  enc_paym_16  enc_paym_17  \\\n",
       "id                                 -0.022741  ...    -0.010049    -0.005368   \n",
       "rn                                 -0.200790  ...     0.158870     0.164487   \n",
       "pre_since_opened                    0.005154  ...    -0.035592    -0.044443   \n",
       "pre_since_confirmed                 0.006327  ...    -0.026685    -0.024848   \n",
       "pre_pterm                          -0.058705  ...     0.081110     0.084519   \n",
       "...                                      ...  ...          ...          ...   \n",
       "enc_paym_21                        -0.030261  ...     0.744141     0.790044   \n",
       "enc_paym_22                        -0.030415  ...     0.705873     0.749616   \n",
       "enc_paym_23                        -0.031091  ...     0.666947     0.708543   \n",
       "enc_paym_24                         0.015017  ...     0.496182     0.527952   \n",
       "flag                                0.007076  ...     0.031993     0.030328   \n",
       "\n",
       "                     enc_paym_18  enc_paym_19  enc_paym_20  enc_paym_21  \\\n",
       "id                     -0.001678     0.003597     0.007220     0.010184   \n",
       "rn                      0.170377     0.174816     0.176665     0.178037   \n",
       "pre_since_opened       -0.046777    -0.043951    -0.039876    -0.036881   \n",
       "pre_since_confirmed    -0.022593    -0.021504    -0.019905    -0.018877   \n",
       "pre_pterm               0.088255     0.092226     0.093451     0.094822   \n",
       "...                          ...          ...          ...          ...   \n",
       "enc_paym_21             0.841635     0.893177     0.943114     1.000000   \n",
       "enc_paym_22             0.798934     0.847878     0.894455     0.942422   \n",
       "enc_paym_23             0.755604     0.802060     0.846045     0.890901   \n",
       "enc_paym_24             0.564167     0.599843     0.633579     0.668388   \n",
       "flag                    0.028888     0.027337     0.025761     0.023949   \n",
       "\n",
       "                     enc_paym_22  enc_paym_23  enc_paym_24      flag  \n",
       "id                      0.012385     0.013781    -0.010858 -0.000037  \n",
       "rn                      0.179105     0.180341     0.158081 -0.014138  \n",
       "pre_since_opened       -0.037089    -0.040171    -0.038730  0.011584  \n",
       "pre_since_confirmed    -0.017182    -0.015935    -0.006572 -0.006152  \n",
       "pre_pterm               0.095662     0.096543     0.046033 -0.007316  \n",
       "...                          ...          ...          ...       ...  \n",
       "enc_paym_21             0.942422     0.890901     0.668388  0.023949  \n",
       "enc_paym_22             1.000000     0.939453     0.705367  0.022085  \n",
       "enc_paym_23             0.939453     1.000000     0.747841  0.020732  \n",
       "enc_paym_24             0.705367     0.747841     1.000000  0.011932  \n",
       "flag                    0.022085     0.020732     0.011932  1.000000  \n",
       "\n",
       "[62 rows x 62 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb284d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enc_paym_21        enc_paym_20          0.943114\n",
       "enc_paym_20        enc_paym_21          0.943114\n",
       "enc_paym_22        enc_paym_21          0.942422\n",
       "enc_paym_21        enc_paym_22          0.942422\n",
       "enc_paym_20        enc_paym_19          0.940890\n",
       "                                          ...   \n",
       "enc_paym_12        enc_paym_18          0.609364\n",
       "enc_paym_13        enc_paym_21          0.601151\n",
       "enc_paym_21        enc_paym_13          0.601151\n",
       "pre_over2limit     pre_maxover2limit   -0.631950\n",
       "pre_maxover2limit  pre_over2limit      -0.631950\n",
       "Length: 194, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотрим кореляции\n",
    "correlation_matrix = final_df.corr()\n",
    "correlation_pairs = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "correlation_pairs = correlation_pairs[abs(correlation_pairs) < 1]\n",
    "high_correlation = correlation_pairs[abs(correlation_pairs) > 0.6]\n",
    "high_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0877848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pre_fterm                pre_till_fclose            0.000979\n",
       "pre_till_fclose          pre_fterm                  0.000979\n",
       "pre_till_pclose          enc_paym_17                0.000970\n",
       "enc_paym_17              pre_till_pclose            0.000970\n",
       "pre_fterm                pre_over2limit             0.000908\n",
       "                                                      ...   \n",
       "enc_paym_8               pre_loans6090             -0.000920\n",
       "pre_loans3060            pre_loans_next_pay_summ   -0.000953\n",
       "pre_loans_next_pay_summ  pre_loans3060             -0.000953\n",
       "is_zero_over2limit       enc_paym_11               -0.000987\n",
       "enc_paym_11              is_zero_over2limit        -0.000987\n",
       "Length: 224, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = final_df.corr()\n",
    "correlation_pairs = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "correlation_pairs = correlation_pairs[abs(correlation_pairs) < 1]\n",
    "high_correlation = correlation_pairs[abs(correlation_pairs) < 0.001]\n",
    "high_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59bb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем значения на X, y, train/test и стандартизируем их.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = final_df.drop(columns=['id', 'flag'])\n",
    "y = final_df['flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63951e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-18 09:36:23,008] A new study created in memory with name: no-name-fb66f60f-4550-4aa8-8562-646804c8bbe6\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:36:37,182] Trial 0 finished with value: 0.7123013943772616 and parameters: {'iterations': 885, 'learning_rate': 0.014473890036877704, 'depth': 8, 'l2_leaf_reg': 3}. Best is trial 0 with value: 0.7123013943772616.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:36:38,471] Trial 1 finished with value: 0.6586982355258011 and parameters: {'iterations': 824, 'learning_rate': 0.00024202791798047022, 'depth': 4, 'l2_leaf_reg': 10}. Best is trial 0 with value: 0.7123013943772616.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:36:43,414] Trial 2 finished with value: 0.6869810051453749 and parameters: {'iterations': 322, 'learning_rate': 0.0024215696794583057, 'depth': 7, 'l2_leaf_reg': 1}. Best is trial 0 with value: 0.7123013943772616.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:36:45,896] Trial 3 finished with value: 0.6843587086721049 and parameters: {'iterations': 353, 'learning_rate': 0.0001423505791138325, 'depth': 10, 'l2_leaf_reg': 9}. Best is trial 0 with value: 0.7123013943772616.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:36:54,675] Trial 4 finished with value: 0.6974008917187339 and parameters: {'iterations': 326, 'learning_rate': 0.003944928571048856, 'depth': 10, 'l2_leaf_reg': 1}. Best is trial 0 with value: 0.7123013943772616.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:37:00,428] Trial 5 finished with value: 0.7133815472023208 and parameters: {'iterations': 488, 'learning_rate': 0.05679288047940864, 'depth': 6, 'l2_leaf_reg': 8}. Best is trial 5 with value: 0.7133815472023208.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:37:08,016] Trial 6 finished with value: 0.7120243913805985 and parameters: {'iterations': 761, 'learning_rate': 0.06708235713817075, 'depth': 10, 'l2_leaf_reg': 10}. Best is trial 5 with value: 0.7133815472023208.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:37:15,064] Trial 7 finished with value: 0.7144303873103413 and parameters: {'iterations': 724, 'learning_rate': 0.07818926354409358, 'depth': 7, 'l2_leaf_reg': 3}. Best is trial 7 with value: 0.7144303873103413.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:37:17,698] Trial 8 finished with value: 0.6921992014853043 and parameters: {'iterations': 172, 'learning_rate': 0.010890478463693658, 'depth': 6, 'l2_leaf_reg': 6}. Best is trial 7 with value: 0.7144303873103413.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3580\\3746832561.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-09-18 09:37:22,023] Trial 9 finished with value: 0.6785687242034522 and parameters: {'iterations': 335, 'learning_rate': 0.0007204964380995159, 'depth': 6, 'l2_leaf_reg': 8}. Best is trial 7 with value: 0.7144303873103413.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'iterations': 724, 'learning_rate': 0.07818926354409358, 'depth': 7, 'l2_leaf_reg': 3}\n",
      "Лучший ROC-AUC: 0.7144303873103413\n",
      "0:\tlearn: 0.5794777\ttotal: 68.7ms\tremaining: 49.7s\n",
      "1:\tlearn: 0.4897011\ttotal: 146ms\tremaining: 52.6s\n",
      "2:\tlearn: 0.4186237\ttotal: 206ms\tremaining: 49.5s\n",
      "3:\tlearn: 0.3631414\ttotal: 282ms\tremaining: 50.7s\n",
      "4:\tlearn: 0.3197851\ttotal: 339ms\tremaining: 48.7s\n",
      "5:\tlearn: 0.2859382\ttotal: 405ms\tremaining: 48.5s\n",
      "6:\tlearn: 0.2593207\ttotal: 463ms\tremaining: 47.5s\n",
      "7:\tlearn: 0.2373601\ttotal: 531ms\tremaining: 47.5s\n",
      "8:\tlearn: 0.2202377\ttotal: 604ms\tremaining: 48s\n",
      "9:\tlearn: 0.2065585\ttotal: 670ms\tremaining: 47.8s\n",
      "10:\tlearn: 0.1956329\ttotal: 741ms\tremaining: 48s\n",
      "11:\tlearn: 0.1868164\ttotal: 821ms\tremaining: 48.7s\n",
      "12:\tlearn: 0.1801330\ttotal: 881ms\tremaining: 48.2s\n",
      "13:\tlearn: 0.1743282\ttotal: 956ms\tremaining: 48.5s\n",
      "14:\tlearn: 0.1693701\ttotal: 1.03s\tremaining: 48.6s\n",
      "15:\tlearn: 0.1654155\ttotal: 1.09s\tremaining: 48.3s\n",
      "16:\tlearn: 0.1621179\ttotal: 1.16s\tremaining: 48.2s\n",
      "17:\tlearn: 0.1594387\ttotal: 1.23s\tremaining: 48.1s\n",
      "18:\tlearn: 0.1572897\ttotal: 1.3s\tremaining: 48.3s\n",
      "19:\tlearn: 0.1553279\ttotal: 1.38s\tremaining: 48.4s\n",
      "20:\tlearn: 0.1537161\ttotal: 1.45s\tremaining: 48.5s\n",
      "21:\tlearn: 0.1524118\ttotal: 1.52s\tremaining: 48.6s\n",
      "22:\tlearn: 0.1513797\ttotal: 1.59s\tremaining: 48.6s\n",
      "23:\tlearn: 0.1504223\ttotal: 1.67s\tremaining: 48.6s\n",
      "24:\tlearn: 0.1496232\ttotal: 1.74s\tremaining: 48.5s\n",
      "25:\tlearn: 0.1489435\ttotal: 1.81s\tremaining: 48.6s\n",
      "26:\tlearn: 0.1483492\ttotal: 1.89s\tremaining: 48.7s\n",
      "27:\tlearn: 0.1478490\ttotal: 1.96s\tremaining: 48.7s\n",
      "28:\tlearn: 0.1474531\ttotal: 2.02s\tremaining: 48.5s\n",
      "29:\tlearn: 0.1470918\ttotal: 2.09s\tremaining: 48.4s\n",
      "30:\tlearn: 0.1468028\ttotal: 2.16s\tremaining: 48.3s\n",
      "31:\tlearn: 0.1465244\ttotal: 2.23s\tremaining: 48.2s\n",
      "32:\tlearn: 0.1462412\ttotal: 2.31s\tremaining: 48.4s\n",
      "33:\tlearn: 0.1460102\ttotal: 2.38s\tremaining: 48.3s\n",
      "34:\tlearn: 0.1458097\ttotal: 2.45s\tremaining: 48.3s\n",
      "35:\tlearn: 0.1456059\ttotal: 2.53s\tremaining: 48.3s\n",
      "36:\tlearn: 0.1454581\ttotal: 2.6s\tremaining: 48.2s\n",
      "37:\tlearn: 0.1453147\ttotal: 2.67s\tremaining: 48.2s\n",
      "38:\tlearn: 0.1451867\ttotal: 2.74s\tremaining: 48.2s\n",
      "39:\tlearn: 0.1450859\ttotal: 2.81s\tremaining: 48.1s\n",
      "40:\tlearn: 0.1449826\ttotal: 2.88s\tremaining: 48s\n",
      "41:\tlearn: 0.1449125\ttotal: 2.95s\tremaining: 47.9s\n",
      "42:\tlearn: 0.1448243\ttotal: 3.02s\tremaining: 47.9s\n",
      "43:\tlearn: 0.1447594\ttotal: 3.1s\tremaining: 47.9s\n",
      "44:\tlearn: 0.1446741\ttotal: 3.17s\tremaining: 47.9s\n",
      "45:\tlearn: 0.1446002\ttotal: 3.25s\tremaining: 47.9s\n",
      "46:\tlearn: 0.1445326\ttotal: 3.33s\tremaining: 47.9s\n",
      "47:\tlearn: 0.1444893\ttotal: 3.4s\tremaining: 47.9s\n",
      "48:\tlearn: 0.1444125\ttotal: 3.48s\tremaining: 47.9s\n",
      "49:\tlearn: 0.1443620\ttotal: 3.55s\tremaining: 47.8s\n",
      "50:\tlearn: 0.1443060\ttotal: 3.62s\tremaining: 47.8s\n",
      "51:\tlearn: 0.1442730\ttotal: 3.69s\tremaining: 47.7s\n",
      "52:\tlearn: 0.1442242\ttotal: 3.76s\tremaining: 47.7s\n",
      "53:\tlearn: 0.1441870\ttotal: 3.84s\tremaining: 47.6s\n",
      "54:\tlearn: 0.1441463\ttotal: 3.91s\tremaining: 47.6s\n",
      "55:\tlearn: 0.1441047\ttotal: 3.99s\tremaining: 47.6s\n",
      "56:\tlearn: 0.1440636\ttotal: 4.06s\tremaining: 47.5s\n",
      "57:\tlearn: 0.1440358\ttotal: 4.13s\tremaining: 47.4s\n",
      "58:\tlearn: 0.1439920\ttotal: 4.2s\tremaining: 47.3s\n",
      "59:\tlearn: 0.1439603\ttotal: 4.28s\tremaining: 47.3s\n",
      "60:\tlearn: 0.1439366\ttotal: 4.35s\tremaining: 47.3s\n",
      "61:\tlearn: 0.1439055\ttotal: 4.42s\tremaining: 47.2s\n",
      "62:\tlearn: 0.1438802\ttotal: 4.49s\tremaining: 47.1s\n",
      "63:\tlearn: 0.1438553\ttotal: 4.56s\tremaining: 47s\n",
      "64:\tlearn: 0.1438244\ttotal: 4.63s\tremaining: 46.9s\n",
      "65:\tlearn: 0.1438055\ttotal: 4.69s\tremaining: 46.8s\n",
      "66:\tlearn: 0.1437864\ttotal: 4.76s\tremaining: 46.7s\n",
      "67:\tlearn: 0.1437571\ttotal: 4.83s\tremaining: 46.6s\n",
      "68:\tlearn: 0.1437272\ttotal: 4.9s\tremaining: 46.5s\n",
      "69:\tlearn: 0.1437119\ttotal: 4.97s\tremaining: 46.4s\n",
      "70:\tlearn: 0.1436937\ttotal: 5.03s\tremaining: 46.3s\n",
      "71:\tlearn: 0.1436686\ttotal: 5.11s\tremaining: 46.3s\n",
      "72:\tlearn: 0.1436430\ttotal: 5.18s\tremaining: 46.2s\n",
      "73:\tlearn: 0.1436210\ttotal: 5.25s\tremaining: 46.2s\n",
      "74:\tlearn: 0.1435890\ttotal: 5.33s\tremaining: 46.1s\n",
      "75:\tlearn: 0.1435709\ttotal: 5.4s\tremaining: 46s\n",
      "76:\tlearn: 0.1435490\ttotal: 5.47s\tremaining: 46s\n",
      "77:\tlearn: 0.1435284\ttotal: 5.55s\tremaining: 46s\n",
      "78:\tlearn: 0.1435059\ttotal: 5.63s\tremaining: 46s\n",
      "79:\tlearn: 0.1434740\ttotal: 5.7s\tremaining: 45.9s\n",
      "80:\tlearn: 0.1434532\ttotal: 5.77s\tremaining: 45.8s\n",
      "81:\tlearn: 0.1434360\ttotal: 5.84s\tremaining: 45.7s\n",
      "82:\tlearn: 0.1434216\ttotal: 5.91s\tremaining: 45.6s\n",
      "83:\tlearn: 0.1434063\ttotal: 5.97s\tremaining: 45.5s\n",
      "84:\tlearn: 0.1433839\ttotal: 6.05s\tremaining: 45.5s\n",
      "85:\tlearn: 0.1433649\ttotal: 6.12s\tremaining: 45.4s\n",
      "86:\tlearn: 0.1433495\ttotal: 6.19s\tremaining: 45.4s\n",
      "87:\tlearn: 0.1433361\ttotal: 6.27s\tremaining: 45.3s\n",
      "88:\tlearn: 0.1433220\ttotal: 6.34s\tremaining: 45.2s\n",
      "89:\tlearn: 0.1433032\ttotal: 6.41s\tremaining: 45.1s\n",
      "90:\tlearn: 0.1432876\ttotal: 6.47s\tremaining: 45s\n",
      "91:\tlearn: 0.1432762\ttotal: 6.54s\tremaining: 44.9s\n",
      "92:\tlearn: 0.1432612\ttotal: 6.61s\tremaining: 44.8s\n",
      "93:\tlearn: 0.1432443\ttotal: 6.68s\tremaining: 44.8s\n",
      "94:\tlearn: 0.1432183\ttotal: 6.75s\tremaining: 44.7s\n",
      "95:\tlearn: 0.1432074\ttotal: 6.83s\tremaining: 44.7s\n",
      "96:\tlearn: 0.1431990\ttotal: 6.9s\tremaining: 44.6s\n",
      "97:\tlearn: 0.1431786\ttotal: 6.97s\tremaining: 44.5s\n",
      "98:\tlearn: 0.1431638\ttotal: 7.05s\tremaining: 44.5s\n",
      "99:\tlearn: 0.1431531\ttotal: 7.12s\tremaining: 44.4s\n",
      "100:\tlearn: 0.1431401\ttotal: 7.18s\tremaining: 44.3s\n",
      "101:\tlearn: 0.1431267\ttotal: 7.26s\tremaining: 44.3s\n",
      "102:\tlearn: 0.1431155\ttotal: 7.32s\tremaining: 44.2s\n",
      "103:\tlearn: 0.1430982\ttotal: 7.39s\tremaining: 44.1s\n",
      "104:\tlearn: 0.1430855\ttotal: 7.46s\tremaining: 44s\n",
      "105:\tlearn: 0.1430706\ttotal: 7.53s\tremaining: 43.9s\n",
      "106:\tlearn: 0.1430624\ttotal: 7.59s\tremaining: 43.8s\n",
      "107:\tlearn: 0.1430490\ttotal: 7.66s\tremaining: 43.7s\n",
      "108:\tlearn: 0.1430323\ttotal: 7.73s\tremaining: 43.6s\n",
      "109:\tlearn: 0.1430230\ttotal: 7.79s\tremaining: 43.5s\n",
      "110:\tlearn: 0.1430123\ttotal: 7.87s\tremaining: 43.5s\n",
      "111:\tlearn: 0.1430037\ttotal: 7.93s\tremaining: 43.4s\n",
      "112:\tlearn: 0.1429911\ttotal: 8.01s\tremaining: 43.3s\n",
      "113:\tlearn: 0.1429802\ttotal: 8.07s\tremaining: 43.2s\n",
      "114:\tlearn: 0.1429664\ttotal: 8.15s\tremaining: 43.1s\n",
      "115:\tlearn: 0.1429548\ttotal: 8.22s\tremaining: 43.1s\n",
      "116:\tlearn: 0.1429416\ttotal: 8.3s\tremaining: 43.1s\n",
      "117:\tlearn: 0.1429231\ttotal: 8.37s\tremaining: 43s\n",
      "118:\tlearn: 0.1429114\ttotal: 8.45s\tremaining: 42.9s\n",
      "119:\tlearn: 0.1428989\ttotal: 8.52s\tremaining: 42.9s\n",
      "120:\tlearn: 0.1428897\ttotal: 8.59s\tremaining: 42.8s\n",
      "121:\tlearn: 0.1428820\ttotal: 8.65s\tremaining: 42.7s\n",
      "122:\tlearn: 0.1428650\ttotal: 8.73s\tremaining: 42.7s\n",
      "123:\tlearn: 0.1428484\ttotal: 8.81s\tremaining: 42.6s\n",
      "124:\tlearn: 0.1428380\ttotal: 8.88s\tremaining: 42.5s\n",
      "125:\tlearn: 0.1428303\ttotal: 8.94s\tremaining: 42.5s\n",
      "126:\tlearn: 0.1428214\ttotal: 9.01s\tremaining: 42.4s\n",
      "127:\tlearn: 0.1428088\ttotal: 9.08s\tremaining: 42.3s\n",
      "128:\tlearn: 0.1427998\ttotal: 9.15s\tremaining: 42.2s\n",
      "129:\tlearn: 0.1427886\ttotal: 9.23s\tremaining: 42.2s\n",
      "130:\tlearn: 0.1427747\ttotal: 9.3s\tremaining: 42.1s\n",
      "131:\tlearn: 0.1427664\ttotal: 9.36s\tremaining: 42s\n",
      "132:\tlearn: 0.1427563\ttotal: 9.44s\tremaining: 41.9s\n",
      "133:\tlearn: 0.1427445\ttotal: 9.51s\tremaining: 41.9s\n",
      "134:\tlearn: 0.1427310\ttotal: 9.58s\tremaining: 41.8s\n",
      "135:\tlearn: 0.1427243\ttotal: 9.64s\tremaining: 41.7s\n",
      "136:\tlearn: 0.1427103\ttotal: 9.71s\tremaining: 41.6s\n",
      "137:\tlearn: 0.1426998\ttotal: 9.79s\tremaining: 41.6s\n",
      "138:\tlearn: 0.1426899\ttotal: 9.86s\tremaining: 41.5s\n",
      "139:\tlearn: 0.1426787\ttotal: 9.93s\tremaining: 41.4s\n",
      "140:\tlearn: 0.1426670\ttotal: 10s\tremaining: 41.4s\n",
      "141:\tlearn: 0.1426561\ttotal: 10.1s\tremaining: 41.3s\n",
      "142:\tlearn: 0.1426487\ttotal: 10.1s\tremaining: 41.2s\n",
      "143:\tlearn: 0.1426420\ttotal: 10.2s\tremaining: 41.2s\n",
      "144:\tlearn: 0.1426344\ttotal: 10.3s\tremaining: 41.1s\n",
      "145:\tlearn: 0.1426214\ttotal: 10.4s\tremaining: 41s\n",
      "146:\tlearn: 0.1426066\ttotal: 10.4s\tremaining: 41s\n",
      "147:\tlearn: 0.1425972\ttotal: 10.5s\tremaining: 40.9s\n",
      "148:\tlearn: 0.1425910\ttotal: 10.6s\tremaining: 40.8s\n",
      "149:\tlearn: 0.1425844\ttotal: 10.6s\tremaining: 40.7s\n",
      "150:\tlearn: 0.1425697\ttotal: 10.7s\tremaining: 40.7s\n",
      "151:\tlearn: 0.1425631\ttotal: 10.8s\tremaining: 40.6s\n",
      "152:\tlearn: 0.1425541\ttotal: 10.8s\tremaining: 40.5s\n",
      "153:\tlearn: 0.1425450\ttotal: 10.9s\tremaining: 40.4s\n",
      "154:\tlearn: 0.1425350\ttotal: 11s\tremaining: 40.4s\n",
      "155:\tlearn: 0.1425242\ttotal: 11.1s\tremaining: 40.3s\n",
      "156:\tlearn: 0.1425166\ttotal: 11.1s\tremaining: 40.2s\n",
      "157:\tlearn: 0.1425107\ttotal: 11.2s\tremaining: 40.1s\n",
      "158:\tlearn: 0.1425007\ttotal: 11.3s\tremaining: 40.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.1424903\ttotal: 11.4s\tremaining: 40s\n",
      "160:\tlearn: 0.1424834\ttotal: 11.4s\tremaining: 40s\n",
      "161:\tlearn: 0.1424760\ttotal: 11.5s\tremaining: 39.9s\n",
      "162:\tlearn: 0.1424696\ttotal: 11.6s\tremaining: 39.8s\n",
      "163:\tlearn: 0.1424589\ttotal: 11.6s\tremaining: 39.7s\n",
      "164:\tlearn: 0.1424520\ttotal: 11.7s\tremaining: 39.7s\n",
      "165:\tlearn: 0.1424463\ttotal: 11.8s\tremaining: 39.6s\n",
      "166:\tlearn: 0.1424368\ttotal: 11.8s\tremaining: 39.5s\n",
      "167:\tlearn: 0.1424302\ttotal: 11.9s\tremaining: 39.4s\n",
      "168:\tlearn: 0.1424197\ttotal: 12s\tremaining: 39.3s\n",
      "169:\tlearn: 0.1424131\ttotal: 12s\tremaining: 39.3s\n",
      "170:\tlearn: 0.1424080\ttotal: 12.1s\tremaining: 39.2s\n",
      "171:\tlearn: 0.1424014\ttotal: 12.2s\tremaining: 39.1s\n",
      "172:\tlearn: 0.1423957\ttotal: 12.3s\tremaining: 39s\n",
      "173:\tlearn: 0.1423907\ttotal: 12.3s\tremaining: 39s\n",
      "174:\tlearn: 0.1423830\ttotal: 12.4s\tremaining: 38.9s\n",
      "175:\tlearn: 0.1423703\ttotal: 12.5s\tremaining: 38.8s\n",
      "176:\tlearn: 0.1423633\ttotal: 12.5s\tremaining: 38.8s\n",
      "177:\tlearn: 0.1423590\ttotal: 12.6s\tremaining: 38.7s\n",
      "178:\tlearn: 0.1423467\ttotal: 12.7s\tremaining: 38.6s\n",
      "179:\tlearn: 0.1423378\ttotal: 12.8s\tremaining: 38.6s\n",
      "180:\tlearn: 0.1423326\ttotal: 12.8s\tremaining: 38.5s\n",
      "181:\tlearn: 0.1423178\ttotal: 12.9s\tremaining: 38.4s\n",
      "182:\tlearn: 0.1423110\ttotal: 13s\tremaining: 38.4s\n",
      "183:\tlearn: 0.1423009\ttotal: 13s\tremaining: 38.3s\n",
      "184:\tlearn: 0.1422859\ttotal: 13.1s\tremaining: 38.2s\n",
      "185:\tlearn: 0.1422772\ttotal: 13.2s\tremaining: 38.1s\n",
      "186:\tlearn: 0.1422642\ttotal: 13.3s\tremaining: 38.1s\n",
      "187:\tlearn: 0.1422565\ttotal: 13.3s\tremaining: 38s\n",
      "188:\tlearn: 0.1422463\ttotal: 13.4s\tremaining: 37.9s\n",
      "189:\tlearn: 0.1422367\ttotal: 13.5s\tremaining: 37.9s\n",
      "190:\tlearn: 0.1422266\ttotal: 13.5s\tremaining: 37.8s\n",
      "191:\tlearn: 0.1422164\ttotal: 13.6s\tremaining: 37.7s\n",
      "192:\tlearn: 0.1422060\ttotal: 13.7s\tremaining: 37.6s\n",
      "193:\tlearn: 0.1421969\ttotal: 13.7s\tremaining: 37.6s\n",
      "194:\tlearn: 0.1421907\ttotal: 13.8s\tremaining: 37.5s\n",
      "195:\tlearn: 0.1421833\ttotal: 13.9s\tremaining: 37.4s\n",
      "196:\tlearn: 0.1421710\ttotal: 13.9s\tremaining: 37.3s\n",
      "197:\tlearn: 0.1421622\ttotal: 14s\tremaining: 37.2s\n",
      "198:\tlearn: 0.1421507\ttotal: 14.1s\tremaining: 37.2s\n",
      "199:\tlearn: 0.1421440\ttotal: 14.2s\tremaining: 37.1s\n",
      "200:\tlearn: 0.1421329\ttotal: 14.2s\tremaining: 37.1s\n",
      "201:\tlearn: 0.1421247\ttotal: 14.3s\tremaining: 37s\n",
      "202:\tlearn: 0.1421180\ttotal: 14.4s\tremaining: 36.9s\n",
      "203:\tlearn: 0.1421085\ttotal: 14.5s\tremaining: 36.8s\n",
      "204:\tlearn: 0.1420963\ttotal: 14.5s\tremaining: 36.8s\n",
      "205:\tlearn: 0.1420896\ttotal: 14.6s\tremaining: 36.7s\n",
      "206:\tlearn: 0.1420851\ttotal: 14.7s\tremaining: 36.6s\n",
      "207:\tlearn: 0.1420791\ttotal: 14.7s\tremaining: 36.5s\n",
      "208:\tlearn: 0.1420737\ttotal: 14.8s\tremaining: 36.4s\n",
      "209:\tlearn: 0.1420685\ttotal: 14.8s\tremaining: 36.3s\n",
      "210:\tlearn: 0.1420589\ttotal: 14.9s\tremaining: 36.3s\n",
      "211:\tlearn: 0.1420463\ttotal: 15s\tremaining: 36.2s\n",
      "212:\tlearn: 0.1420410\ttotal: 15.1s\tremaining: 36.1s\n",
      "213:\tlearn: 0.1420295\ttotal: 15.1s\tremaining: 36.1s\n",
      "214:\tlearn: 0.1420214\ttotal: 15.2s\tremaining: 36s\n",
      "215:\tlearn: 0.1420119\ttotal: 15.3s\tremaining: 35.9s\n",
      "216:\tlearn: 0.1420069\ttotal: 15.3s\tremaining: 35.8s\n",
      "217:\tlearn: 0.1419963\ttotal: 15.4s\tremaining: 35.8s\n",
      "218:\tlearn: 0.1419860\ttotal: 15.5s\tremaining: 35.7s\n",
      "219:\tlearn: 0.1419797\ttotal: 15.6s\tremaining: 35.6s\n",
      "220:\tlearn: 0.1419702\ttotal: 15.6s\tremaining: 35.6s\n",
      "221:\tlearn: 0.1419621\ttotal: 15.7s\tremaining: 35.5s\n",
      "222:\tlearn: 0.1419552\ttotal: 15.8s\tremaining: 35.4s\n",
      "223:\tlearn: 0.1419457\ttotal: 15.8s\tremaining: 35.4s\n",
      "224:\tlearn: 0.1419411\ttotal: 15.9s\tremaining: 35.3s\n",
      "225:\tlearn: 0.1419355\ttotal: 16s\tremaining: 35.2s\n",
      "226:\tlearn: 0.1419302\ttotal: 16.1s\tremaining: 35.2s\n",
      "227:\tlearn: 0.1419217\ttotal: 16.1s\tremaining: 35.1s\n",
      "228:\tlearn: 0.1419153\ttotal: 16.2s\tremaining: 35s\n",
      "229:\tlearn: 0.1419064\ttotal: 16.3s\tremaining: 35s\n",
      "230:\tlearn: 0.1418971\ttotal: 16.4s\tremaining: 34.9s\n",
      "231:\tlearn: 0.1418884\ttotal: 16.4s\tremaining: 34.8s\n",
      "232:\tlearn: 0.1418819\ttotal: 16.5s\tremaining: 34.8s\n",
      "233:\tlearn: 0.1418749\ttotal: 16.6s\tremaining: 34.7s\n",
      "234:\tlearn: 0.1418675\ttotal: 16.6s\tremaining: 34.6s\n",
      "235:\tlearn: 0.1418574\ttotal: 16.7s\tremaining: 34.6s\n",
      "236:\tlearn: 0.1418460\ttotal: 16.8s\tremaining: 34.5s\n",
      "237:\tlearn: 0.1418374\ttotal: 16.9s\tremaining: 34.5s\n",
      "238:\tlearn: 0.1418321\ttotal: 16.9s\tremaining: 34.4s\n",
      "239:\tlearn: 0.1418275\ttotal: 17s\tremaining: 34.3s\n",
      "240:\tlearn: 0.1418199\ttotal: 17.1s\tremaining: 34.2s\n",
      "241:\tlearn: 0.1418137\ttotal: 17.1s\tremaining: 34.1s\n",
      "242:\tlearn: 0.1418038\ttotal: 17.2s\tremaining: 34.1s\n",
      "243:\tlearn: 0.1418003\ttotal: 17.3s\tremaining: 34s\n",
      "244:\tlearn: 0.1417926\ttotal: 17.4s\tremaining: 33.9s\n",
      "245:\tlearn: 0.1417896\ttotal: 17.4s\tremaining: 33.8s\n",
      "246:\tlearn: 0.1417852\ttotal: 17.5s\tremaining: 33.8s\n",
      "247:\tlearn: 0.1417822\ttotal: 17.5s\tremaining: 33.7s\n",
      "248:\tlearn: 0.1417781\ttotal: 17.6s\tremaining: 33.6s\n",
      "249:\tlearn: 0.1417669\ttotal: 17.7s\tremaining: 33.5s\n",
      "250:\tlearn: 0.1417571\ttotal: 17.8s\tremaining: 33.5s\n",
      "251:\tlearn: 0.1417481\ttotal: 17.8s\tremaining: 33.4s\n",
      "252:\tlearn: 0.1417434\ttotal: 17.9s\tremaining: 33.3s\n",
      "253:\tlearn: 0.1417367\ttotal: 18s\tremaining: 33.2s\n",
      "254:\tlearn: 0.1417269\ttotal: 18s\tremaining: 33.2s\n",
      "255:\tlearn: 0.1417218\ttotal: 18.1s\tremaining: 33.1s\n",
      "256:\tlearn: 0.1417161\ttotal: 18.2s\tremaining: 33s\n",
      "257:\tlearn: 0.1417094\ttotal: 18.3s\tremaining: 33s\n",
      "258:\tlearn: 0.1417000\ttotal: 18.3s\tremaining: 32.9s\n",
      "259:\tlearn: 0.1416939\ttotal: 18.4s\tremaining: 32.8s\n",
      "260:\tlearn: 0.1416867\ttotal: 18.5s\tremaining: 32.8s\n",
      "261:\tlearn: 0.1416819\ttotal: 18.5s\tremaining: 32.7s\n",
      "262:\tlearn: 0.1416761\ttotal: 18.6s\tremaining: 32.6s\n",
      "263:\tlearn: 0.1416656\ttotal: 18.7s\tremaining: 32.5s\n",
      "264:\tlearn: 0.1416610\ttotal: 18.7s\tremaining: 32.5s\n",
      "265:\tlearn: 0.1416547\ttotal: 18.8s\tremaining: 32.4s\n",
      "266:\tlearn: 0.1416514\ttotal: 18.9s\tremaining: 32.3s\n",
      "267:\tlearn: 0.1416473\ttotal: 18.9s\tremaining: 32.2s\n",
      "268:\tlearn: 0.1416376\ttotal: 19s\tremaining: 32.1s\n",
      "269:\tlearn: 0.1416331\ttotal: 19.1s\tremaining: 32.1s\n",
      "270:\tlearn: 0.1416294\ttotal: 19.1s\tremaining: 32s\n",
      "271:\tlearn: 0.1416257\ttotal: 19.2s\tremaining: 31.9s\n",
      "272:\tlearn: 0.1416167\ttotal: 19.3s\tremaining: 31.8s\n",
      "273:\tlearn: 0.1416082\ttotal: 19.3s\tremaining: 31.8s\n",
      "274:\tlearn: 0.1416007\ttotal: 19.4s\tremaining: 31.7s\n",
      "275:\tlearn: 0.1415964\ttotal: 19.5s\tremaining: 31.6s\n",
      "276:\tlearn: 0.1415905\ttotal: 19.6s\tremaining: 31.6s\n",
      "277:\tlearn: 0.1415813\ttotal: 19.6s\tremaining: 31.5s\n",
      "278:\tlearn: 0.1415738\ttotal: 19.7s\tremaining: 31.4s\n",
      "279:\tlearn: 0.1415662\ttotal: 19.8s\tremaining: 31.3s\n",
      "280:\tlearn: 0.1415600\ttotal: 19.8s\tremaining: 31.3s\n",
      "281:\tlearn: 0.1415549\ttotal: 19.9s\tremaining: 31.2s\n",
      "282:\tlearn: 0.1415494\ttotal: 20s\tremaining: 31.1s\n",
      "283:\tlearn: 0.1415417\ttotal: 20.1s\tremaining: 31.1s\n",
      "284:\tlearn: 0.1415346\ttotal: 20.1s\tremaining: 31s\n",
      "285:\tlearn: 0.1415251\ttotal: 20.2s\tremaining: 30.9s\n",
      "286:\tlearn: 0.1415186\ttotal: 20.3s\tremaining: 30.9s\n",
      "287:\tlearn: 0.1415122\ttotal: 20.4s\tremaining: 30.8s\n",
      "288:\tlearn: 0.1415059\ttotal: 20.4s\tremaining: 30.7s\n",
      "289:\tlearn: 0.1415002\ttotal: 20.5s\tremaining: 30.7s\n",
      "290:\tlearn: 0.1414926\ttotal: 20.6s\tremaining: 30.6s\n",
      "291:\tlearn: 0.1414865\ttotal: 20.7s\tremaining: 30.6s\n",
      "292:\tlearn: 0.1414812\ttotal: 20.7s\tremaining: 30.5s\n",
      "293:\tlearn: 0.1414754\ttotal: 20.8s\tremaining: 30.4s\n",
      "294:\tlearn: 0.1414699\ttotal: 20.9s\tremaining: 30.4s\n",
      "295:\tlearn: 0.1414647\ttotal: 20.9s\tremaining: 30.3s\n",
      "296:\tlearn: 0.1414571\ttotal: 21s\tremaining: 30.2s\n",
      "297:\tlearn: 0.1414511\ttotal: 21.1s\tremaining: 30.2s\n",
      "298:\tlearn: 0.1414446\ttotal: 21.2s\tremaining: 30.1s\n",
      "299:\tlearn: 0.1414380\ttotal: 21.2s\tremaining: 30s\n",
      "300:\tlearn: 0.1414351\ttotal: 21.3s\tremaining: 29.9s\n",
      "301:\tlearn: 0.1414302\ttotal: 21.4s\tremaining: 29.9s\n",
      "302:\tlearn: 0.1414232\ttotal: 21.4s\tremaining: 29.8s\n",
      "303:\tlearn: 0.1414189\ttotal: 21.5s\tremaining: 29.7s\n",
      "304:\tlearn: 0.1414133\ttotal: 21.6s\tremaining: 29.6s\n",
      "305:\tlearn: 0.1414062\ttotal: 21.7s\tremaining: 29.6s\n",
      "306:\tlearn: 0.1414014\ttotal: 21.7s\tremaining: 29.5s\n",
      "307:\tlearn: 0.1413971\ttotal: 21.8s\tremaining: 29.4s\n",
      "308:\tlearn: 0.1413917\ttotal: 21.9s\tremaining: 29.4s\n",
      "309:\tlearn: 0.1413856\ttotal: 21.9s\tremaining: 29.3s\n",
      "310:\tlearn: 0.1413803\ttotal: 22s\tremaining: 29.2s\n",
      "311:\tlearn: 0.1413739\ttotal: 22.1s\tremaining: 29.2s\n",
      "312:\tlearn: 0.1413684\ttotal: 22.2s\tremaining: 29.1s\n",
      "313:\tlearn: 0.1413641\ttotal: 22.2s\tremaining: 29s\n",
      "314:\tlearn: 0.1413541\ttotal: 22.3s\tremaining: 29s\n",
      "315:\tlearn: 0.1413458\ttotal: 22.4s\tremaining: 28.9s\n",
      "316:\tlearn: 0.1413422\ttotal: 22.4s\tremaining: 28.8s\n",
      "317:\tlearn: 0.1413365\ttotal: 22.5s\tremaining: 28.7s\n",
      "318:\tlearn: 0.1413314\ttotal: 22.6s\tremaining: 28.7s\n",
      "319:\tlearn: 0.1413258\ttotal: 22.6s\tremaining: 28.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320:\tlearn: 0.1413218\ttotal: 22.7s\tremaining: 28.5s\n",
      "321:\tlearn: 0.1413159\ttotal: 22.8s\tremaining: 28.4s\n",
      "322:\tlearn: 0.1413122\ttotal: 22.8s\tremaining: 28.4s\n",
      "323:\tlearn: 0.1413051\ttotal: 22.9s\tremaining: 28.3s\n",
      "324:\tlearn: 0.1413020\ttotal: 23s\tremaining: 28.2s\n",
      "325:\tlearn: 0.1412951\ttotal: 23s\tremaining: 28.1s\n",
      "326:\tlearn: 0.1412910\ttotal: 23.1s\tremaining: 28s\n",
      "327:\tlearn: 0.1412843\ttotal: 23.2s\tremaining: 28s\n",
      "328:\tlearn: 0.1412782\ttotal: 23.2s\tremaining: 27.9s\n",
      "329:\tlearn: 0.1412725\ttotal: 23.3s\tremaining: 27.8s\n",
      "330:\tlearn: 0.1412668\ttotal: 23.4s\tremaining: 27.8s\n",
      "331:\tlearn: 0.1412602\ttotal: 23.5s\tremaining: 27.7s\n",
      "332:\tlearn: 0.1412535\ttotal: 23.5s\tremaining: 27.6s\n",
      "333:\tlearn: 0.1412461\ttotal: 23.6s\tremaining: 27.6s\n",
      "334:\tlearn: 0.1412426\ttotal: 23.7s\tremaining: 27.5s\n",
      "335:\tlearn: 0.1412371\ttotal: 23.7s\tremaining: 27.4s\n",
      "336:\tlearn: 0.1412298\ttotal: 23.8s\tremaining: 27.4s\n",
      "337:\tlearn: 0.1412250\ttotal: 23.9s\tremaining: 27.3s\n",
      "338:\tlearn: 0.1412196\ttotal: 24s\tremaining: 27.2s\n",
      "339:\tlearn: 0.1412138\ttotal: 24s\tremaining: 27.1s\n",
      "340:\tlearn: 0.1412100\ttotal: 24.1s\tremaining: 27.1s\n",
      "341:\tlearn: 0.1412039\ttotal: 24.2s\tremaining: 27s\n",
      "342:\tlearn: 0.1411954\ttotal: 24.3s\tremaining: 26.9s\n",
      "343:\tlearn: 0.1411917\ttotal: 24.3s\tremaining: 26.9s\n",
      "344:\tlearn: 0.1411862\ttotal: 24.4s\tremaining: 26.8s\n",
      "345:\tlearn: 0.1411787\ttotal: 24.5s\tremaining: 26.7s\n",
      "346:\tlearn: 0.1411727\ttotal: 24.5s\tremaining: 26.6s\n",
      "347:\tlearn: 0.1411682\ttotal: 24.6s\tremaining: 26.6s\n",
      "348:\tlearn: 0.1411634\ttotal: 24.7s\tremaining: 26.5s\n",
      "349:\tlearn: 0.1411565\ttotal: 24.7s\tremaining: 26.4s\n",
      "350:\tlearn: 0.1411478\ttotal: 24.8s\tremaining: 26.4s\n",
      "351:\tlearn: 0.1411417\ttotal: 24.9s\tremaining: 26.3s\n",
      "352:\tlearn: 0.1411377\ttotal: 24.9s\tremaining: 26.2s\n",
      "353:\tlearn: 0.1411324\ttotal: 25s\tremaining: 26.1s\n",
      "354:\tlearn: 0.1411286\ttotal: 25.1s\tremaining: 26s\n",
      "355:\tlearn: 0.1411236\ttotal: 25.1s\tremaining: 26s\n",
      "356:\tlearn: 0.1411200\ttotal: 25.2s\tremaining: 25.9s\n",
      "357:\tlearn: 0.1411141\ttotal: 25.3s\tremaining: 25.8s\n",
      "358:\tlearn: 0.1411092\ttotal: 25.3s\tremaining: 25.8s\n",
      "359:\tlearn: 0.1411021\ttotal: 25.4s\tremaining: 25.7s\n",
      "360:\tlearn: 0.1410970\ttotal: 25.5s\tremaining: 25.6s\n",
      "361:\tlearn: 0.1410911\ttotal: 25.6s\tremaining: 25.6s\n",
      "362:\tlearn: 0.1410866\ttotal: 25.6s\tremaining: 25.5s\n",
      "363:\tlearn: 0.1410805\ttotal: 25.7s\tremaining: 25.4s\n",
      "364:\tlearn: 0.1410746\ttotal: 25.8s\tremaining: 25.3s\n",
      "365:\tlearn: 0.1410697\ttotal: 25.8s\tremaining: 25.3s\n",
      "366:\tlearn: 0.1410633\ttotal: 25.9s\tremaining: 25.2s\n",
      "367:\tlearn: 0.1410596\ttotal: 26s\tremaining: 25.1s\n",
      "368:\tlearn: 0.1410559\ttotal: 26s\tremaining: 25.1s\n",
      "369:\tlearn: 0.1410500\ttotal: 26.1s\tremaining: 25s\n",
      "370:\tlearn: 0.1410432\ttotal: 26.2s\tremaining: 24.9s\n",
      "371:\tlearn: 0.1410367\ttotal: 26.3s\tremaining: 24.9s\n",
      "372:\tlearn: 0.1410335\ttotal: 26.3s\tremaining: 24.8s\n",
      "373:\tlearn: 0.1410310\ttotal: 26.4s\tremaining: 24.7s\n",
      "374:\tlearn: 0.1410240\ttotal: 26.5s\tremaining: 24.6s\n",
      "375:\tlearn: 0.1410197\ttotal: 26.5s\tremaining: 24.6s\n",
      "376:\tlearn: 0.1410147\ttotal: 26.6s\tremaining: 24.5s\n",
      "377:\tlearn: 0.1410061\ttotal: 26.7s\tremaining: 24.4s\n",
      "378:\tlearn: 0.1410033\ttotal: 26.7s\tremaining: 24.3s\n",
      "379:\tlearn: 0.1409988\ttotal: 26.8s\tremaining: 24.3s\n",
      "380:\tlearn: 0.1409904\ttotal: 26.9s\tremaining: 24.2s\n",
      "381:\tlearn: 0.1409838\ttotal: 27s\tremaining: 24.1s\n",
      "382:\tlearn: 0.1409773\ttotal: 27s\tremaining: 24.1s\n",
      "383:\tlearn: 0.1409734\ttotal: 27.1s\tremaining: 24s\n",
      "384:\tlearn: 0.1409680\ttotal: 27.2s\tremaining: 23.9s\n",
      "385:\tlearn: 0.1409620\ttotal: 27.3s\tremaining: 23.9s\n",
      "386:\tlearn: 0.1409561\ttotal: 27.3s\tremaining: 23.8s\n",
      "387:\tlearn: 0.1409500\ttotal: 27.4s\tremaining: 23.7s\n",
      "388:\tlearn: 0.1409421\ttotal: 27.5s\tremaining: 23.7s\n",
      "389:\tlearn: 0.1409388\ttotal: 27.5s\tremaining: 23.6s\n",
      "390:\tlearn: 0.1409347\ttotal: 27.6s\tremaining: 23.5s\n",
      "391:\tlearn: 0.1409299\ttotal: 27.7s\tremaining: 23.4s\n",
      "392:\tlearn: 0.1409228\ttotal: 27.7s\tremaining: 23.4s\n",
      "393:\tlearn: 0.1409168\ttotal: 27.8s\tremaining: 23.3s\n",
      "394:\tlearn: 0.1409128\ttotal: 27.9s\tremaining: 23.2s\n",
      "395:\tlearn: 0.1409086\ttotal: 27.9s\tremaining: 23.1s\n",
      "396:\tlearn: 0.1409033\ttotal: 28s\tremaining: 23.1s\n",
      "397:\tlearn: 0.1409012\ttotal: 28.1s\tremaining: 23s\n",
      "398:\tlearn: 0.1408947\ttotal: 28.1s\tremaining: 22.9s\n",
      "399:\tlearn: 0.1408912\ttotal: 28.2s\tremaining: 22.9s\n",
      "400:\tlearn: 0.1408887\ttotal: 28.3s\tremaining: 22.8s\n",
      "401:\tlearn: 0.1408833\ttotal: 28.4s\tremaining: 22.7s\n",
      "402:\tlearn: 0.1408783\ttotal: 28.4s\tremaining: 22.6s\n",
      "403:\tlearn: 0.1408730\ttotal: 28.5s\tremaining: 22.6s\n",
      "404:\tlearn: 0.1408681\ttotal: 28.6s\tremaining: 22.5s\n",
      "405:\tlearn: 0.1408660\ttotal: 28.6s\tremaining: 22.4s\n",
      "406:\tlearn: 0.1408613\ttotal: 28.7s\tremaining: 22.4s\n",
      "407:\tlearn: 0.1408579\ttotal: 28.8s\tremaining: 22.3s\n",
      "408:\tlearn: 0.1408548\ttotal: 28.8s\tremaining: 22.2s\n",
      "409:\tlearn: 0.1408500\ttotal: 28.9s\tremaining: 22.1s\n",
      "410:\tlearn: 0.1408458\ttotal: 29s\tremaining: 22.1s\n",
      "411:\tlearn: 0.1408424\ttotal: 29s\tremaining: 22s\n",
      "412:\tlearn: 0.1408379\ttotal: 29.1s\tremaining: 21.9s\n",
      "413:\tlearn: 0.1408328\ttotal: 29.2s\tremaining: 21.8s\n",
      "414:\tlearn: 0.1408282\ttotal: 29.2s\tremaining: 21.8s\n",
      "415:\tlearn: 0.1408262\ttotal: 29.3s\tremaining: 21.7s\n",
      "416:\tlearn: 0.1408220\ttotal: 29.4s\tremaining: 21.6s\n",
      "417:\tlearn: 0.1408147\ttotal: 29.4s\tremaining: 21.5s\n",
      "418:\tlearn: 0.1408092\ttotal: 29.5s\tremaining: 21.5s\n",
      "419:\tlearn: 0.1408059\ttotal: 29.6s\tremaining: 21.4s\n",
      "420:\tlearn: 0.1408004\ttotal: 29.6s\tremaining: 21.3s\n",
      "421:\tlearn: 0.1407931\ttotal: 29.7s\tremaining: 21.3s\n",
      "422:\tlearn: 0.1407875\ttotal: 29.8s\tremaining: 21.2s\n",
      "423:\tlearn: 0.1407813\ttotal: 29.8s\tremaining: 21.1s\n",
      "424:\tlearn: 0.1407744\ttotal: 29.9s\tremaining: 21s\n",
      "425:\tlearn: 0.1407669\ttotal: 30s\tremaining: 21s\n",
      "426:\tlearn: 0.1407613\ttotal: 30.1s\tremaining: 20.9s\n",
      "427:\tlearn: 0.1407560\ttotal: 30.1s\tremaining: 20.8s\n",
      "428:\tlearn: 0.1407519\ttotal: 30.2s\tremaining: 20.8s\n",
      "429:\tlearn: 0.1407466\ttotal: 30.3s\tremaining: 20.7s\n",
      "430:\tlearn: 0.1407410\ttotal: 30.4s\tremaining: 20.6s\n",
      "431:\tlearn: 0.1407338\ttotal: 30.4s\tremaining: 20.6s\n",
      "432:\tlearn: 0.1407309\ttotal: 30.5s\tremaining: 20.5s\n",
      "433:\tlearn: 0.1407247\ttotal: 30.6s\tremaining: 20.4s\n",
      "434:\tlearn: 0.1407199\ttotal: 30.6s\tremaining: 20.4s\n",
      "435:\tlearn: 0.1407135\ttotal: 30.7s\tremaining: 20.3s\n",
      "436:\tlearn: 0.1407112\ttotal: 30.8s\tremaining: 20.2s\n",
      "437:\tlearn: 0.1407065\ttotal: 30.8s\tremaining: 20.1s\n",
      "438:\tlearn: 0.1407000\ttotal: 30.9s\tremaining: 20.1s\n",
      "439:\tlearn: 0.1406923\ttotal: 31s\tremaining: 20s\n",
      "440:\tlearn: 0.1406867\ttotal: 31s\tremaining: 19.9s\n",
      "441:\tlearn: 0.1406808\ttotal: 31.1s\tremaining: 19.9s\n",
      "442:\tlearn: 0.1406758\ttotal: 31.2s\tremaining: 19.8s\n",
      "443:\tlearn: 0.1406705\ttotal: 31.3s\tremaining: 19.7s\n",
      "444:\tlearn: 0.1406650\ttotal: 31.3s\tremaining: 19.6s\n",
      "445:\tlearn: 0.1406610\ttotal: 31.4s\tremaining: 19.6s\n",
      "446:\tlearn: 0.1406538\ttotal: 31.5s\tremaining: 19.5s\n",
      "447:\tlearn: 0.1406497\ttotal: 31.5s\tremaining: 19.4s\n",
      "448:\tlearn: 0.1406440\ttotal: 31.6s\tremaining: 19.4s\n",
      "449:\tlearn: 0.1406415\ttotal: 31.7s\tremaining: 19.3s\n",
      "450:\tlearn: 0.1406380\ttotal: 31.7s\tremaining: 19.2s\n",
      "451:\tlearn: 0.1406340\ttotal: 31.8s\tremaining: 19.1s\n",
      "452:\tlearn: 0.1406297\ttotal: 31.9s\tremaining: 19.1s\n",
      "453:\tlearn: 0.1406231\ttotal: 32s\tremaining: 19s\n",
      "454:\tlearn: 0.1406175\ttotal: 32s\tremaining: 18.9s\n",
      "455:\tlearn: 0.1406123\ttotal: 32.1s\tremaining: 18.9s\n",
      "456:\tlearn: 0.1406096\ttotal: 32.1s\tremaining: 18.8s\n",
      "457:\tlearn: 0.1406039\ttotal: 32.2s\tremaining: 18.7s\n",
      "458:\tlearn: 0.1405990\ttotal: 32.3s\tremaining: 18.7s\n",
      "459:\tlearn: 0.1405911\ttotal: 32.4s\tremaining: 18.6s\n",
      "460:\tlearn: 0.1405841\ttotal: 32.5s\tremaining: 18.5s\n",
      "461:\tlearn: 0.1405787\ttotal: 32.5s\tremaining: 18.4s\n",
      "462:\tlearn: 0.1405740\ttotal: 32.6s\tremaining: 18.4s\n",
      "463:\tlearn: 0.1405701\ttotal: 32.7s\tremaining: 18.3s\n",
      "464:\tlearn: 0.1405649\ttotal: 32.7s\tremaining: 18.2s\n",
      "465:\tlearn: 0.1405585\ttotal: 32.8s\tremaining: 18.2s\n",
      "466:\tlearn: 0.1405531\ttotal: 32.9s\tremaining: 18.1s\n",
      "467:\tlearn: 0.1405481\ttotal: 32.9s\tremaining: 18s\n",
      "468:\tlearn: 0.1405446\ttotal: 33s\tremaining: 17.9s\n",
      "469:\tlearn: 0.1405395\ttotal: 33.1s\tremaining: 17.9s\n",
      "470:\tlearn: 0.1405345\ttotal: 33.2s\tremaining: 17.8s\n",
      "471:\tlearn: 0.1405287\ttotal: 33.2s\tremaining: 17.7s\n",
      "472:\tlearn: 0.1405237\ttotal: 33.3s\tremaining: 17.7s\n",
      "473:\tlearn: 0.1405182\ttotal: 33.4s\tremaining: 17.6s\n",
      "474:\tlearn: 0.1405130\ttotal: 33.4s\tremaining: 17.5s\n",
      "475:\tlearn: 0.1405065\ttotal: 33.5s\tremaining: 17.5s\n",
      "476:\tlearn: 0.1405024\ttotal: 33.6s\tremaining: 17.4s\n",
      "477:\tlearn: 0.1404967\ttotal: 33.6s\tremaining: 17.3s\n",
      "478:\tlearn: 0.1404916\ttotal: 33.7s\tremaining: 17.2s\n",
      "479:\tlearn: 0.1404852\ttotal: 33.8s\tremaining: 17.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480:\tlearn: 0.1404795\ttotal: 33.9s\tremaining: 17.1s\n",
      "481:\tlearn: 0.1404752\ttotal: 33.9s\tremaining: 17s\n",
      "482:\tlearn: 0.1404714\ttotal: 34s\tremaining: 17s\n",
      "483:\tlearn: 0.1404657\ttotal: 34.1s\tremaining: 16.9s\n",
      "484:\tlearn: 0.1404600\ttotal: 34.1s\tremaining: 16.8s\n",
      "485:\tlearn: 0.1404554\ttotal: 34.2s\tremaining: 16.8s\n",
      "486:\tlearn: 0.1404508\ttotal: 34.3s\tremaining: 16.7s\n",
      "487:\tlearn: 0.1404464\ttotal: 34.4s\tremaining: 16.6s\n",
      "488:\tlearn: 0.1404398\ttotal: 34.4s\tremaining: 16.5s\n",
      "489:\tlearn: 0.1404339\ttotal: 34.5s\tremaining: 16.5s\n",
      "490:\tlearn: 0.1404298\ttotal: 34.6s\tremaining: 16.4s\n",
      "491:\tlearn: 0.1404273\ttotal: 34.6s\tremaining: 16.3s\n",
      "492:\tlearn: 0.1404210\ttotal: 34.7s\tremaining: 16.3s\n",
      "493:\tlearn: 0.1404150\ttotal: 34.8s\tremaining: 16.2s\n",
      "494:\tlearn: 0.1404084\ttotal: 34.8s\tremaining: 16.1s\n",
      "495:\tlearn: 0.1404031\ttotal: 34.9s\tremaining: 16s\n",
      "496:\tlearn: 0.1403965\ttotal: 35s\tremaining: 16s\n",
      "497:\tlearn: 0.1403902\ttotal: 35s\tremaining: 15.9s\n",
      "498:\tlearn: 0.1403867\ttotal: 35.1s\tremaining: 15.8s\n",
      "499:\tlearn: 0.1403823\ttotal: 35.2s\tremaining: 15.8s\n",
      "500:\tlearn: 0.1403786\ttotal: 35.3s\tremaining: 15.7s\n",
      "501:\tlearn: 0.1403719\ttotal: 35.3s\tremaining: 15.6s\n",
      "502:\tlearn: 0.1403685\ttotal: 35.4s\tremaining: 15.6s\n",
      "503:\tlearn: 0.1403650\ttotal: 35.5s\tremaining: 15.5s\n",
      "504:\tlearn: 0.1403598\ttotal: 35.5s\tremaining: 15.4s\n",
      "505:\tlearn: 0.1403554\ttotal: 35.6s\tremaining: 15.3s\n",
      "506:\tlearn: 0.1403487\ttotal: 35.7s\tremaining: 15.3s\n",
      "507:\tlearn: 0.1403463\ttotal: 35.7s\tremaining: 15.2s\n",
      "508:\tlearn: 0.1403412\ttotal: 35.8s\tremaining: 15.1s\n",
      "509:\tlearn: 0.1403363\ttotal: 35.9s\tremaining: 15.1s\n",
      "510:\tlearn: 0.1403289\ttotal: 36s\tremaining: 15s\n",
      "511:\tlearn: 0.1403240\ttotal: 36s\tremaining: 14.9s\n",
      "512:\tlearn: 0.1403166\ttotal: 36.1s\tremaining: 14.9s\n",
      "513:\tlearn: 0.1403117\ttotal: 36.2s\tremaining: 14.8s\n",
      "514:\tlearn: 0.1403068\ttotal: 36.2s\tremaining: 14.7s\n",
      "515:\tlearn: 0.1403020\ttotal: 36.3s\tremaining: 14.6s\n",
      "516:\tlearn: 0.1402954\ttotal: 36.4s\tremaining: 14.6s\n",
      "517:\tlearn: 0.1402879\ttotal: 36.5s\tremaining: 14.5s\n",
      "518:\tlearn: 0.1402839\ttotal: 36.5s\tremaining: 14.4s\n",
      "519:\tlearn: 0.1402806\ttotal: 36.6s\tremaining: 14.4s\n",
      "520:\tlearn: 0.1402751\ttotal: 36.7s\tremaining: 14.3s\n",
      "521:\tlearn: 0.1402702\ttotal: 36.7s\tremaining: 14.2s\n",
      "522:\tlearn: 0.1402649\ttotal: 36.8s\tremaining: 14.1s\n",
      "523:\tlearn: 0.1402607\ttotal: 36.9s\tremaining: 14.1s\n",
      "524:\tlearn: 0.1402565\ttotal: 36.9s\tremaining: 14s\n",
      "525:\tlearn: 0.1402537\ttotal: 37s\tremaining: 13.9s\n",
      "526:\tlearn: 0.1402474\ttotal: 37.1s\tremaining: 13.9s\n",
      "527:\tlearn: 0.1402416\ttotal: 37.2s\tremaining: 13.8s\n",
      "528:\tlearn: 0.1402382\ttotal: 37.2s\tremaining: 13.7s\n",
      "529:\tlearn: 0.1402326\ttotal: 37.3s\tremaining: 13.7s\n",
      "530:\tlearn: 0.1402270\ttotal: 37.4s\tremaining: 13.6s\n",
      "531:\tlearn: 0.1402228\ttotal: 37.5s\tremaining: 13.5s\n",
      "532:\tlearn: 0.1402171\ttotal: 37.5s\tremaining: 13.5s\n",
      "533:\tlearn: 0.1402131\ttotal: 37.6s\tremaining: 13.4s\n",
      "534:\tlearn: 0.1402100\ttotal: 37.7s\tremaining: 13.3s\n",
      "535:\tlearn: 0.1402063\ttotal: 37.7s\tremaining: 13.2s\n",
      "536:\tlearn: 0.1402033\ttotal: 37.8s\tremaining: 13.2s\n",
      "537:\tlearn: 0.1401988\ttotal: 37.9s\tremaining: 13.1s\n",
      "538:\tlearn: 0.1401952\ttotal: 38s\tremaining: 13s\n",
      "539:\tlearn: 0.1401911\ttotal: 38s\tremaining: 13s\n",
      "540:\tlearn: 0.1401871\ttotal: 38.1s\tremaining: 12.9s\n",
      "541:\tlearn: 0.1401854\ttotal: 38.2s\tremaining: 12.8s\n",
      "542:\tlearn: 0.1401769\ttotal: 38.2s\tremaining: 12.7s\n",
      "543:\tlearn: 0.1401714\ttotal: 38.3s\tremaining: 12.7s\n",
      "544:\tlearn: 0.1401667\ttotal: 38.4s\tremaining: 12.6s\n",
      "545:\tlearn: 0.1401630\ttotal: 38.4s\tremaining: 12.5s\n",
      "546:\tlearn: 0.1401582\ttotal: 38.5s\tremaining: 12.5s\n",
      "547:\tlearn: 0.1401555\ttotal: 38.6s\tremaining: 12.4s\n",
      "548:\tlearn: 0.1401525\ttotal: 38.6s\tremaining: 12.3s\n",
      "549:\tlearn: 0.1401495\ttotal: 38.7s\tremaining: 12.2s\n",
      "550:\tlearn: 0.1401450\ttotal: 38.8s\tremaining: 12.2s\n",
      "551:\tlearn: 0.1401410\ttotal: 38.8s\tremaining: 12.1s\n",
      "552:\tlearn: 0.1401359\ttotal: 38.9s\tremaining: 12s\n",
      "553:\tlearn: 0.1401296\ttotal: 39s\tremaining: 12s\n",
      "554:\tlearn: 0.1401242\ttotal: 39.1s\tremaining: 11.9s\n",
      "555:\tlearn: 0.1401187\ttotal: 39.1s\tremaining: 11.8s\n",
      "556:\tlearn: 0.1401137\ttotal: 39.2s\tremaining: 11.8s\n",
      "557:\tlearn: 0.1401077\ttotal: 39.3s\tremaining: 11.7s\n",
      "558:\tlearn: 0.1401038\ttotal: 39.3s\tremaining: 11.6s\n",
      "559:\tlearn: 0.1401021\ttotal: 39.4s\tremaining: 11.5s\n",
      "560:\tlearn: 0.1400979\ttotal: 39.5s\tremaining: 11.5s\n",
      "561:\tlearn: 0.1400943\ttotal: 39.5s\tremaining: 11.4s\n",
      "562:\tlearn: 0.1400909\ttotal: 39.6s\tremaining: 11.3s\n",
      "563:\tlearn: 0.1400855\ttotal: 39.7s\tremaining: 11.3s\n",
      "564:\tlearn: 0.1400815\ttotal: 39.7s\tremaining: 11.2s\n",
      "565:\tlearn: 0.1400750\ttotal: 39.8s\tremaining: 11.1s\n",
      "566:\tlearn: 0.1400722\ttotal: 39.9s\tremaining: 11s\n",
      "567:\tlearn: 0.1400706\ttotal: 39.9s\tremaining: 11s\n",
      "568:\tlearn: 0.1400668\ttotal: 40s\tremaining: 10.9s\n",
      "569:\tlearn: 0.1400629\ttotal: 40.1s\tremaining: 10.8s\n",
      "570:\tlearn: 0.1400594\ttotal: 40.2s\tremaining: 10.8s\n",
      "571:\tlearn: 0.1400563\ttotal: 40.2s\tremaining: 10.7s\n",
      "572:\tlearn: 0.1400500\ttotal: 40.3s\tremaining: 10.6s\n",
      "573:\tlearn: 0.1400458\ttotal: 40.4s\tremaining: 10.5s\n",
      "574:\tlearn: 0.1400406\ttotal: 40.4s\tremaining: 10.5s\n",
      "575:\tlearn: 0.1400362\ttotal: 40.5s\tremaining: 10.4s\n",
      "576:\tlearn: 0.1400312\ttotal: 40.6s\tremaining: 10.3s\n",
      "577:\tlearn: 0.1400299\ttotal: 40.6s\tremaining: 10.3s\n",
      "578:\tlearn: 0.1400290\ttotal: 40.7s\tremaining: 10.2s\n",
      "579:\tlearn: 0.1400257\ttotal: 40.8s\tremaining: 10.1s\n",
      "580:\tlearn: 0.1400224\ttotal: 40.8s\tremaining: 10.1s\n",
      "581:\tlearn: 0.1400184\ttotal: 40.9s\tremaining: 9.98s\n",
      "582:\tlearn: 0.1400142\ttotal: 41s\tremaining: 9.91s\n",
      "583:\tlearn: 0.1400110\ttotal: 41s\tremaining: 9.84s\n",
      "584:\tlearn: 0.1400076\ttotal: 41.1s\tremaining: 9.77s\n",
      "585:\tlearn: 0.1400032\ttotal: 41.2s\tremaining: 9.7s\n",
      "586:\tlearn: 0.1400000\ttotal: 41.2s\tremaining: 9.63s\n",
      "587:\tlearn: 0.1399970\ttotal: 41.3s\tremaining: 9.55s\n",
      "588:\tlearn: 0.1399931\ttotal: 41.4s\tremaining: 9.48s\n",
      "589:\tlearn: 0.1399897\ttotal: 41.4s\tremaining: 9.41s\n",
      "590:\tlearn: 0.1399851\ttotal: 41.5s\tremaining: 9.34s\n",
      "591:\tlearn: 0.1399840\ttotal: 41.6s\tremaining: 9.27s\n",
      "592:\tlearn: 0.1399803\ttotal: 41.6s\tremaining: 9.2s\n",
      "593:\tlearn: 0.1399748\ttotal: 41.7s\tremaining: 9.13s\n",
      "594:\tlearn: 0.1399704\ttotal: 41.8s\tremaining: 9.06s\n",
      "595:\tlearn: 0.1399682\ttotal: 41.9s\tremaining: 8.99s\n",
      "596:\tlearn: 0.1399633\ttotal: 41.9s\tremaining: 8.92s\n",
      "597:\tlearn: 0.1399590\ttotal: 42s\tremaining: 8.85s\n",
      "598:\tlearn: 0.1399540\ttotal: 42.1s\tremaining: 8.78s\n",
      "599:\tlearn: 0.1399463\ttotal: 42.1s\tremaining: 8.71s\n",
      "600:\tlearn: 0.1399444\ttotal: 42.2s\tremaining: 8.64s\n",
      "601:\tlearn: 0.1399391\ttotal: 42.3s\tremaining: 8.57s\n",
      "602:\tlearn: 0.1399356\ttotal: 42.3s\tremaining: 8.49s\n",
      "603:\tlearn: 0.1399316\ttotal: 42.4s\tremaining: 8.42s\n",
      "604:\tlearn: 0.1399251\ttotal: 42.5s\tremaining: 8.35s\n",
      "605:\tlearn: 0.1399191\ttotal: 42.5s\tremaining: 8.28s\n",
      "606:\tlearn: 0.1399119\ttotal: 42.6s\tremaining: 8.21s\n",
      "607:\tlearn: 0.1399090\ttotal: 42.7s\tremaining: 8.14s\n",
      "608:\tlearn: 0.1399047\ttotal: 42.7s\tremaining: 8.07s\n",
      "609:\tlearn: 0.1398992\ttotal: 42.8s\tremaining: 8s\n",
      "610:\tlearn: 0.1398961\ttotal: 42.9s\tremaining: 7.93s\n",
      "611:\tlearn: 0.1398913\ttotal: 43s\tremaining: 7.86s\n",
      "612:\tlearn: 0.1398884\ttotal: 43s\tremaining: 7.79s\n",
      "613:\tlearn: 0.1398836\ttotal: 43.1s\tremaining: 7.72s\n",
      "614:\tlearn: 0.1398787\ttotal: 43.2s\tremaining: 7.65s\n",
      "615:\tlearn: 0.1398758\ttotal: 43.2s\tremaining: 7.58s\n",
      "616:\tlearn: 0.1398730\ttotal: 43.3s\tremaining: 7.51s\n",
      "617:\tlearn: 0.1398697\ttotal: 43.4s\tremaining: 7.44s\n",
      "618:\tlearn: 0.1398630\ttotal: 43.5s\tremaining: 7.37s\n",
      "619:\tlearn: 0.1398575\ttotal: 43.5s\tremaining: 7.3s\n",
      "620:\tlearn: 0.1398521\ttotal: 43.6s\tremaining: 7.23s\n",
      "621:\tlearn: 0.1398480\ttotal: 43.7s\tremaining: 7.16s\n",
      "622:\tlearn: 0.1398431\ttotal: 43.7s\tremaining: 7.09s\n",
      "623:\tlearn: 0.1398394\ttotal: 43.8s\tremaining: 7.02s\n",
      "624:\tlearn: 0.1398340\ttotal: 43.9s\tremaining: 6.95s\n",
      "625:\tlearn: 0.1398299\ttotal: 44s\tremaining: 6.88s\n",
      "626:\tlearn: 0.1398257\ttotal: 44s\tremaining: 6.81s\n",
      "627:\tlearn: 0.1398215\ttotal: 44.1s\tremaining: 6.74s\n",
      "628:\tlearn: 0.1398156\ttotal: 44.2s\tremaining: 6.67s\n",
      "629:\tlearn: 0.1398134\ttotal: 44.2s\tremaining: 6.6s\n",
      "630:\tlearn: 0.1398119\ttotal: 44.3s\tremaining: 6.53s\n",
      "631:\tlearn: 0.1398044\ttotal: 44.4s\tremaining: 6.46s\n",
      "632:\tlearn: 0.1397986\ttotal: 44.5s\tremaining: 6.39s\n",
      "633:\tlearn: 0.1397952\ttotal: 44.5s\tremaining: 6.32s\n",
      "634:\tlearn: 0.1397934\ttotal: 44.6s\tremaining: 6.25s\n",
      "635:\tlearn: 0.1397916\ttotal: 44.7s\tremaining: 6.18s\n",
      "636:\tlearn: 0.1397912\ttotal: 44.7s\tremaining: 6.11s\n",
      "637:\tlearn: 0.1397870\ttotal: 44.8s\tremaining: 6.04s\n",
      "638:\tlearn: 0.1397824\ttotal: 44.9s\tremaining: 5.97s\n",
      "639:\tlearn: 0.1397772\ttotal: 45s\tremaining: 5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640:\tlearn: 0.1397723\ttotal: 45s\tremaining: 5.83s\n",
      "641:\tlearn: 0.1397693\ttotal: 45.1s\tremaining: 5.76s\n",
      "642:\tlearn: 0.1397659\ttotal: 45.2s\tremaining: 5.69s\n",
      "643:\tlearn: 0.1397625\ttotal: 45.2s\tremaining: 5.62s\n",
      "644:\tlearn: 0.1397563\ttotal: 45.3s\tremaining: 5.55s\n",
      "645:\tlearn: 0.1397505\ttotal: 45.4s\tremaining: 5.48s\n",
      "646:\tlearn: 0.1397443\ttotal: 45.5s\tremaining: 5.41s\n",
      "647:\tlearn: 0.1397407\ttotal: 45.5s\tremaining: 5.34s\n",
      "648:\tlearn: 0.1397351\ttotal: 45.6s\tremaining: 5.27s\n",
      "649:\tlearn: 0.1397309\ttotal: 45.7s\tremaining: 5.2s\n",
      "650:\tlearn: 0.1397274\ttotal: 45.8s\tremaining: 5.13s\n",
      "651:\tlearn: 0.1397257\ttotal: 45.8s\tremaining: 5.06s\n",
      "652:\tlearn: 0.1397223\ttotal: 45.9s\tremaining: 4.99s\n",
      "653:\tlearn: 0.1397187\ttotal: 46s\tremaining: 4.92s\n",
      "654:\tlearn: 0.1397155\ttotal: 46s\tremaining: 4.85s\n",
      "655:\tlearn: 0.1397125\ttotal: 46.1s\tremaining: 4.78s\n",
      "656:\tlearn: 0.1397083\ttotal: 46.2s\tremaining: 4.71s\n",
      "657:\tlearn: 0.1397033\ttotal: 46.2s\tremaining: 4.64s\n",
      "658:\tlearn: 0.1397001\ttotal: 46.3s\tremaining: 4.57s\n",
      "659:\tlearn: 0.1396942\ttotal: 46.4s\tremaining: 4.5s\n",
      "660:\tlearn: 0.1396880\ttotal: 46.5s\tremaining: 4.43s\n",
      "661:\tlearn: 0.1396841\ttotal: 46.5s\tremaining: 4.36s\n",
      "662:\tlearn: 0.1396797\ttotal: 46.6s\tremaining: 4.29s\n",
      "663:\tlearn: 0.1396742\ttotal: 46.7s\tremaining: 4.21s\n",
      "664:\tlearn: 0.1396717\ttotal: 46.7s\tremaining: 4.14s\n",
      "665:\tlearn: 0.1396672\ttotal: 46.8s\tremaining: 4.07s\n",
      "666:\tlearn: 0.1396631\ttotal: 46.9s\tremaining: 4s\n",
      "667:\tlearn: 0.1396602\ttotal: 46.9s\tremaining: 3.93s\n",
      "668:\tlearn: 0.1396559\ttotal: 47s\tremaining: 3.86s\n",
      "669:\tlearn: 0.1396517\ttotal: 47.1s\tremaining: 3.79s\n",
      "670:\tlearn: 0.1396464\ttotal: 47.2s\tremaining: 3.72s\n",
      "671:\tlearn: 0.1396436\ttotal: 47.2s\tremaining: 3.65s\n",
      "672:\tlearn: 0.1396403\ttotal: 47.3s\tremaining: 3.58s\n",
      "673:\tlearn: 0.1396355\ttotal: 47.4s\tremaining: 3.51s\n",
      "674:\tlearn: 0.1396323\ttotal: 47.4s\tremaining: 3.44s\n",
      "675:\tlearn: 0.1396258\ttotal: 47.5s\tremaining: 3.37s\n",
      "676:\tlearn: 0.1396226\ttotal: 47.6s\tremaining: 3.3s\n",
      "677:\tlearn: 0.1396177\ttotal: 47.7s\tremaining: 3.23s\n",
      "678:\tlearn: 0.1396139\ttotal: 47.7s\tremaining: 3.16s\n",
      "679:\tlearn: 0.1396087\ttotal: 47.8s\tremaining: 3.09s\n",
      "680:\tlearn: 0.1396050\ttotal: 47.9s\tremaining: 3.02s\n",
      "681:\tlearn: 0.1396008\ttotal: 47.9s\tremaining: 2.95s\n",
      "682:\tlearn: 0.1395957\ttotal: 48s\tremaining: 2.88s\n",
      "683:\tlearn: 0.1395932\ttotal: 48.1s\tremaining: 2.81s\n",
      "684:\tlearn: 0.1395890\ttotal: 48.2s\tremaining: 2.74s\n",
      "685:\tlearn: 0.1395857\ttotal: 48.2s\tremaining: 2.67s\n",
      "686:\tlearn: 0.1395807\ttotal: 48.3s\tremaining: 2.6s\n",
      "687:\tlearn: 0.1395778\ttotal: 48.4s\tremaining: 2.53s\n",
      "688:\tlearn: 0.1395716\ttotal: 48.4s\tremaining: 2.46s\n",
      "689:\tlearn: 0.1395674\ttotal: 48.5s\tremaining: 2.39s\n",
      "690:\tlearn: 0.1395637\ttotal: 48.6s\tremaining: 2.32s\n",
      "691:\tlearn: 0.1395583\ttotal: 48.7s\tremaining: 2.25s\n",
      "692:\tlearn: 0.1395528\ttotal: 48.8s\tremaining: 2.18s\n",
      "693:\tlearn: 0.1395489\ttotal: 48.9s\tremaining: 2.11s\n",
      "694:\tlearn: 0.1395424\ttotal: 49s\tremaining: 2.04s\n",
      "695:\tlearn: 0.1395380\ttotal: 49s\tremaining: 1.97s\n",
      "696:\tlearn: 0.1395316\ttotal: 49.1s\tremaining: 1.9s\n",
      "697:\tlearn: 0.1395267\ttotal: 49.2s\tremaining: 1.83s\n",
      "698:\tlearn: 0.1395239\ttotal: 49.3s\tremaining: 1.76s\n",
      "699:\tlearn: 0.1395206\ttotal: 49.4s\tremaining: 1.69s\n",
      "700:\tlearn: 0.1395149\ttotal: 49.4s\tremaining: 1.62s\n",
      "701:\tlearn: 0.1395097\ttotal: 49.5s\tremaining: 1.55s\n",
      "702:\tlearn: 0.1395058\ttotal: 49.6s\tremaining: 1.48s\n",
      "703:\tlearn: 0.1395003\ttotal: 49.7s\tremaining: 1.41s\n",
      "704:\tlearn: 0.1394961\ttotal: 49.7s\tremaining: 1.34s\n",
      "705:\tlearn: 0.1394920\ttotal: 49.8s\tremaining: 1.27s\n",
      "706:\tlearn: 0.1394916\ttotal: 49.9s\tremaining: 1.2s\n",
      "707:\tlearn: 0.1394870\ttotal: 49.9s\tremaining: 1.13s\n",
      "708:\tlearn: 0.1394835\ttotal: 50s\tremaining: 1.06s\n",
      "709:\tlearn: 0.1394791\ttotal: 50.1s\tremaining: 988ms\n",
      "710:\tlearn: 0.1394748\ttotal: 50.2s\tremaining: 917ms\n",
      "711:\tlearn: 0.1394731\ttotal: 50.2s\tremaining: 847ms\n",
      "712:\tlearn: 0.1394687\ttotal: 50.3s\tremaining: 776ms\n",
      "713:\tlearn: 0.1394655\ttotal: 50.4s\tremaining: 706ms\n",
      "714:\tlearn: 0.1394622\ttotal: 50.5s\tremaining: 635ms\n",
      "715:\tlearn: 0.1394560\ttotal: 50.5s\tremaining: 565ms\n",
      "716:\tlearn: 0.1394506\ttotal: 50.6s\tremaining: 494ms\n",
      "717:\tlearn: 0.1394474\ttotal: 50.7s\tremaining: 424ms\n",
      "718:\tlearn: 0.1394438\ttotal: 50.8s\tremaining: 353ms\n",
      "719:\tlearn: 0.1394387\ttotal: 50.8s\tremaining: 282ms\n",
      "720:\tlearn: 0.1394357\ttotal: 50.9s\tremaining: 212ms\n",
      "721:\tlearn: 0.1394322\ttotal: 51s\tremaining: 141ms\n",
      "722:\tlearn: 0.1394276\ttotal: 51s\tremaining: 70.6ms\n",
      "723:\tlearn: 0.1394242\ttotal: 51.1s\tremaining: 0us\n",
      "Финальный ROC-AUC: 0.7138754863850251\n"
     ]
    }
   ],
   "source": [
    "# Тестируем на CatBoostClassifier, подбирая параметры с помощью optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,\n",
    "        'class_weights': class_weights_dict,\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "final_preds = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, final_preds)\n",
    "print(\"Финальный ROC-AUC:\", final_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918ab1c",
   "metadata": {},
   "source": [
    "Итог: 0.7138754863850251"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187aa590",
   "metadata": {},
   "source": [
    "### Эксперимент 3\n",
    "Здесь мы пробуем исопльзовать PCA, как замену преобразования (понижения размерности) enc_paym_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe25d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# имопрт данных\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"train_data\")\n",
    "train_target = pd.read_csv(\"train_target.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead44a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определние правил аггрегации и группировка данных\n",
    "aggregations = {\n",
    "    'rn': 'max', \n",
    "    'pre_since_opened': 'median',\n",
    "    'pre_since_confirmed': 'median', \n",
    "    'pre_pterm': 'median',\n",
    "    'pre_fterm': 'median',\n",
    "    'pre_till_pclose': 'median',\n",
    "    'pre_till_fclose': 'median',\n",
    "    'pre_loans_credit_limit': 'median',\n",
    "    'pre_loans_next_pay_summ': 'median',\n",
    "    'pre_loans_outstanding': 'median',\n",
    "    'pre_loans_total_overdue': 'median',\n",
    "    'pre_loans_max_overdue_sum': 'median',\n",
    "    'pre_loans_credit_cost_rate': 'median',\n",
    "    'pre_loans5': 'median',\n",
    "    'pre_loans530': 'median',\n",
    "    'pre_loans3060': 'median',\n",
    "    'pre_loans6090': 'median',\n",
    "    'pre_loans90': 'median',\n",
    "    'is_zero_loans5': 'mean',\n",
    "    'is_zero_loans530': 'mean',\n",
    "    'is_zero_loans3060': 'mean',\n",
    "    'is_zero_loans6090': 'mean',\n",
    "    'is_zero_loans90': 'mean',\n",
    "    'pre_util': 'median',\n",
    "    'pre_over2limit': 'median',\n",
    "    'pre_maxover2limit': 'median',\n",
    "    'is_zero_util': 'mean',\n",
    "    'is_zero_over2limit': 'mean',\n",
    "    'is_zero_maxover2limit': 'mean',\n",
    "    'enc_loans_account_holder_type': 'median',\n",
    "    'enc_loans_credit_status': 'median',\n",
    "    'enc_loans_account_cur': 'median',\n",
    "    'enc_loans_credit_type': 'median',\n",
    "    'pclose_flag': 'median',\n",
    "    'fclose_flag': 'median',\n",
    "    'enc_paym_0': 'median',\n",
    "    'enc_paym_1': 'median',\n",
    "    'enc_paym_2': 'median',\n",
    "    'enc_paym_3': 'median',\n",
    "    'enc_paym_4': 'median',\n",
    "    'enc_paym_5': 'median',\n",
    "    'enc_paym_6': 'median',\n",
    "    'enc_paym_7': 'median',\n",
    "    'enc_paym_8': 'median',\n",
    "    'enc_paym_9': 'median',\n",
    "    'enc_paym_10': 'median',\n",
    "    'enc_paym_11': 'median',\n",
    "    'enc_paym_12': 'median',\n",
    "    'enc_paym_13': 'median',\n",
    "    'enc_paym_14': 'median',\n",
    "    'enc_paym_15': 'median',\n",
    "    'enc_paym_16': 'median',\n",
    "    'enc_paym_17': 'median',\n",
    "    'enc_paym_18': 'median',\n",
    "    'enc_paym_19': 'median',\n",
    "    'enc_paym_20': 'median',\n",
    "    'enc_paym_21': 'median',\n",
    "    'enc_paym_22': 'median',\n",
    "    'enc_paym_23': 'median',\n",
    "    'enc_paym_24': 'median'\n",
    "}\n",
    "grouped_df = df.groupby('id').agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4476163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использвоание PCA для преобразования enc_paym_N\n",
    "from sklearn.decomposition import PCA\n",
    "enc_paym_columns = [f'enc_paym_{i}' for i in range(25)] \n",
    "X = grouped_df[enc_paym_columns]\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "df_pca = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2'])\n",
    "df_pca['id'] = grouped_df['id']\n",
    "grouped_df.drop(enc_paym_columns, axis=1, inplace=True)\n",
    "pca_df = grouped_df.merge(df_pca, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f96adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение с таргетом\n",
    "final_df = pca_df.merge(train_target, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f055e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>is_zero_maxover2limit</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>enc_loans_credit_status</th>\n",
       "      <th>enc_loans_account_cur</th>\n",
       "      <th>enc_loans_credit_type</th>\n",
       "      <th>pclose_flag</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.634182</td>\n",
       "      <td>-1.863417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.044334</td>\n",
       "      <td>-0.780536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.692204</td>\n",
       "      <td>-2.391195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.780740</td>\n",
       "      <td>-2.181642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.161593</td>\n",
       "      <td>3.915705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  pre_fterm  \\\n",
       "0   0  10               5.0                  9.0        6.5        8.0   \n",
       "1   1  14              12.5                  7.0        7.0        8.0   \n",
       "2   2   3              12.0                  9.0        4.0        8.0   \n",
       "3   3  15               6.0                  9.0        4.0        8.0   \n",
       "4   4   1              12.0                  9.0        4.0        8.0   \n",
       "\n",
       "   pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "0             12.0             11.0                    11.0   \n",
       "1              9.0              6.5                     6.0   \n",
       "2              1.0             11.0                     1.0   \n",
       "3              3.0             10.0                    11.0   \n",
       "4              1.0             11.0                    12.0   \n",
       "\n",
       "   pre_loans_next_pay_summ  ...  is_zero_maxover2limit  \\\n",
       "0                      3.0  ...               0.900000   \n",
       "1                      2.0  ...               0.785714   \n",
       "2                      1.0  ...               0.666667   \n",
       "3                      2.0  ...               0.933333   \n",
       "4                      1.0  ...               1.000000   \n",
       "\n",
       "   enc_loans_account_holder_type  enc_loans_credit_status  \\\n",
       "0                            1.0                      3.0   \n",
       "1                            1.0                      3.0   \n",
       "2                            1.0                      2.0   \n",
       "3                            1.0                      3.0   \n",
       "4                            1.0                      2.0   \n",
       "\n",
       "   enc_loans_account_cur  enc_loans_credit_type  pclose_flag  fclose_flag  \\\n",
       "0                    1.0                    4.0          0.0          0.0   \n",
       "1                    1.0                    4.0          0.0          0.0   \n",
       "2                    1.0                    3.0          1.0          1.0   \n",
       "3                    1.0                    4.0          0.0          0.0   \n",
       "4                    1.0                    3.0          1.0          1.0   \n",
       "\n",
       "       PCA1      PCA2  flag  \n",
       "0 -0.634182 -1.863417     0  \n",
       "1 -1.044334 -0.780536     0  \n",
       "2 -0.692204 -2.391195     0  \n",
       "3  2.780740 -2.181642     0  \n",
       "4 -5.161593  3.915705     0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c597b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>is_zero_maxover2limit</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>enc_loans_credit_status</th>\n",
       "      <th>enc_loans_account_cur</th>\n",
       "      <th>enc_loans_credit_type</th>\n",
       "      <th>pclose_flag</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074279</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>-0.003865</td>\n",
       "      <td>-0.012971</td>\n",
       "      <td>-0.022741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034301</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>-0.005245</td>\n",
       "      <td>0.090867</td>\n",
       "      <td>-0.038292</td>\n",
       "      <td>-0.030114</td>\n",
       "      <td>4.263053e-02</td>\n",
       "      <td>-4.261130e-02</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rn</th>\n",
       "      <td>0.074279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022856</td>\n",
       "      <td>-0.011241</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>-0.016063</td>\n",
       "      <td>0.073501</td>\n",
       "      <td>-0.055806</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>-0.200790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>-0.068007</td>\n",
       "      <td>0.479661</td>\n",
       "      <td>-0.016342</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>-0.291479</td>\n",
       "      <td>-0.370548</td>\n",
       "      <td>-6.294235e-02</td>\n",
       "      <td>-2.610057e-01</td>\n",
       "      <td>-0.014138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_since_opened</th>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.022856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015967</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>-0.032863</td>\n",
       "      <td>-0.054148</td>\n",
       "      <td>-0.006013</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>-0.005022</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>0.015189</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>-0.016724</td>\n",
       "      <td>-6.050729e-02</td>\n",
       "      <td>1.706300e-01</td>\n",
       "      <td>0.011584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <td>0.012538</td>\n",
       "      <td>-0.011241</td>\n",
       "      <td>-0.015967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025293</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.021289</td>\n",
       "      <td>-0.071005</td>\n",
       "      <td>-0.010780</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013476</td>\n",
       "      <td>-0.003496</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>-0.040799</td>\n",
       "      <td>0.032918</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>3.943669e-02</td>\n",
       "      <td>-1.439267e-02</td>\n",
       "      <td>-0.006152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_pterm</th>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.025293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083474</td>\n",
       "      <td>0.275438</td>\n",
       "      <td>-0.071958</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>-0.058705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094911</td>\n",
       "      <td>-0.044209</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.145605</td>\n",
       "      <td>-0.307900</td>\n",
       "      <td>-0.192805</td>\n",
       "      <td>1.351234e-02</td>\n",
       "      <td>-1.984303e-01</td>\n",
       "      <td>-0.007316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_fterm</th>\n",
       "      <td>0.008800</td>\n",
       "      <td>-0.016063</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.083474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.002708</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049685</td>\n",
       "      <td>-0.019735</td>\n",
       "      <td>0.036652</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>-0.011496</td>\n",
       "      <td>-0.067113</td>\n",
       "      <td>2.262062e-01</td>\n",
       "      <td>-3.234167e-02</td>\n",
       "      <td>-0.013389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.073501</td>\n",
       "      <td>-0.032863</td>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.275438</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067357</td>\n",
       "      <td>0.034717</td>\n",
       "      <td>-0.082038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136103</td>\n",
       "      <td>-0.066251</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>0.157355</td>\n",
       "      <td>-0.431777</td>\n",
       "      <td>-0.184868</td>\n",
       "      <td>1.966996e-02</td>\n",
       "      <td>-3.078653e-02</td>\n",
       "      <td>0.003658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <td>-0.003865</td>\n",
       "      <td>-0.055806</td>\n",
       "      <td>-0.054148</td>\n",
       "      <td>-0.071005</td>\n",
       "      <td>-0.071958</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.067357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>-0.211587</td>\n",
       "      <td>-0.013421</td>\n",
       "      <td>-0.017223</td>\n",
       "      <td>0.148067</td>\n",
       "      <td>0.311906</td>\n",
       "      <td>1.150663e-03</td>\n",
       "      <td>3.346705e-02</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <td>-0.012971</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>-0.006013</td>\n",
       "      <td>-0.010780</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>-0.002708</td>\n",
       "      <td>0.034717</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009959</td>\n",
       "      <td>-0.070457</td>\n",
       "      <td>-0.006416</td>\n",
       "      <td>-0.020803</td>\n",
       "      <td>0.127687</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>-5.919980e-02</td>\n",
       "      <td>7.783502e-03</td>\n",
       "      <td>0.019402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <td>-0.022741</td>\n",
       "      <td>-0.200790</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>-0.058705</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>-0.082038</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>-0.028141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.038693</td>\n",
       "      <td>-0.197996</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>-0.093174</td>\n",
       "      <td>0.185576</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>-1.496049e-02</td>\n",
       "      <td>8.337432e-02</td>\n",
       "      <td>0.007076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans_outstanding</th>\n",
       "      <td>-0.011446</td>\n",
       "      <td>-0.021604</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.030023</td>\n",
       "      <td>0.031970</td>\n",
       "      <td>0.040904</td>\n",
       "      <td>-0.032090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>-0.158515</td>\n",
       "      <td>-0.033957</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>0.126461</td>\n",
       "      <td>0.048672</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>-1.031337e-02</td>\n",
       "      <td>2.284212e-03</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans_total_overdue</th>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.030709</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-1.070011e-04</td>\n",
       "      <td>-6.143656e-04</td>\n",
       "      <td>0.003010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans_max_overdue_sum</th>\n",
       "      <td>-0.002715</td>\n",
       "      <td>-0.005267</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>-0.014056</td>\n",
       "      <td>-0.012973</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.018362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.013269</td>\n",
       "      <td>-0.006538</td>\n",
       "      <td>-0.001744</td>\n",
       "      <td>0.028688</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>-4.955727e-03</td>\n",
       "      <td>-1.855381e-02</td>\n",
       "      <td>-0.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans_credit_cost_rate</th>\n",
       "      <td>-0.005280</td>\n",
       "      <td>-0.126976</td>\n",
       "      <td>-0.058715</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>-0.051545</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>-0.012451</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>-0.060160</td>\n",
       "      <td>0.120380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>-0.099978</td>\n",
       "      <td>-0.005311</td>\n",
       "      <td>-0.010096</td>\n",
       "      <td>0.105098</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>-2.739428e-02</td>\n",
       "      <td>5.554075e-02</td>\n",
       "      <td>0.007601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans5</th>\n",
       "      <td>-0.001325</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>0.022330</td>\n",
       "      <td>-0.002328</td>\n",
       "      <td>-0.016295</td>\n",
       "      <td>-0.013229</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>-0.010324</td>\n",
       "      <td>0.032473</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>0.025413</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>-3.753921e-02</td>\n",
       "      <td>-4.931592e-02</td>\n",
       "      <td>-0.009945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans530</th>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>-0.001331</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>-0.016209</td>\n",
       "      <td>0.018619</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112643</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>-0.009709</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>-0.049197</td>\n",
       "      <td>-0.019128</td>\n",
       "      <td>-5.161570e-02</td>\n",
       "      <td>-5.839997e-02</td>\n",
       "      <td>-0.007114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans3060</th>\n",
       "      <td>0.002023</td>\n",
       "      <td>-0.012110</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>-0.007889</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.007120</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>7.494298e-03</td>\n",
       "      <td>1.593881e-02</td>\n",
       "      <td>0.005146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans6090</th>\n",
       "      <td>-0.002710</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>-0.002040</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>-1.531698e-03</td>\n",
       "      <td>-6.238607e-03</td>\n",
       "      <td>-0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_loans90</th>\n",
       "      <td>0.006018</td>\n",
       "      <td>-0.015414</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021517</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>-0.007850</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>-4.709490e-03</td>\n",
       "      <td>1.801714e-02</td>\n",
       "      <td>0.005933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_loans5</th>\n",
       "      <td>0.040065</td>\n",
       "      <td>-0.029281</td>\n",
       "      <td>-0.006399</td>\n",
       "      <td>-0.014000</td>\n",
       "      <td>-0.037949</td>\n",
       "      <td>-0.032891</td>\n",
       "      <td>-0.090053</td>\n",
       "      <td>-0.022146</td>\n",
       "      <td>-0.007547</td>\n",
       "      <td>0.082017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123440</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.045003</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.024803</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>-0.024452</td>\n",
       "      <td>-1.713536e-01</td>\n",
       "      <td>-3.452766e-02</td>\n",
       "      <td>-0.032215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_loans530</th>\n",
       "      <td>-0.001111</td>\n",
       "      <td>-0.032421</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>-0.010960</td>\n",
       "      <td>-0.064339</td>\n",
       "      <td>0.047294</td>\n",
       "      <td>0.047864</td>\n",
       "      <td>-0.018302</td>\n",
       "      <td>-0.006622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531929</td>\n",
       "      <td>0.039593</td>\n",
       "      <td>-0.125723</td>\n",
       "      <td>-0.004848</td>\n",
       "      <td>-0.096060</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>0.117030</td>\n",
       "      <td>-1.617091e-01</td>\n",
       "      <td>2.914049e-02</td>\n",
       "      <td>-0.056670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_loans3060</th>\n",
       "      <td>-0.017132</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>-0.071855</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>-0.020805</td>\n",
       "      <td>-0.042945</td>\n",
       "      <td>-0.008315</td>\n",
       "      <td>0.051698</td>\n",
       "      <td>-0.023080</td>\n",
       "      <td>0.059896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160502</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>-0.110516</td>\n",
       "      <td>-0.009500</td>\n",
       "      <td>-0.007913</td>\n",
       "      <td>0.067321</td>\n",
       "      <td>0.056011</td>\n",
       "      <td>-3.434544e-02</td>\n",
       "      <td>-1.220987e-01</td>\n",
       "      <td>-0.070019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_loans6090</th>\n",
       "      <td>-0.027364</td>\n",
       "      <td>0.029270</td>\n",
       "      <td>-0.072559</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>-0.014844</td>\n",
       "      <td>-0.042804</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.051958</td>\n",
       "      <td>-0.020912</td>\n",
       "      <td>0.049793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133066</td>\n",
       "      <td>0.012792</td>\n",
       "      <td>-0.102942</td>\n",
       "      <td>-0.008707</td>\n",
       "      <td>-0.003230</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.049744</td>\n",
       "      <td>1.511282e-02</td>\n",
       "      <td>-1.366636e-01</td>\n",
       "      <td>-0.067050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_loans90</th>\n",
       "      <td>-0.026417</td>\n",
       "      <td>0.036618</td>\n",
       "      <td>-0.079110</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-0.044213</td>\n",
       "      <td>0.013939</td>\n",
       "      <td>0.053910</td>\n",
       "      <td>-0.019480</td>\n",
       "      <td>0.046519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160941</td>\n",
       "      <td>0.012475</td>\n",
       "      <td>-0.108508</td>\n",
       "      <td>-0.012855</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.038580</td>\n",
       "      <td>0.046979</td>\n",
       "      <td>4.643185e-02</td>\n",
       "      <td>-1.558903e-01</td>\n",
       "      <td>-0.068420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_util</th>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>-0.014122</td>\n",
       "      <td>0.050642</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>-0.099652</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>-0.194025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052367</td>\n",
       "      <td>-0.093369</td>\n",
       "      <td>0.524377</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.227483</td>\n",
       "      <td>-0.229178</td>\n",
       "      <td>-0.379402</td>\n",
       "      <td>4.506999e-02</td>\n",
       "      <td>-1.883282e-01</td>\n",
       "      <td>-0.041547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_over2limit</th>\n",
       "      <td>0.005104</td>\n",
       "      <td>-0.111945</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>-0.023638</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.035781</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>0.026018</td>\n",
       "      <td>-0.007190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360377</td>\n",
       "      <td>0.140895</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>-0.113613</td>\n",
       "      <td>0.094760</td>\n",
       "      <td>0.079018</td>\n",
       "      <td>-2.406333e-02</td>\n",
       "      <td>1.184876e-01</td>\n",
       "      <td>0.018330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_maxover2limit</th>\n",
       "      <td>0.026643</td>\n",
       "      <td>0.155568</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>-0.004811</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.068287</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>-0.024166</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546829</td>\n",
       "      <td>-0.116001</td>\n",
       "      <td>0.029427</td>\n",
       "      <td>-0.003971</td>\n",
       "      <td>0.088051</td>\n",
       "      <td>-0.156459</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>1.124425e-02</td>\n",
       "      <td>-1.084936e-01</td>\n",
       "      <td>-0.029647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_util</th>\n",
       "      <td>-0.007955</td>\n",
       "      <td>0.365181</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>-0.020858</td>\n",
       "      <td>0.049531</td>\n",
       "      <td>-0.011139</td>\n",
       "      <td>0.043150</td>\n",
       "      <td>-0.173225</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>-0.204414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>-0.088764</td>\n",
       "      <td>0.649281</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.246454</td>\n",
       "      <td>-0.216407</td>\n",
       "      <td>-0.422438</td>\n",
       "      <td>2.378043e-02</td>\n",
       "      <td>-1.665683e-01</td>\n",
       "      <td>-0.047293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_over2limit</th>\n",
       "      <td>-0.059779</td>\n",
       "      <td>-0.024674</td>\n",
       "      <td>-0.024220</td>\n",
       "      <td>-0.007598</td>\n",
       "      <td>0.032368</td>\n",
       "      <td>-0.018403</td>\n",
       "      <td>0.050935</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>-0.016874</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586574</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>-0.086255</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.146183</td>\n",
       "      <td>-0.000562</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>7.040611e-03</td>\n",
       "      <td>-8.404998e-02</td>\n",
       "      <td>-0.017485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_zero_maxover2limit</th>\n",
       "      <td>0.034301</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>-0.013476</td>\n",
       "      <td>0.094911</td>\n",
       "      <td>-0.049685</td>\n",
       "      <td>0.136103</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>-0.009959</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047715</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>-0.116686</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>-8.283326e-02</td>\n",
       "      <td>-4.037564e-02</td>\n",
       "      <td>-0.038408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <td>0.006625</td>\n",
       "      <td>-0.068007</td>\n",
       "      <td>-0.005022</td>\n",
       "      <td>-0.003496</td>\n",
       "      <td>-0.044209</td>\n",
       "      <td>-0.019735</td>\n",
       "      <td>-0.066251</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>-0.070457</td>\n",
       "      <td>0.038693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084407</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>-0.318540</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>0.094829</td>\n",
       "      <td>4.932169e-04</td>\n",
       "      <td>7.720033e-02</td>\n",
       "      <td>-0.005477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_loans_credit_status</th>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.479661</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>0.036652</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>-0.211587</td>\n",
       "      <td>-0.006416</td>\n",
       "      <td>-0.197996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>-0.084407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.278608</td>\n",
       "      <td>-0.294270</td>\n",
       "      <td>-0.597270</td>\n",
       "      <td>1.317383e-03</td>\n",
       "      <td>-1.993140e-01</td>\n",
       "      <td>-0.029797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_loans_account_cur</th>\n",
       "      <td>-0.005245</td>\n",
       "      <td>-0.016342</td>\n",
       "      <td>0.015189</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>-0.013421</td>\n",
       "      <td>-0.020803</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034283</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>1.264118e-02</td>\n",
       "      <td>1.744470e-02</td>\n",
       "      <td>-0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc_loans_credit_type</th>\n",
       "      <td>0.090867</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.040799</td>\n",
       "      <td>0.145605</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>0.157355</td>\n",
       "      <td>-0.017223</td>\n",
       "      <td>0.127687</td>\n",
       "      <td>-0.093174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>-0.318540</td>\n",
       "      <td>0.278608</td>\n",
       "      <td>-0.034283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.168929</td>\n",
       "      <td>-0.270234</td>\n",
       "      <td>-1.431520e-01</td>\n",
       "      <td>-1.615784e-01</td>\n",
       "      <td>0.022509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclose_flag</th>\n",
       "      <td>-0.038292</td>\n",
       "      <td>-0.291479</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>0.032918</td>\n",
       "      <td>-0.307900</td>\n",
       "      <td>-0.011496</td>\n",
       "      <td>-0.431777</td>\n",
       "      <td>0.148067</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>0.185576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116686</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>-0.294270</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.168929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458370</td>\n",
       "      <td>-5.312827e-02</td>\n",
       "      <td>1.553557e-01</td>\n",
       "      <td>0.018032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fclose_flag</th>\n",
       "      <td>-0.030114</td>\n",
       "      <td>-0.370548</td>\n",
       "      <td>-0.016724</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>-0.192805</td>\n",
       "      <td>-0.067113</td>\n",
       "      <td>-0.184868</td>\n",
       "      <td>0.311906</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.094829</td>\n",
       "      <td>-0.597270</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>-0.270234</td>\n",
       "      <td>0.458370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.350276e-03</td>\n",
       "      <td>2.165154e-01</td>\n",
       "      <td>0.023005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA1</th>\n",
       "      <td>0.042631</td>\n",
       "      <td>-0.062942</td>\n",
       "      <td>-0.060507</td>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>0.226206</td>\n",
       "      <td>0.019670</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>-0.059200</td>\n",
       "      <td>-0.014960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082833</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>-0.143152</td>\n",
       "      <td>-0.053128</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.507718e-16</td>\n",
       "      <td>-0.059593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA2</th>\n",
       "      <td>-0.042611</td>\n",
       "      <td>-0.261006</td>\n",
       "      <td>0.170630</td>\n",
       "      <td>-0.014393</td>\n",
       "      <td>-0.198430</td>\n",
       "      <td>-0.032342</td>\n",
       "      <td>-0.030787</td>\n",
       "      <td>0.033467</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.083374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040376</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>-0.199314</td>\n",
       "      <td>0.017445</td>\n",
       "      <td>-0.161578</td>\n",
       "      <td>0.155356</td>\n",
       "      <td>0.216515</td>\n",
       "      <td>4.507718e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.043542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.014138</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.013389</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038408</td>\n",
       "      <td>-0.005477</td>\n",
       "      <td>-0.029797</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>0.023005</td>\n",
       "      <td>-5.959303e-02</td>\n",
       "      <td>4.354217e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        rn  pre_since_opened  \\\n",
       "id                             1.000000  0.074279          0.041197   \n",
       "rn                             0.074279  1.000000          0.022856   \n",
       "pre_since_opened               0.041197  0.022856          1.000000   \n",
       "pre_since_confirmed            0.012538 -0.011241         -0.015967   \n",
       "pre_pterm                      0.012521  0.027872          0.000199   \n",
       "pre_fterm                      0.008800 -0.016063          0.018226   \n",
       "pre_till_pclose                0.014166  0.073501         -0.032863   \n",
       "pre_till_fclose               -0.003865 -0.055806         -0.054148   \n",
       "pre_loans_credit_limit        -0.012971  0.016918         -0.006013   \n",
       "pre_loans_next_pay_summ       -0.022741 -0.200790          0.005154   \n",
       "pre_loans_outstanding         -0.011446 -0.021604          0.001371   \n",
       "pre_loans_total_overdue       -0.000035 -0.000722          0.001034   \n",
       "pre_loans_max_overdue_sum     -0.002715 -0.005267         -0.002377   \n",
       "pre_loans_credit_cost_rate    -0.005280 -0.126976         -0.058715   \n",
       "pre_loans5                    -0.001325  0.037357          0.001427   \n",
       "pre_loans530                   0.009352  0.050420          0.002422   \n",
       "pre_loans3060                  0.002023 -0.012110         -0.000373   \n",
       "pre_loans6090                 -0.002710  0.005034         -0.000810   \n",
       "pre_loans90                    0.006018 -0.015414          0.003179   \n",
       "is_zero_loans5                 0.040065 -0.029281         -0.006399   \n",
       "is_zero_loans530              -0.001111 -0.032421          0.003686   \n",
       "is_zero_loans3060             -0.017132  0.020036         -0.071855   \n",
       "is_zero_loans6090             -0.027364  0.029270         -0.072559   \n",
       "is_zero_loans90               -0.026417  0.036618         -0.079110   \n",
       "pre_util                       0.008557  0.367036         -0.009947   \n",
       "pre_over2limit                 0.005104 -0.111945          0.007185   \n",
       "pre_maxover2limit              0.026643  0.155568          0.007481   \n",
       "is_zero_util                  -0.007955  0.365181         -0.000576   \n",
       "is_zero_over2limit            -0.059779 -0.024674         -0.024220   \n",
       "is_zero_maxover2limit          0.034301 -0.000908          0.009194   \n",
       "enc_loans_account_holder_type  0.006625 -0.068007         -0.005022   \n",
       "enc_loans_credit_status        0.002197  0.479661          0.031123   \n",
       "enc_loans_account_cur         -0.005245 -0.016342          0.015189   \n",
       "enc_loans_credit_type          0.090867  0.311111          0.000534   \n",
       "pclose_flag                   -0.038292 -0.291479         -0.009273   \n",
       "fclose_flag                   -0.030114 -0.370548         -0.016724   \n",
       "PCA1                           0.042631 -0.062942         -0.060507   \n",
       "PCA2                          -0.042611 -0.261006          0.170630   \n",
       "flag                          -0.000037 -0.014138          0.011584   \n",
       "\n",
       "                               pre_since_confirmed  pre_pterm  pre_fterm  \\\n",
       "id                                        0.012538   0.012521   0.008800   \n",
       "rn                                       -0.011241   0.027872  -0.016063   \n",
       "pre_since_opened                         -0.015967   0.000199   0.018226   \n",
       "pre_since_confirmed                       1.000000  -0.025293   0.016467   \n",
       "pre_pterm                                -0.025293   1.000000   0.083474   \n",
       "pre_fterm                                 0.016467   0.083474   1.000000   \n",
       "pre_till_pclose                           0.021289   0.275438   0.076098   \n",
       "pre_till_fclose                          -0.071005  -0.071958   0.000979   \n",
       "pre_loans_credit_limit                   -0.010780   0.016123  -0.002708   \n",
       "pre_loans_next_pay_summ                   0.006327  -0.058705   0.010614   \n",
       "pre_loans_outstanding                     0.010777   0.014474   0.018529   \n",
       "pre_loans_total_overdue                  -0.000237   0.001094   0.001933   \n",
       "pre_loans_max_overdue_sum                -0.001687  -0.002538  -0.014056   \n",
       "pre_loans_credit_cost_rate                0.018966  -0.051545   0.014628   \n",
       "pre_loans5                               -0.002580   0.022330  -0.002328   \n",
       "pre_loans530                             -0.001331   0.013754  -0.016209   \n",
       "pre_loans3060                            -0.001736  -0.005104   0.001942   \n",
       "pre_loans6090                             0.000419   0.002867  -0.000158   \n",
       "pre_loans90                              -0.002145  -0.005153   0.000576   \n",
       "is_zero_loans5                           -0.014000  -0.037949  -0.032891   \n",
       "is_zero_loans530                          0.000868  -0.010960  -0.064339   \n",
       "is_zero_loans3060                         0.005114  -0.020805  -0.042945   \n",
       "is_zero_loans6090                         0.004861  -0.014844  -0.042804   \n",
       "is_zero_loans90                           0.009652  -0.009384  -0.044213   \n",
       "pre_util                                 -0.014122   0.050642   0.011649   \n",
       "pre_over2limit                            0.008033  -0.023638   0.000908   \n",
       "pre_maxover2limit                        -0.004811   0.026392   0.001434   \n",
       "is_zero_util                             -0.020858   0.049531  -0.011139   \n",
       "is_zero_over2limit                       -0.007598   0.032368  -0.018403   \n",
       "is_zero_maxover2limit                    -0.013476   0.094911  -0.049685   \n",
       "enc_loans_account_holder_type            -0.003496  -0.044209  -0.019735   \n",
       "enc_loans_credit_status                   0.007781   0.105707   0.036652   \n",
       "enc_loans_account_cur                    -0.002123   0.001329   0.007494   \n",
       "enc_loans_credit_type                    -0.040799   0.145605   0.022163   \n",
       "pclose_flag                               0.032918  -0.307900  -0.011496   \n",
       "fclose_flag                               0.002133  -0.192805  -0.067113   \n",
       "PCA1                                      0.039437   0.013512   0.226206   \n",
       "PCA2                                     -0.014393  -0.198430  -0.032342   \n",
       "flag                                     -0.006152  -0.007316  -0.013389   \n",
       "\n",
       "                               pre_till_pclose  pre_till_fclose  \\\n",
       "id                                    0.014166        -0.003865   \n",
       "rn                                    0.073501        -0.055806   \n",
       "pre_since_opened                     -0.032863        -0.054148   \n",
       "pre_since_confirmed                   0.021289        -0.071005   \n",
       "pre_pterm                             0.275438        -0.071958   \n",
       "pre_fterm                             0.076098         0.000979   \n",
       "pre_till_pclose                       1.000000        -0.067357   \n",
       "pre_till_fclose                      -0.067357         1.000000   \n",
       "pre_loans_credit_limit                0.034717         0.019196   \n",
       "pre_loans_next_pay_summ              -0.082038         0.021807   \n",
       "pre_loans_outstanding                 0.030023         0.031970   \n",
       "pre_loans_total_overdue              -0.000439        -0.000038   \n",
       "pre_loans_max_overdue_sum            -0.012973         0.004930   \n",
       "pre_loans_credit_cost_rate           -0.012451         0.038396   \n",
       "pre_loans5                           -0.016295        -0.013229   \n",
       "pre_loans530                          0.018619         0.001714   \n",
       "pre_loans3060                         0.003893         0.003611   \n",
       "pre_loans6090                        -0.000704        -0.002040   \n",
       "pre_loans90                           0.004440         0.000613   \n",
       "is_zero_loans5                       -0.090053        -0.022146   \n",
       "is_zero_loans530                      0.047294         0.047864   \n",
       "is_zero_loans3060                    -0.008315         0.051698   \n",
       "is_zero_loans6090                     0.004951         0.051958   \n",
       "is_zero_loans90                       0.013939         0.053910   \n",
       "pre_util                              0.057786        -0.099652   \n",
       "pre_over2limit                       -0.035781        -0.000253   \n",
       "pre_maxover2limit                     0.068287        -0.001176   \n",
       "is_zero_util                          0.043150        -0.173225   \n",
       "is_zero_over2limit                    0.050935         0.010757   \n",
       "is_zero_maxover2limit                 0.136103        -0.001470   \n",
       "enc_loans_account_holder_type        -0.066251         0.011508   \n",
       "enc_loans_credit_status               0.086069        -0.211587   \n",
       "enc_loans_account_cur                -0.000285        -0.013421   \n",
       "enc_loans_credit_type                 0.157355        -0.017223   \n",
       "pclose_flag                          -0.431777         0.148067   \n",
       "fclose_flag                          -0.184868         0.311906   \n",
       "PCA1                                  0.019670         0.001151   \n",
       "PCA2                                 -0.030787         0.033467   \n",
       "flag                                  0.003658         0.002761   \n",
       "\n",
       "                               pre_loans_credit_limit  \\\n",
       "id                                          -0.012971   \n",
       "rn                                           0.016918   \n",
       "pre_since_opened                            -0.006013   \n",
       "pre_since_confirmed                         -0.010780   \n",
       "pre_pterm                                    0.016123   \n",
       "pre_fterm                                   -0.002708   \n",
       "pre_till_pclose                              0.034717   \n",
       "pre_till_fclose                              0.019196   \n",
       "pre_loans_credit_limit                       1.000000   \n",
       "pre_loans_next_pay_summ                     -0.028141   \n",
       "pre_loans_outstanding                        0.040904   \n",
       "pre_loans_total_overdue                     -0.001199   \n",
       "pre_loans_max_overdue_sum                    0.003468   \n",
       "pre_loans_credit_cost_rate                  -0.060160   \n",
       "pre_loans5                                  -0.002676   \n",
       "pre_loans530                                -0.000097   \n",
       "pre_loans3060                                0.001421   \n",
       "pre_loans6090                               -0.000867   \n",
       "pre_loans90                                  0.001354   \n",
       "is_zero_loans5                              -0.007547   \n",
       "is_zero_loans530                            -0.018302   \n",
       "is_zero_loans3060                           -0.023080   \n",
       "is_zero_loans6090                           -0.020912   \n",
       "is_zero_loans90                             -0.019480   \n",
       "pre_util                                    -0.001530   \n",
       "pre_over2limit                               0.026018   \n",
       "pre_maxover2limit                           -0.024166   \n",
       "is_zero_util                                -0.001211   \n",
       "is_zero_over2limit                          -0.016874   \n",
       "is_zero_maxover2limit                       -0.009959   \n",
       "enc_loans_account_holder_type               -0.070457   \n",
       "enc_loans_credit_status                     -0.006416   \n",
       "enc_loans_account_cur                       -0.020803   \n",
       "enc_loans_credit_type                        0.127687   \n",
       "pclose_flag                                  0.021679   \n",
       "fclose_flag                                  0.003282   \n",
       "PCA1                                        -0.059200   \n",
       "PCA2                                         0.007784   \n",
       "flag                                         0.019402   \n",
       "\n",
       "                               pre_loans_next_pay_summ  ...  \\\n",
       "id                                           -0.022741  ...   \n",
       "rn                                           -0.200790  ...   \n",
       "pre_since_opened                              0.005154  ...   \n",
       "pre_since_confirmed                           0.006327  ...   \n",
       "pre_pterm                                    -0.058705  ...   \n",
       "pre_fterm                                     0.010614  ...   \n",
       "pre_till_pclose                              -0.082038  ...   \n",
       "pre_till_fclose                               0.021807  ...   \n",
       "pre_loans_credit_limit                       -0.028141  ...   \n",
       "pre_loans_next_pay_summ                       1.000000  ...   \n",
       "pre_loans_outstanding                        -0.032090  ...   \n",
       "pre_loans_total_overdue                       0.002052  ...   \n",
       "pre_loans_max_overdue_sum                     0.018362  ...   \n",
       "pre_loans_credit_cost_rate                    0.120380  ...   \n",
       "pre_loans5                                    0.000899  ...   \n",
       "pre_loans530                                 -0.028735  ...   \n",
       "pre_loans3060                                -0.000953  ...   \n",
       "pre_loans6090                                 0.000594  ...   \n",
       "pre_loans90                                  -0.002021  ...   \n",
       "is_zero_loans5                                0.082017  ...   \n",
       "is_zero_loans530                             -0.006622  ...   \n",
       "is_zero_loans3060                             0.059896  ...   \n",
       "is_zero_loans6090                             0.049793  ...   \n",
       "is_zero_loans90                               0.046519  ...   \n",
       "pre_util                                     -0.194025  ...   \n",
       "pre_over2limit                               -0.007190  ...   \n",
       "pre_maxover2limit                            -0.024605  ...   \n",
       "is_zero_util                                 -0.204414  ...   \n",
       "is_zero_over2limit                            0.091454  ...   \n",
       "is_zero_maxover2limit                        -0.000142  ...   \n",
       "enc_loans_account_holder_type                 0.038693  ...   \n",
       "enc_loans_credit_status                      -0.197996  ...   \n",
       "enc_loans_account_cur                         0.004989  ...   \n",
       "enc_loans_credit_type                        -0.093174  ...   \n",
       "pclose_flag                                   0.185576  ...   \n",
       "fclose_flag                                   0.125628  ...   \n",
       "PCA1                                         -0.014960  ...   \n",
       "PCA2                                          0.083374  ...   \n",
       "flag                                          0.007076  ...   \n",
       "\n",
       "                               is_zero_maxover2limit  \\\n",
       "id                                          0.034301   \n",
       "rn                                         -0.000908   \n",
       "pre_since_opened                            0.009194   \n",
       "pre_since_confirmed                        -0.013476   \n",
       "pre_pterm                                   0.094911   \n",
       "pre_fterm                                  -0.049685   \n",
       "pre_till_pclose                             0.136103   \n",
       "pre_till_fclose                            -0.001470   \n",
       "pre_loans_credit_limit                     -0.009959   \n",
       "pre_loans_next_pay_summ                    -0.000142   \n",
       "pre_loans_outstanding                       0.004667   \n",
       "pre_loans_total_overdue                    -0.002694   \n",
       "pre_loans_max_overdue_sum                   0.005129   \n",
       "pre_loans_credit_cost_rate                  0.013540   \n",
       "pre_loans5                                  0.011816   \n",
       "pre_loans530                                0.112643   \n",
       "pre_loans3060                              -0.013152   \n",
       "pre_loans6090                               0.006156   \n",
       "pre_loans90                                -0.021517   \n",
       "is_zero_loans5                              0.123440   \n",
       "is_zero_loans530                            0.531929   \n",
       "is_zero_loans3060                           0.160502   \n",
       "is_zero_loans6090                           0.133066   \n",
       "is_zero_loans90                             0.160941   \n",
       "pre_util                                    0.052367   \n",
       "pre_over2limit                             -0.360377   \n",
       "pre_maxover2limit                           0.546829   \n",
       "is_zero_util                                0.099734   \n",
       "is_zero_over2limit                          0.586574   \n",
       "is_zero_maxover2limit                       1.000000   \n",
       "enc_loans_account_holder_type              -0.047715   \n",
       "enc_loans_credit_status                    -0.090463   \n",
       "enc_loans_account_cur                       0.000153   \n",
       "enc_loans_credit_type                       0.049853   \n",
       "pclose_flag                                -0.116686   \n",
       "fclose_flag                                 0.003935   \n",
       "PCA1                                       -0.082833   \n",
       "PCA2                                       -0.040376   \n",
       "flag                                       -0.038408   \n",
       "\n",
       "                               enc_loans_account_holder_type  \\\n",
       "id                                                  0.006625   \n",
       "rn                                                 -0.068007   \n",
       "pre_since_opened                                   -0.005022   \n",
       "pre_since_confirmed                                -0.003496   \n",
       "pre_pterm                                          -0.044209   \n",
       "pre_fterm                                          -0.019735   \n",
       "pre_till_pclose                                    -0.066251   \n",
       "pre_till_fclose                                     0.011508   \n",
       "pre_loans_credit_limit                             -0.070457   \n",
       "pre_loans_next_pay_summ                             0.038693   \n",
       "pre_loans_outstanding                              -0.158515   \n",
       "pre_loans_total_overdue                            -0.000046   \n",
       "pre_loans_max_overdue_sum                           0.000137   \n",
       "pre_loans_credit_cost_rate                          0.009409   \n",
       "pre_loans5                                         -0.010324   \n",
       "pre_loans530                                       -0.001698   \n",
       "pre_loans3060                                       0.001971   \n",
       "pre_loans6090                                      -0.001592   \n",
       "pre_loans90                                         0.001599   \n",
       "is_zero_loans5                                      0.002737   \n",
       "is_zero_loans530                                    0.039593   \n",
       "is_zero_loans3060                                   0.014257   \n",
       "is_zero_loans6090                                   0.012792   \n",
       "is_zero_loans90                                     0.012475   \n",
       "pre_util                                           -0.093369   \n",
       "pre_over2limit                                      0.140895   \n",
       "pre_maxover2limit                                  -0.116001   \n",
       "is_zero_util                                       -0.088764   \n",
       "is_zero_over2limit                                 -0.111596   \n",
       "is_zero_maxover2limit                              -0.047715   \n",
       "enc_loans_account_holder_type                       1.000000   \n",
       "enc_loans_credit_status                            -0.084407   \n",
       "enc_loans_account_cur                               0.013378   \n",
       "enc_loans_credit_type                              -0.318540   \n",
       "pclose_flag                                         0.056362   \n",
       "fclose_flag                                         0.094829   \n",
       "PCA1                                                0.000493   \n",
       "PCA2                                                0.077200   \n",
       "flag                                               -0.005477   \n",
       "\n",
       "                               enc_loans_credit_status  enc_loans_account_cur  \\\n",
       "id                                            0.002197              -0.005245   \n",
       "rn                                            0.479661              -0.016342   \n",
       "pre_since_opened                              0.031123               0.015189   \n",
       "pre_since_confirmed                           0.007781              -0.002123   \n",
       "pre_pterm                                     0.105707               0.001329   \n",
       "pre_fterm                                     0.036652               0.007494   \n",
       "pre_till_pclose                               0.086069              -0.000285   \n",
       "pre_till_fclose                              -0.211587              -0.013421   \n",
       "pre_loans_credit_limit                       -0.006416              -0.020803   \n",
       "pre_loans_next_pay_summ                      -0.197996               0.004989   \n",
       "pre_loans_outstanding                        -0.033957              -0.003331   \n",
       "pre_loans_total_overdue                       0.000392               0.030709   \n",
       "pre_loans_max_overdue_sum                    -0.013269              -0.006538   \n",
       "pre_loans_credit_cost_rate                   -0.099978              -0.005311   \n",
       "pre_loans5                                    0.032473              -0.000856   \n",
       "pre_loans530                                  0.013353              -0.009709   \n",
       "pre_loans3060                                -0.007889              -0.000578   \n",
       "pre_loans6090                                 0.003300               0.000077   \n",
       "pre_loans90                                  -0.001125               0.000892   \n",
       "is_zero_loans5                               -0.045003               0.000761   \n",
       "is_zero_loans530                             -0.125723              -0.004848   \n",
       "is_zero_loans3060                            -0.110516              -0.009500   \n",
       "is_zero_loans6090                            -0.102942              -0.008707   \n",
       "is_zero_loans90                              -0.108508              -0.012855   \n",
       "pre_util                                      0.524377               0.001756   \n",
       "pre_over2limit                               -0.005872               0.004298   \n",
       "pre_maxover2limit                             0.029427              -0.003971   \n",
       "is_zero_util                                  0.649281               0.010762   \n",
       "is_zero_over2limit                           -0.086255               0.000575   \n",
       "is_zero_maxover2limit                        -0.090463               0.000153   \n",
       "enc_loans_account_holder_type                -0.084407               0.013378   \n",
       "enc_loans_credit_status                       1.000000               0.006969   \n",
       "enc_loans_account_cur                         0.006969               1.000000   \n",
       "enc_loans_credit_type                         0.278608              -0.034283   \n",
       "pclose_flag                                  -0.294270              -0.000052   \n",
       "fclose_flag                                  -0.597270              -0.001938   \n",
       "PCA1                                          0.001317               0.012641   \n",
       "PCA2                                         -0.199314               0.017445   \n",
       "flag                                         -0.029797              -0.001399   \n",
       "\n",
       "                               enc_loans_credit_type  pclose_flag  \\\n",
       "id                                          0.090867    -0.038292   \n",
       "rn                                          0.311111    -0.291479   \n",
       "pre_since_opened                            0.000534    -0.009273   \n",
       "pre_since_confirmed                        -0.040799     0.032918   \n",
       "pre_pterm                                   0.145605    -0.307900   \n",
       "pre_fterm                                   0.022163    -0.011496   \n",
       "pre_till_pclose                             0.157355    -0.431777   \n",
       "pre_till_fclose                            -0.017223     0.148067   \n",
       "pre_loans_credit_limit                      0.127687     0.021679   \n",
       "pre_loans_next_pay_summ                    -0.093174     0.185576   \n",
       "pre_loans_outstanding                       0.126461     0.048672   \n",
       "pre_loans_total_overdue                     0.000346    -0.000184   \n",
       "pre_loans_max_overdue_sum                  -0.001744     0.028688   \n",
       "pre_loans_credit_cost_rate                 -0.010096     0.105098   \n",
       "pre_loans5                                  0.025413     0.002379   \n",
       "pre_loans530                                0.016466    -0.049197   \n",
       "pre_loans3060                              -0.007120    -0.001425   \n",
       "pre_loans6090                               0.004044     0.000315   \n",
       "pre_loans90                                -0.007850    -0.001033   \n",
       "is_zero_loans5                              0.024803     0.129337   \n",
       "is_zero_loans530                           -0.096060    -0.003200   \n",
       "is_zero_loans3060                          -0.007913     0.067321   \n",
       "is_zero_loans6090                          -0.003230     0.047700   \n",
       "is_zero_loans90                            -0.000411     0.038580   \n",
       "pre_util                                    0.227483    -0.229178   \n",
       "pre_over2limit                             -0.113613     0.094760   \n",
       "pre_maxover2limit                           0.088051    -0.156459   \n",
       "is_zero_util                                0.246454    -0.216407   \n",
       "is_zero_over2limit                          0.146183    -0.000562   \n",
       "is_zero_maxover2limit                       0.049853    -0.116686   \n",
       "enc_loans_account_holder_type              -0.318540     0.056362   \n",
       "enc_loans_credit_status                     0.278608    -0.294270   \n",
       "enc_loans_account_cur                      -0.034283    -0.000052   \n",
       "enc_loans_credit_type                       1.000000    -0.168929   \n",
       "pclose_flag                                -0.168929     1.000000   \n",
       "fclose_flag                                -0.270234     0.458370   \n",
       "PCA1                                       -0.143152    -0.053128   \n",
       "PCA2                                       -0.161578     0.155356   \n",
       "flag                                        0.022509     0.018032   \n",
       "\n",
       "                               fclose_flag          PCA1          PCA2  \\\n",
       "id                               -0.030114  4.263053e-02 -4.261130e-02   \n",
       "rn                               -0.370548 -6.294235e-02 -2.610057e-01   \n",
       "pre_since_opened                 -0.016724 -6.050729e-02  1.706300e-01   \n",
       "pre_since_confirmed               0.002133  3.943669e-02 -1.439267e-02   \n",
       "pre_pterm                        -0.192805  1.351234e-02 -1.984303e-01   \n",
       "pre_fterm                        -0.067113  2.262062e-01 -3.234167e-02   \n",
       "pre_till_pclose                  -0.184868  1.966996e-02 -3.078653e-02   \n",
       "pre_till_fclose                   0.311906  1.150663e-03  3.346705e-02   \n",
       "pre_loans_credit_limit            0.003282 -5.919980e-02  7.783502e-03   \n",
       "pre_loans_next_pay_summ           0.125628 -1.496049e-02  8.337432e-02   \n",
       "pre_loans_outstanding             0.023412 -1.031337e-02  2.284212e-03   \n",
       "pre_loans_total_overdue          -0.000270 -1.070011e-04 -6.143656e-04   \n",
       "pre_loans_max_overdue_sum         0.018744 -4.955727e-03 -1.855381e-02   \n",
       "pre_loans_credit_cost_rate        0.050494 -2.739428e-02  5.554075e-02   \n",
       "pre_loans5                       -0.050862 -3.753921e-02 -4.931592e-02   \n",
       "pre_loans530                     -0.019128 -5.161570e-02 -5.839997e-02   \n",
       "pre_loans3060                     0.013668  7.494298e-03  1.593881e-02   \n",
       "pre_loans6090                    -0.005482 -1.531698e-03 -6.238607e-03   \n",
       "pre_loans90                       0.010745 -4.709490e-03  1.801714e-02   \n",
       "is_zero_loans5                   -0.024452 -1.713536e-01 -3.452766e-02   \n",
       "is_zero_loans530                  0.117030 -1.617091e-01  2.914049e-02   \n",
       "is_zero_loans3060                 0.056011 -3.434544e-02 -1.220987e-01   \n",
       "is_zero_loans6090                 0.049744  1.511282e-02 -1.366636e-01   \n",
       "is_zero_loans90                   0.046979  4.643185e-02 -1.558903e-01   \n",
       "pre_util                         -0.379402  4.506999e-02 -1.883282e-01   \n",
       "pre_over2limit                    0.079018 -2.406333e-02  1.184876e-01   \n",
       "pre_maxover2limit                -0.090334  1.124425e-02 -1.084936e-01   \n",
       "is_zero_util                     -0.422438  2.378043e-02 -1.665683e-01   \n",
       "is_zero_over2limit                0.010026  7.040611e-03 -8.404998e-02   \n",
       "is_zero_maxover2limit             0.003935 -8.283326e-02 -4.037564e-02   \n",
       "enc_loans_account_holder_type     0.094829  4.932169e-04  7.720033e-02   \n",
       "enc_loans_credit_status          -0.597270  1.317383e-03 -1.993140e-01   \n",
       "enc_loans_account_cur            -0.001938  1.264118e-02  1.744470e-02   \n",
       "enc_loans_credit_type            -0.270234 -1.431520e-01 -1.615784e-01   \n",
       "pclose_flag                       0.458370 -5.312827e-02  1.553557e-01   \n",
       "fclose_flag                       1.000000 -2.350276e-03  2.165154e-01   \n",
       "PCA1                             -0.002350  1.000000e+00  4.507718e-16   \n",
       "PCA2                              0.216515  4.507718e-16  1.000000e+00   \n",
       "flag                              0.023005 -5.959303e-02  4.354217e-02   \n",
       "\n",
       "                                   flag  \n",
       "id                            -0.000037  \n",
       "rn                            -0.014138  \n",
       "pre_since_opened               0.011584  \n",
       "pre_since_confirmed           -0.006152  \n",
       "pre_pterm                     -0.007316  \n",
       "pre_fterm                     -0.013389  \n",
       "pre_till_pclose                0.003658  \n",
       "pre_till_fclose                0.002761  \n",
       "pre_loans_credit_limit         0.019402  \n",
       "pre_loans_next_pay_summ        0.007076  \n",
       "pre_loans_outstanding          0.016300  \n",
       "pre_loans_total_overdue        0.003010  \n",
       "pre_loans_max_overdue_sum     -0.005401  \n",
       "pre_loans_credit_cost_rate     0.007601  \n",
       "pre_loans5                    -0.009945  \n",
       "pre_loans530                  -0.007114  \n",
       "pre_loans3060                  0.005146  \n",
       "pre_loans6090                 -0.001935  \n",
       "pre_loans90                    0.005933  \n",
       "is_zero_loans5                -0.032215  \n",
       "is_zero_loans530              -0.056670  \n",
       "is_zero_loans3060             -0.070019  \n",
       "is_zero_loans6090             -0.067050  \n",
       "is_zero_loans90               -0.068420  \n",
       "pre_util                      -0.041547  \n",
       "pre_over2limit                 0.018330  \n",
       "pre_maxover2limit             -0.029647  \n",
       "is_zero_util                  -0.047293  \n",
       "is_zero_over2limit            -0.017485  \n",
       "is_zero_maxover2limit         -0.038408  \n",
       "enc_loans_account_holder_type -0.005477  \n",
       "enc_loans_credit_status       -0.029797  \n",
       "enc_loans_account_cur         -0.001399  \n",
       "enc_loans_credit_type          0.022509  \n",
       "pclose_flag                    0.018032  \n",
       "fclose_flag                    0.023005  \n",
       "PCA1                          -0.059593  \n",
       "PCA2                           0.043542  \n",
       "flag                           1.000000  \n",
       "\n",
       "[39 rows x 39 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d20251d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем значения на X, y, train/test и стандартизируем их.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = final_df.drop(columns=['id', 'flag'])\n",
    "y = final_df['flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633f4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-18 09:53:19,023] A new study created in memory with name: no-name-35c22191-d15f-401c-a619-bdd32fcc7b96\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:53:37,743] Trial 0 finished with value: 0.7071741731094856 and parameters: {'iterations': 260, 'learning_rate': 0.06452240316537888, 'depth': 5, 'l2_leaf_reg': 3}. Best is trial 0 with value: 0.7071741731094856.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:53:58,657] Trial 1 finished with value: 0.7114086148959831 and parameters: {'iterations': 228, 'learning_rate': 0.0903721612429925, 'depth': 8, 'l2_leaf_reg': 8}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:54:42,560] Trial 2 finished with value: 0.6840059974413742 and parameters: {'iterations': 517, 'learning_rate': 0.0014975460210306984, 'depth': 7, 'l2_leaf_reg': 8}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:55:55,251] Trial 3 finished with value: 0.7001849657774135 and parameters: {'iterations': 700, 'learning_rate': 0.003907128059616271, 'depth': 9, 'l2_leaf_reg': 6}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:56:40,907] Trial 4 finished with value: 0.6961011533914834 and parameters: {'iterations': 678, 'learning_rate': 0.008008858005777076, 'depth': 4, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 09:58:56,114] Trial 5 finished with value: 0.7007114126273623 and parameters: {'iterations': 932, 'learning_rate': 0.0026597358939834323, 'depth': 10, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 10:00:02,541] Trial 6 finished with value: 0.68860149929113 and parameters: {'iterations': 996, 'learning_rate': 0.0027223749100694504, 'depth': 4, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 10:01:14,836] Trial 7 finished with value: 0.6912565047845783 and parameters: {'iterations': 870, 'learning_rate': 0.0019174373867439966, 'depth': 7, 'l2_leaf_reg': 10}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 10:01:21,349] Trial 8 finished with value: 0.6762616353311005 and parameters: {'iterations': 589, 'learning_rate': 5.457911709273203e-05, 'depth': 7, 'l2_leaf_reg': 10}. Best is trial 1 with value: 0.7114086148959831.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11524\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-18 10:02:06,256] Trial 9 finished with value: 0.6934582028294484 and parameters: {'iterations': 542, 'learning_rate': 0.0037582938138378437, 'depth': 7, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7114086148959831.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'iterations': 228, 'learning_rate': 0.0903721612429925, 'depth': 8, 'l2_leaf_reg': 8}\n",
      "Лучший ROC-AUC: 0.7114086148959831\n",
      "0:\tlearn: 0.5630849\ttotal: 67.9ms\tremaining: 15.4s\n",
      "1:\tlearn: 0.4653685\ttotal: 128ms\tremaining: 14.4s\n",
      "2:\tlearn: 0.3913049\ttotal: 174ms\tremaining: 13.1s\n",
      "3:\tlearn: 0.3350902\ttotal: 237ms\tremaining: 13.2s\n",
      "4:\tlearn: 0.2923074\ttotal: 304ms\tremaining: 13.5s\n",
      "5:\tlearn: 0.2603685\ttotal: 366ms\tremaining: 13.5s\n",
      "6:\tlearn: 0.2356590\ttotal: 426ms\tremaining: 13.4s\n",
      "7:\tlearn: 0.2168282\ttotal: 486ms\tremaining: 13.4s\n",
      "8:\tlearn: 0.2017804\ttotal: 545ms\tremaining: 13.3s\n",
      "9:\tlearn: 0.1901500\ttotal: 605ms\tremaining: 13.2s\n",
      "10:\tlearn: 0.1814874\ttotal: 673ms\tremaining: 13.3s\n",
      "11:\tlearn: 0.1749174\ttotal: 728ms\tremaining: 13.1s\n",
      "12:\tlearn: 0.1693317\ttotal: 796ms\tremaining: 13.2s\n",
      "13:\tlearn: 0.1646386\ttotal: 866ms\tremaining: 13.2s\n",
      "14:\tlearn: 0.1610986\ttotal: 929ms\tremaining: 13.2s\n",
      "15:\tlearn: 0.1580892\ttotal: 996ms\tremaining: 13.2s\n",
      "16:\tlearn: 0.1557089\ttotal: 1.06s\tremaining: 13.2s\n",
      "17:\tlearn: 0.1539356\ttotal: 1.13s\tremaining: 13.2s\n",
      "18:\tlearn: 0.1523470\ttotal: 1.2s\tremaining: 13.2s\n",
      "19:\tlearn: 0.1511138\ttotal: 1.26s\tremaining: 13.2s\n",
      "20:\tlearn: 0.1501055\ttotal: 1.33s\tremaining: 13.2s\n",
      "21:\tlearn: 0.1493822\ttotal: 1.4s\tremaining: 13.1s\n",
      "22:\tlearn: 0.1486363\ttotal: 1.47s\tremaining: 13.1s\n",
      "23:\tlearn: 0.1479952\ttotal: 1.53s\tremaining: 13s\n",
      "24:\tlearn: 0.1474580\ttotal: 1.6s\tremaining: 13s\n",
      "25:\tlearn: 0.1470105\ttotal: 1.67s\tremaining: 13s\n",
      "26:\tlearn: 0.1466126\ttotal: 1.74s\tremaining: 13s\n",
      "27:\tlearn: 0.1462748\ttotal: 1.81s\tremaining: 12.9s\n",
      "28:\tlearn: 0.1459792\ttotal: 1.89s\tremaining: 12.9s\n",
      "29:\tlearn: 0.1457335\ttotal: 1.96s\tremaining: 12.9s\n",
      "30:\tlearn: 0.1455329\ttotal: 2.02s\tremaining: 12.9s\n",
      "31:\tlearn: 0.1453540\ttotal: 2.09s\tremaining: 12.8s\n",
      "32:\tlearn: 0.1452014\ttotal: 2.16s\tremaining: 12.8s\n",
      "33:\tlearn: 0.1450437\ttotal: 2.23s\tremaining: 12.7s\n",
      "34:\tlearn: 0.1448984\ttotal: 2.3s\tremaining: 12.7s\n",
      "35:\tlearn: 0.1447766\ttotal: 2.36s\tremaining: 12.6s\n",
      "36:\tlearn: 0.1446551\ttotal: 2.43s\tremaining: 12.5s\n",
      "37:\tlearn: 0.1445538\ttotal: 2.5s\tremaining: 12.5s\n",
      "38:\tlearn: 0.1444717\ttotal: 2.56s\tremaining: 12.4s\n",
      "39:\tlearn: 0.1443965\ttotal: 2.63s\tremaining: 12.4s\n",
      "40:\tlearn: 0.1443235\ttotal: 2.7s\tremaining: 12.3s\n",
      "41:\tlearn: 0.1442554\ttotal: 2.77s\tremaining: 12.3s\n",
      "42:\tlearn: 0.1442023\ttotal: 2.84s\tremaining: 12.2s\n",
      "43:\tlearn: 0.1441435\ttotal: 2.9s\tremaining: 12.2s\n",
      "44:\tlearn: 0.1440822\ttotal: 2.98s\tremaining: 12.1s\n",
      "45:\tlearn: 0.1440276\ttotal: 3.05s\tremaining: 12.1s\n",
      "46:\tlearn: 0.1439886\ttotal: 3.12s\tremaining: 12s\n",
      "47:\tlearn: 0.1439277\ttotal: 3.19s\tremaining: 12s\n",
      "48:\tlearn: 0.1438803\ttotal: 3.25s\tremaining: 11.9s\n",
      "49:\tlearn: 0.1438427\ttotal: 3.32s\tremaining: 11.8s\n",
      "50:\tlearn: 0.1437961\ttotal: 3.39s\tremaining: 11.8s\n",
      "51:\tlearn: 0.1437540\ttotal: 3.46s\tremaining: 11.7s\n",
      "52:\tlearn: 0.1437159\ttotal: 3.53s\tremaining: 11.7s\n",
      "53:\tlearn: 0.1436659\ttotal: 3.6s\tremaining: 11.6s\n",
      "54:\tlearn: 0.1436276\ttotal: 3.67s\tremaining: 11.5s\n",
      "55:\tlearn: 0.1435904\ttotal: 3.73s\tremaining: 11.5s\n",
      "56:\tlearn: 0.1435454\ttotal: 3.8s\tremaining: 11.4s\n",
      "57:\tlearn: 0.1435129\ttotal: 3.88s\tremaining: 11.4s\n",
      "58:\tlearn: 0.1434789\ttotal: 3.94s\tremaining: 11.3s\n",
      "59:\tlearn: 0.1434479\ttotal: 4.01s\tremaining: 11.2s\n",
      "60:\tlearn: 0.1434114\ttotal: 4.07s\tremaining: 11.2s\n",
      "61:\tlearn: 0.1433844\ttotal: 4.14s\tremaining: 11.1s\n",
      "62:\tlearn: 0.1433591\ttotal: 4.21s\tremaining: 11s\n",
      "63:\tlearn: 0.1433303\ttotal: 4.28s\tremaining: 11s\n",
      "64:\tlearn: 0.1433038\ttotal: 4.34s\tremaining: 10.9s\n",
      "65:\tlearn: 0.1432742\ttotal: 4.41s\tremaining: 10.8s\n",
      "66:\tlearn: 0.1432525\ttotal: 4.47s\tremaining: 10.8s\n",
      "67:\tlearn: 0.1432301\ttotal: 4.54s\tremaining: 10.7s\n",
      "68:\tlearn: 0.1432065\ttotal: 4.6s\tremaining: 10.6s\n",
      "69:\tlearn: 0.1431895\ttotal: 4.67s\tremaining: 10.5s\n",
      "70:\tlearn: 0.1431585\ttotal: 4.73s\tremaining: 10.5s\n",
      "71:\tlearn: 0.1431383\ttotal: 4.8s\tremaining: 10.4s\n",
      "72:\tlearn: 0.1431064\ttotal: 4.88s\tremaining: 10.4s\n",
      "73:\tlearn: 0.1430807\ttotal: 4.95s\tremaining: 10.3s\n",
      "74:\tlearn: 0.1430611\ttotal: 5.01s\tremaining: 10.2s\n",
      "75:\tlearn: 0.1430423\ttotal: 5.08s\tremaining: 10.2s\n",
      "76:\tlearn: 0.1430235\ttotal: 5.15s\tremaining: 10.1s\n",
      "77:\tlearn: 0.1430092\ttotal: 5.21s\tremaining: 10s\n",
      "78:\tlearn: 0.1429837\ttotal: 5.28s\tremaining: 9.95s\n",
      "79:\tlearn: 0.1429673\ttotal: 5.34s\tremaining: 9.88s\n",
      "80:\tlearn: 0.1429389\ttotal: 5.41s\tremaining: 9.81s\n",
      "81:\tlearn: 0.1429079\ttotal: 5.47s\tremaining: 9.75s\n",
      "82:\tlearn: 0.1428926\ttotal: 5.54s\tremaining: 9.67s\n",
      "83:\tlearn: 0.1428790\ttotal: 5.59s\tremaining: 9.59s\n",
      "84:\tlearn: 0.1428594\ttotal: 5.66s\tremaining: 9.52s\n",
      "85:\tlearn: 0.1428364\ttotal: 5.72s\tremaining: 9.45s\n",
      "86:\tlearn: 0.1428159\ttotal: 5.79s\tremaining: 9.39s\n",
      "87:\tlearn: 0.1427967\ttotal: 5.87s\tremaining: 9.33s\n",
      "88:\tlearn: 0.1427779\ttotal: 5.93s\tremaining: 9.26s\n",
      "89:\tlearn: 0.1427589\ttotal: 6s\tremaining: 9.19s\n",
      "90:\tlearn: 0.1427417\ttotal: 6.06s\tremaining: 9.12s\n",
      "91:\tlearn: 0.1427282\ttotal: 6.12s\tremaining: 9.05s\n",
      "92:\tlearn: 0.1427080\ttotal: 6.19s\tremaining: 8.99s\n",
      "93:\tlearn: 0.1426945\ttotal: 6.26s\tremaining: 8.92s\n",
      "94:\tlearn: 0.1426805\ttotal: 6.32s\tremaining: 8.85s\n",
      "95:\tlearn: 0.1426653\ttotal: 6.38s\tremaining: 8.78s\n",
      "96:\tlearn: 0.1426529\ttotal: 6.45s\tremaining: 8.71s\n",
      "97:\tlearn: 0.1426376\ttotal: 6.51s\tremaining: 8.63s\n",
      "98:\tlearn: 0.1426265\ttotal: 6.57s\tremaining: 8.56s\n",
      "99:\tlearn: 0.1426118\ttotal: 6.63s\tremaining: 8.49s\n",
      "100:\tlearn: 0.1426041\ttotal: 6.69s\tremaining: 8.41s\n",
      "101:\tlearn: 0.1425958\ttotal: 6.75s\tremaining: 8.34s\n",
      "102:\tlearn: 0.1425864\ttotal: 6.81s\tremaining: 8.27s\n",
      "103:\tlearn: 0.1425725\ttotal: 6.88s\tremaining: 8.21s\n",
      "104:\tlearn: 0.1425557\ttotal: 6.95s\tremaining: 8.14s\n",
      "105:\tlearn: 0.1425393\ttotal: 7.02s\tremaining: 8.07s\n",
      "106:\tlearn: 0.1425255\ttotal: 7.08s\tremaining: 8.01s\n",
      "107:\tlearn: 0.1425150\ttotal: 7.14s\tremaining: 7.94s\n",
      "108:\tlearn: 0.1424971\ttotal: 7.21s\tremaining: 7.87s\n",
      "109:\tlearn: 0.1424879\ttotal: 7.27s\tremaining: 7.8s\n",
      "110:\tlearn: 0.1424704\ttotal: 7.34s\tremaining: 7.73s\n",
      "111:\tlearn: 0.1424532\ttotal: 7.4s\tremaining: 7.66s\n",
      "112:\tlearn: 0.1424370\ttotal: 7.47s\tremaining: 7.6s\n",
      "113:\tlearn: 0.1424271\ttotal: 7.53s\tremaining: 7.53s\n",
      "114:\tlearn: 0.1424188\ttotal: 7.59s\tremaining: 7.46s\n",
      "115:\tlearn: 0.1424024\ttotal: 7.66s\tremaining: 7.39s\n",
      "116:\tlearn: 0.1423922\ttotal: 7.72s\tremaining: 7.33s\n",
      "117:\tlearn: 0.1423837\ttotal: 7.79s\tremaining: 7.26s\n",
      "118:\tlearn: 0.1423737\ttotal: 7.86s\tremaining: 7.2s\n",
      "119:\tlearn: 0.1423581\ttotal: 7.92s\tremaining: 7.13s\n",
      "120:\tlearn: 0.1423474\ttotal: 7.99s\tremaining: 7.06s\n",
      "121:\tlearn: 0.1423279\ttotal: 8.05s\tremaining: 7s\n",
      "122:\tlearn: 0.1423206\ttotal: 8.12s\tremaining: 6.93s\n",
      "123:\tlearn: 0.1423127\ttotal: 8.18s\tremaining: 6.86s\n",
      "124:\tlearn: 0.1423028\ttotal: 8.24s\tremaining: 6.79s\n",
      "125:\tlearn: 0.1422919\ttotal: 8.31s\tremaining: 6.72s\n",
      "126:\tlearn: 0.1422773\ttotal: 8.37s\tremaining: 6.66s\n",
      "127:\tlearn: 0.1422687\ttotal: 8.43s\tremaining: 6.58s\n",
      "128:\tlearn: 0.1422620\ttotal: 8.49s\tremaining: 6.51s\n",
      "129:\tlearn: 0.1422506\ttotal: 8.55s\tremaining: 6.44s\n",
      "130:\tlearn: 0.1422411\ttotal: 8.61s\tremaining: 6.38s\n",
      "131:\tlearn: 0.1422294\ttotal: 8.67s\tremaining: 6.31s\n",
      "132:\tlearn: 0.1422167\ttotal: 8.74s\tremaining: 6.24s\n",
      "133:\tlearn: 0.1421994\ttotal: 8.8s\tremaining: 6.17s\n",
      "134:\tlearn: 0.1421893\ttotal: 8.88s\tremaining: 6.12s\n",
      "135:\tlearn: 0.1421817\ttotal: 8.94s\tremaining: 6.05s\n",
      "136:\tlearn: 0.1421744\ttotal: 9s\tremaining: 5.98s\n",
      "137:\tlearn: 0.1421620\ttotal: 9.06s\tremaining: 5.91s\n",
      "138:\tlearn: 0.1421540\ttotal: 9.12s\tremaining: 5.84s\n",
      "139:\tlearn: 0.1421438\ttotal: 9.18s\tremaining: 5.77s\n",
      "140:\tlearn: 0.1421271\ttotal: 9.26s\tremaining: 5.71s\n",
      "141:\tlearn: 0.1421166\ttotal: 9.32s\tremaining: 5.64s\n",
      "142:\tlearn: 0.1421067\ttotal: 9.38s\tremaining: 5.57s\n",
      "143:\tlearn: 0.1420959\ttotal: 9.44s\tremaining: 5.51s\n",
      "144:\tlearn: 0.1420872\ttotal: 9.5s\tremaining: 5.44s\n",
      "145:\tlearn: 0.1420704\ttotal: 9.58s\tremaining: 5.38s\n",
      "146:\tlearn: 0.1420554\ttotal: 9.65s\tremaining: 5.32s\n",
      "147:\tlearn: 0.1420442\ttotal: 9.71s\tremaining: 5.25s\n",
      "148:\tlearn: 0.1420292\ttotal: 9.78s\tremaining: 5.19s\n",
      "149:\tlearn: 0.1420139\ttotal: 9.86s\tremaining: 5.13s\n",
      "150:\tlearn: 0.1420065\ttotal: 9.91s\tremaining: 5.06s\n",
      "151:\tlearn: 0.1419959\ttotal: 9.98s\tremaining: 4.99s\n",
      "152:\tlearn: 0.1419856\ttotal: 10s\tremaining: 4.92s\n",
      "153:\tlearn: 0.1419741\ttotal: 10.1s\tremaining: 4.86s\n",
      "154:\tlearn: 0.1419629\ttotal: 10.2s\tremaining: 4.79s\n",
      "155:\tlearn: 0.1419556\ttotal: 10.2s\tremaining: 4.72s\n",
      "156:\tlearn: 0.1419498\ttotal: 10.3s\tremaining: 4.66s\n",
      "157:\tlearn: 0.1419336\ttotal: 10.4s\tremaining: 4.59s\n",
      "158:\tlearn: 0.1419239\ttotal: 10.4s\tremaining: 4.52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.1419153\ttotal: 10.5s\tremaining: 4.46s\n",
      "160:\tlearn: 0.1419067\ttotal: 10.6s\tremaining: 4.39s\n",
      "161:\tlearn: 0.1418963\ttotal: 10.6s\tremaining: 4.33s\n",
      "162:\tlearn: 0.1418873\ttotal: 10.7s\tremaining: 4.26s\n",
      "163:\tlearn: 0.1418793\ttotal: 10.7s\tremaining: 4.19s\n",
      "164:\tlearn: 0.1418696\ttotal: 10.8s\tremaining: 4.13s\n",
      "165:\tlearn: 0.1418606\ttotal: 10.9s\tremaining: 4.06s\n",
      "166:\tlearn: 0.1418481\ttotal: 10.9s\tremaining: 4s\n",
      "167:\tlearn: 0.1418389\ttotal: 11s\tremaining: 3.93s\n",
      "168:\tlearn: 0.1418300\ttotal: 11.1s\tremaining: 3.87s\n",
      "169:\tlearn: 0.1418159\ttotal: 11.1s\tremaining: 3.8s\n",
      "170:\tlearn: 0.1418091\ttotal: 11.2s\tremaining: 3.73s\n",
      "171:\tlearn: 0.1418022\ttotal: 11.3s\tremaining: 3.67s\n",
      "172:\tlearn: 0.1417945\ttotal: 11.3s\tremaining: 3.6s\n",
      "173:\tlearn: 0.1417789\ttotal: 11.4s\tremaining: 3.54s\n",
      "174:\tlearn: 0.1417754\ttotal: 11.5s\tremaining: 3.47s\n",
      "175:\tlearn: 0.1417660\ttotal: 11.5s\tremaining: 3.4s\n",
      "176:\tlearn: 0.1417593\ttotal: 11.6s\tremaining: 3.34s\n",
      "177:\tlearn: 0.1417493\ttotal: 11.6s\tremaining: 3.27s\n",
      "178:\tlearn: 0.1417332\ttotal: 11.7s\tremaining: 3.21s\n",
      "179:\tlearn: 0.1417238\ttotal: 11.8s\tremaining: 3.14s\n",
      "180:\tlearn: 0.1417146\ttotal: 11.9s\tremaining: 3.08s\n",
      "181:\tlearn: 0.1417032\ttotal: 11.9s\tremaining: 3.02s\n",
      "182:\tlearn: 0.1416917\ttotal: 12s\tremaining: 2.95s\n",
      "183:\tlearn: 0.1416792\ttotal: 12.1s\tremaining: 2.88s\n",
      "184:\tlearn: 0.1416662\ttotal: 12.1s\tremaining: 2.82s\n",
      "185:\tlearn: 0.1416594\ttotal: 12.2s\tremaining: 2.75s\n",
      "186:\tlearn: 0.1416523\ttotal: 12.3s\tremaining: 2.69s\n",
      "187:\tlearn: 0.1416428\ttotal: 12.3s\tremaining: 2.62s\n",
      "188:\tlearn: 0.1416350\ttotal: 12.4s\tremaining: 2.55s\n",
      "189:\tlearn: 0.1416249\ttotal: 12.4s\tremaining: 2.49s\n",
      "190:\tlearn: 0.1416153\ttotal: 12.5s\tremaining: 2.42s\n",
      "191:\tlearn: 0.1416081\ttotal: 12.6s\tremaining: 2.35s\n",
      "192:\tlearn: 0.1416000\ttotal: 12.6s\tremaining: 2.29s\n",
      "193:\tlearn: 0.1415921\ttotal: 12.7s\tremaining: 2.22s\n",
      "194:\tlearn: 0.1415777\ttotal: 12.7s\tremaining: 2.16s\n",
      "195:\tlearn: 0.1415676\ttotal: 12.8s\tremaining: 2.09s\n",
      "196:\tlearn: 0.1415541\ttotal: 12.9s\tremaining: 2.03s\n",
      "197:\tlearn: 0.1415476\ttotal: 12.9s\tremaining: 1.96s\n",
      "198:\tlearn: 0.1415397\ttotal: 13s\tremaining: 1.89s\n",
      "199:\tlearn: 0.1415329\ttotal: 13.1s\tremaining: 1.83s\n",
      "200:\tlearn: 0.1415237\ttotal: 13.1s\tremaining: 1.76s\n",
      "201:\tlearn: 0.1415139\ttotal: 13.2s\tremaining: 1.7s\n",
      "202:\tlearn: 0.1415057\ttotal: 13.3s\tremaining: 1.63s\n",
      "203:\tlearn: 0.1414977\ttotal: 13.3s\tremaining: 1.57s\n",
      "204:\tlearn: 0.1414867\ttotal: 13.4s\tremaining: 1.5s\n",
      "205:\tlearn: 0.1414767\ttotal: 13.4s\tremaining: 1.44s\n",
      "206:\tlearn: 0.1414638\ttotal: 13.5s\tremaining: 1.37s\n",
      "207:\tlearn: 0.1414498\ttotal: 13.6s\tremaining: 1.3s\n",
      "208:\tlearn: 0.1414390\ttotal: 13.6s\tremaining: 1.24s\n",
      "209:\tlearn: 0.1414290\ttotal: 13.7s\tremaining: 1.17s\n",
      "210:\tlearn: 0.1414220\ttotal: 13.8s\tremaining: 1.11s\n",
      "211:\tlearn: 0.1414130\ttotal: 13.8s\tremaining: 1.04s\n",
      "212:\tlearn: 0.1414034\ttotal: 13.9s\tremaining: 978ms\n",
      "213:\tlearn: 0.1413977\ttotal: 13.9s\tremaining: 913ms\n",
      "214:\tlearn: 0.1413931\ttotal: 14s\tremaining: 847ms\n",
      "215:\tlearn: 0.1413871\ttotal: 14.1s\tremaining: 782ms\n",
      "216:\tlearn: 0.1413796\ttotal: 14.1s\tremaining: 717ms\n",
      "217:\tlearn: 0.1413704\ttotal: 14.2s\tremaining: 651ms\n",
      "218:\tlearn: 0.1413634\ttotal: 14.3s\tremaining: 586ms\n",
      "219:\tlearn: 0.1413525\ttotal: 14.3s\tremaining: 521ms\n",
      "220:\tlearn: 0.1413438\ttotal: 14.4s\tremaining: 456ms\n",
      "221:\tlearn: 0.1413382\ttotal: 14.4s\tremaining: 390ms\n",
      "222:\tlearn: 0.1413263\ttotal: 14.5s\tremaining: 325ms\n",
      "223:\tlearn: 0.1413195\ttotal: 14.6s\tremaining: 260ms\n",
      "224:\tlearn: 0.1413140\ttotal: 14.6s\tremaining: 195ms\n",
      "225:\tlearn: 0.1413075\ttotal: 14.7s\tremaining: 130ms\n",
      "226:\tlearn: 0.1412976\ttotal: 14.8s\tremaining: 65ms\n",
      "227:\tlearn: 0.1412888\ttotal: 14.8s\tremaining: 0us\n",
      "Финальный ROC-AUC: 0.709926128840979\n"
     ]
    }
   ],
   "source": [
    "# Тестируем на CatBoostClassifier, подбирая параметры с помощью optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,\n",
    "        'class_weights': class_weights_dict\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "final_preds = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, final_preds)\n",
    "print(\"Финальный ROC-AUC:\", final_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba35a1",
   "metadata": {},
   "source": [
    "Итог: 0.709926128840979"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e810b4",
   "metadata": {},
   "source": [
    "### 4 эксперимент\n",
    "Объединяем 1 и 3 эксперимент, добавляя выделение важных признаков в PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "067e6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт данных\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"train_data\")\n",
    "train_target = pd.read_csv(\"train_target.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5db1557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение с таргетом\n",
    "merged_df = df.merge(train_target, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc4a05bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26162717, 62)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c0b6989",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"total_overdue_count\"] = merged_df[\"pre_loans5\"] + merged_df[\"pre_loans530\"] + merged_df[\"pre_loans3060\"] + merged_df[\"pre_loans6090\"] + merged_df[\"pre_loans90\"]\n",
    "merged_df.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)\n",
    "merged_df[\"has_overdue_flag\"] = 1 - (merged_df[\"is_zero_loans5\"] & merged_df[\"is_zero_loans530\"] & merged_df[\"is_zero_loans3060\"] & merged_df[\"is_zero_loans6090\"] & merged_df[\"is_zero_loans90\"])\n",
    "merged_df.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)\n",
    "merged_df[\"has_no_debt_flag\"] = merged_df[\"is_zero_util\"] & merged_df[\"is_zero_over2limit\"] & merged_df[\"is_zero_maxover2limit\"]\n",
    "merged_df.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)\n",
    "merged_df[\"term_difference\"] = merged_df[\"pre_pterm\"] - merged_df[\"pre_fterm\"]\n",
    "merged_df[\"close_difference\"] = merged_df[\"pre_till_pclose\"] - merged_df[\"pre_till_fclose\"]\n",
    "merged_df.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)\n",
    "merged_df.drop([\"pre_over2limit\", \"pre_loans_total_overdue\"], axis=1, inplace=True)\n",
    "merged_df[\"pre_since_conf_opened\"] = merged_df['pre_since_confirmed'] - merged_df['pre_since_opened']\n",
    "merged_df.drop(['pre_since_opened','pre_since_confirmed'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac88be9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26162717, 48)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cb6961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Важные признаки: Index(['enc_paym_4', 'enc_paym_5', 'enc_paym_6', 'enc_paym_7', 'enc_paym_8',\n",
      "       'enc_paym_9', 'enc_paym_10', 'enc_paym_11', 'enc_paym_12',\n",
      "       'enc_paym_13', 'enc_paym_14', 'enc_paym_15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Получение важных признаков из enc_paym_N\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "enc_paym_columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "X = merged_df[enc_paym_columns]\n",
    "y = merged_df['flag']\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "selector = SelectFromModel(model, prefit=True)\n",
    "X_important = selector.transform(X)\n",
    "\n",
    "selected_features = selector.get_support(indices=True)\n",
    "important_features = X.columns[selected_features]\n",
    "\n",
    "print(\"Важные признаки:\", important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae39c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование PCA на важных признаках\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "enc_paym_columns = [f'enc_paym_{i}' for i in range(25)] \n",
    "X = merged_df[important_features]\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df_pca = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2'])\n",
    "merged_df.drop(enc_paym_columns, axis=1, inplace=True)\n",
    "merged_df[[\"enc_paym1\", 'enc_paym2']] = df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9989b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26162717, 24)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b0404d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'rn', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ',\n",
       "       'pre_loans_outstanding', 'pre_loans_max_overdue_sum',\n",
       "       'pre_loans_credit_cost_rate', 'pre_util', 'pre_maxover2limit',\n",
       "       'enc_loans_account_holder_type', 'enc_loans_credit_status',\n",
       "       'enc_loans_credit_type', 'enc_loans_account_cur', 'pclose_flag',\n",
       "       'fclose_flag', 'flag', 'total_overdue_count', 'has_overdue_flag',\n",
       "       'has_no_debt_flag', 'term_difference', 'close_difference', 'enc_paym1',\n",
       "       'enc_paym2', 'pre_since_conf_opened'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2780ea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7582862628"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage(index=True).sum() + train_target.memory_usage(index=True).sum() - merged_df.memory_usage(index=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ffca975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>pre_loans_outstanding</th>\n",
       "      <th>pre_loans_max_overdue_sum</th>\n",
       "      <th>pre_loans_credit_cost_rate</th>\n",
       "      <th>pre_util</th>\n",
       "      <th>pre_maxover2limit</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>...</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>flag</th>\n",
       "      <th>total_overdue_count</th>\n",
       "      <th>has_overdue_flag</th>\n",
       "      <th>has_no_debt_flag</th>\n",
       "      <th>term_difference</th>\n",
       "      <th>close_difference</th>\n",
       "      <th>enc_paym1</th>\n",
       "      <th>enc_paym2</th>\n",
       "      <th>pre_since_conf_opened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>-3.628027</td>\n",
       "      <td>1.222879</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.679743</td>\n",
       "      <td>0.889779</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-10</td>\n",
       "      <td>3.679743</td>\n",
       "      <td>0.889779</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.223487</td>\n",
       "      <td>-1.915711</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.913414</td>\n",
       "      <td>-1.354639</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rn  pre_loans_credit_limit  pre_loans_next_pay_summ  \\\n",
       "0   0   1                      11                        3   \n",
       "1   0   2                       0                        3   \n",
       "2   0   3                      11                        0   \n",
       "3   0   4                      12                        2   \n",
       "4   0   5                      10                        2   \n",
       "\n",
       "   pre_loans_outstanding  pre_loans_max_overdue_sum  \\\n",
       "0                      3                          2   \n",
       "1                      3                          2   \n",
       "2                      5                          2   \n",
       "3                      3                          2   \n",
       "4                      3                          2   \n",
       "\n",
       "   pre_loans_credit_cost_rate  pre_util  pre_maxover2limit  \\\n",
       "0                          11        16                 17   \n",
       "1                          11        16                 17   \n",
       "2                           8        15                 17   \n",
       "3                           4        16                 17   \n",
       "4                           4        16                 17   \n",
       "\n",
       "   enc_loans_account_holder_type  ...  fclose_flag  flag  total_overdue_count  \\\n",
       "0                              1  ...            0     0                   39   \n",
       "1                              1  ...            0     0                   39   \n",
       "2                              1  ...            1     0                   39   \n",
       "3                              1  ...            0     0                   39   \n",
       "4                              1  ...            0     0                   39   \n",
       "\n",
       "   has_overdue_flag  has_no_debt_flag  term_difference  close_difference  \\\n",
       "0                 0                 1               -1                 6   \n",
       "1                 0                 1                0                 0   \n",
       "2                 0                 0               -4               -10   \n",
       "3                 1                 1               -3                 9   \n",
       "4                 0                 1               13                -1   \n",
       "\n",
       "   enc_paym1  enc_paym2  pre_since_conf_opened  \n",
       "0  -3.628027   1.222879                     -9  \n",
       "1   3.679743   0.889779                     -9  \n",
       "2   3.679743   0.889779                     -9  \n",
       "3   1.223487  -1.915711                     -3  \n",
       "4  -1.913414  -1.354639                      7  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d373627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'rn', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ',\n",
       "       'pre_loans_outstanding', 'pre_loans_max_overdue_sum',\n",
       "       'pre_loans_credit_cost_rate', 'pre_util', 'pre_maxover2limit',\n",
       "       'enc_loans_account_holder_type', 'enc_loans_credit_status',\n",
       "       'enc_loans_credit_type', 'enc_loans_account_cur', 'pclose_flag',\n",
       "       'fclose_flag', 'flag', 'total_overdue_count', 'has_overdue_flag',\n",
       "       'has_no_debt_flag', 'term_difference', 'close_difference', 'enc_paym1',\n",
       "       'enc_paym2', 'pre_since_conf_opened'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60db89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение правил аггрегации\n",
    "aggregations = {\n",
    "    'rn': 'count', \n",
    "    'pre_loans_credit_limit': 'min',\n",
    "    'pre_loans_next_pay_summ': 'sum',\n",
    "    'pre_loans_outstanding': 'mean',\n",
    "    'pre_loans_max_overdue_sum': 'max',\n",
    "    'pre_loans_credit_cost_rate': 'max',\n",
    "    'pre_util': 'mean',\n",
    "    'pre_maxover2limit': 'mean',\n",
    "    'enc_loans_account_holder_type': 'median',\n",
    "    'enc_loans_credit_status': 'median',\n",
    "    'enc_loans_credit_type': 'median',\n",
    "    'enc_loans_account_cur': 'median',\n",
    "    'pclose_flag': 'max',\n",
    "    'fclose_flag': 'max',\n",
    "    'flag': 'max',\n",
    "    'total_overdue_count': 'sum',\n",
    "    'has_overdue_flag': 'max',\n",
    "    'has_no_debt_flag': 'max',\n",
    "    'term_difference': 'median',\n",
    "    'close_difference': 'median',\n",
    "    'enc_paym1': 'mean',\n",
    "    'enc_paym2': 'mean',\n",
    "    'pre_since_conf_opened': 'median',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d68a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группировка данных\n",
    "final_df = df.groupby('id').agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "317eb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем значения на X, y, train/test и стандартизируем их.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = final_df.drop(columns=['id', 'flag'])\n",
    "y = final_df['flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16a2b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-20 16:48:14,742] A new study created in memory with name: no-name-b42a8e15-3031-4f0e-b626-dca3489758c1\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:48:27,981] Trial 0 finished with value: 0.6692362052862839 and parameters: {'iterations': 354, 'learning_rate': 3.2022699519404837e-05, 'depth': 10, 'l2_leaf_reg': 2}. Best is trial 0 with value: 0.6692362052862839.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:48:36,220] Trial 1 finished with value: 0.6506724620829086 and parameters: {'iterations': 447, 'learning_rate': 2.8082553948990834e-05, 'depth': 4, 'l2_leaf_reg': 8}. Best is trial 0 with value: 0.6692362052862839.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:48:49,527] Trial 2 finished with value: 0.654830888402111 and parameters: {'iterations': 333, 'learning_rate': 1.2239344744909578e-05, 'depth': 5, 'l2_leaf_reg': 8}. Best is trial 0 with value: 0.6692362052862839.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:50:16,386] Trial 3 finished with value: 0.6783853756456154 and parameters: {'iterations': 865, 'learning_rate': 0.005419804023449855, 'depth': 5, 'l2_leaf_reg': 9}. Best is trial 3 with value: 0.6783853756456154.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:50:36,895] Trial 4 finished with value: 0.6499884424841063 and parameters: {'iterations': 640, 'learning_rate': 0.00012224019751289585, 'depth': 4, 'l2_leaf_reg': 10}. Best is trial 3 with value: 0.6783853756456154.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:51:10,502] Trial 5 finished with value: 0.6701449464473312 and parameters: {'iterations': 290, 'learning_rate': 0.005483190544830557, 'depth': 6, 'l2_leaf_reg': 10}. Best is trial 3 with value: 0.6783853756456154.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:51:24,065] Trial 6 finished with value: 0.6692680642879189 and parameters: {'iterations': 760, 'learning_rate': 1.2563636377793689e-05, 'depth': 10, 'l2_leaf_reg': 8}. Best is trial 3 with value: 0.6783853756456154.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:51:30,783] Trial 7 finished with value: 0.6491835482282657 and parameters: {'iterations': 989, 'learning_rate': 0.00020780261188538187, 'depth': 4, 'l2_leaf_reg': 2}. Best is trial 3 with value: 0.6783853756456154.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:51:59,531] Trial 8 finished with value: 0.6892048719444132 and parameters: {'iterations': 278, 'learning_rate': 0.07010603469493519, 'depth': 5, 'l2_leaf_reg': 8}. Best is trial 8 with value: 0.6892048719444132.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20464\\3038657274.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-20 16:53:07,348] Trial 9 finished with value: 0.6778927919651604 and parameters: {'iterations': 660, 'learning_rate': 0.006667731044561632, 'depth': 5, 'l2_leaf_reg': 4}. Best is trial 8 with value: 0.6892048719444132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'iterations': 278, 'learning_rate': 0.07010603469493519, 'depth': 5, 'l2_leaf_reg': 8}\n",
      "Лучший ROC-AUC: 0.6892048719444132\n",
      "0:\tlearn: 0.5918680\ttotal: 74.8ms\tremaining: 20.7s\n",
      "1:\tlearn: 0.5085208\ttotal: 149ms\tremaining: 20.5s\n",
      "2:\tlearn: 0.4424157\ttotal: 219ms\tremaining: 20.1s\n",
      "3:\tlearn: 0.3878410\ttotal: 297ms\tremaining: 20.3s\n",
      "4:\tlearn: 0.3445888\ttotal: 365ms\tremaining: 19.9s\n",
      "5:\tlearn: 0.3099300\ttotal: 433ms\tremaining: 19.6s\n",
      "6:\tlearn: 0.2817651\ttotal: 521ms\tremaining: 20.2s\n",
      "7:\tlearn: 0.2575964\ttotal: 593ms\tremaining: 20s\n",
      "8:\tlearn: 0.2392098\ttotal: 659ms\tremaining: 19.7s\n",
      "9:\tlearn: 0.2236924\ttotal: 735ms\tremaining: 19.7s\n",
      "10:\tlearn: 0.2113918\ttotal: 812ms\tremaining: 19.7s\n",
      "11:\tlearn: 0.2009904\ttotal: 884ms\tremaining: 19.6s\n",
      "12:\tlearn: 0.1925061\ttotal: 949ms\tremaining: 19.4s\n",
      "13:\tlearn: 0.1856028\ttotal: 1.02s\tremaining: 19.2s\n",
      "14:\tlearn: 0.1795714\ttotal: 1.09s\tremaining: 19.1s\n",
      "15:\tlearn: 0.1747811\ttotal: 1.16s\tremaining: 19s\n",
      "16:\tlearn: 0.1706174\ttotal: 1.23s\tremaining: 18.9s\n",
      "17:\tlearn: 0.1671758\ttotal: 1.3s\tremaining: 18.8s\n",
      "18:\tlearn: 0.1641882\ttotal: 1.38s\tremaining: 18.8s\n",
      "19:\tlearn: 0.1618271\ttotal: 1.45s\tremaining: 18.7s\n",
      "20:\tlearn: 0.1596179\ttotal: 1.53s\tremaining: 18.7s\n",
      "21:\tlearn: 0.1578782\ttotal: 1.61s\tremaining: 18.7s\n",
      "22:\tlearn: 0.1564556\ttotal: 1.68s\tremaining: 18.6s\n",
      "23:\tlearn: 0.1551788\ttotal: 1.75s\tremaining: 18.5s\n",
      "24:\tlearn: 0.1541000\ttotal: 1.81s\tremaining: 18.4s\n",
      "25:\tlearn: 0.1531950\ttotal: 1.88s\tremaining: 18.2s\n",
      "26:\tlearn: 0.1523951\ttotal: 1.95s\tremaining: 18.1s\n",
      "27:\tlearn: 0.1516748\ttotal: 2.02s\tremaining: 18s\n",
      "28:\tlearn: 0.1511483\ttotal: 2.08s\tremaining: 17.9s\n",
      "29:\tlearn: 0.1505830\ttotal: 2.15s\tremaining: 17.8s\n",
      "30:\tlearn: 0.1501560\ttotal: 2.23s\tremaining: 17.7s\n",
      "31:\tlearn: 0.1497192\ttotal: 2.3s\tremaining: 17.7s\n",
      "32:\tlearn: 0.1493835\ttotal: 2.37s\tremaining: 17.6s\n",
      "33:\tlearn: 0.1490316\ttotal: 2.44s\tremaining: 17.5s\n",
      "34:\tlearn: 0.1487155\ttotal: 2.53s\tremaining: 17.5s\n",
      "35:\tlearn: 0.1484549\ttotal: 2.6s\tremaining: 17.5s\n",
      "36:\tlearn: 0.1482774\ttotal: 2.66s\tremaining: 17.3s\n",
      "37:\tlearn: 0.1480638\ttotal: 2.73s\tremaining: 17.3s\n",
      "38:\tlearn: 0.1478780\ttotal: 2.81s\tremaining: 17.2s\n",
      "39:\tlearn: 0.1477183\ttotal: 2.88s\tremaining: 17.2s\n",
      "40:\tlearn: 0.1475767\ttotal: 2.95s\tremaining: 17.1s\n",
      "41:\tlearn: 0.1474804\ttotal: 3.02s\tremaining: 17s\n",
      "42:\tlearn: 0.1473729\ttotal: 3.09s\tremaining: 16.9s\n",
      "43:\tlearn: 0.1472647\ttotal: 3.17s\tremaining: 16.8s\n",
      "44:\tlearn: 0.1471746\ttotal: 3.24s\tremaining: 16.8s\n",
      "45:\tlearn: 0.1470858\ttotal: 3.31s\tremaining: 16.7s\n",
      "46:\tlearn: 0.1470036\ttotal: 3.38s\tremaining: 16.6s\n",
      "47:\tlearn: 0.1469374\ttotal: 3.45s\tremaining: 16.6s\n",
      "48:\tlearn: 0.1468772\ttotal: 3.53s\tremaining: 16.5s\n",
      "49:\tlearn: 0.1468300\ttotal: 3.6s\tremaining: 16.4s\n",
      "50:\tlearn: 0.1467792\ttotal: 3.67s\tremaining: 16.3s\n",
      "51:\tlearn: 0.1467257\ttotal: 3.75s\tremaining: 16.3s\n",
      "52:\tlearn: 0.1466853\ttotal: 3.82s\tremaining: 16.2s\n",
      "53:\tlearn: 0.1466257\ttotal: 3.89s\tremaining: 16.1s\n",
      "54:\tlearn: 0.1465950\ttotal: 3.96s\tremaining: 16.1s\n",
      "55:\tlearn: 0.1465524\ttotal: 4.03s\tremaining: 16s\n",
      "56:\tlearn: 0.1465098\ttotal: 4.1s\tremaining: 15.9s\n",
      "57:\tlearn: 0.1464724\ttotal: 4.17s\tremaining: 15.8s\n",
      "58:\tlearn: 0.1464404\ttotal: 4.24s\tremaining: 15.7s\n",
      "59:\tlearn: 0.1464058\ttotal: 4.32s\tremaining: 15.7s\n",
      "60:\tlearn: 0.1463687\ttotal: 4.39s\tremaining: 15.6s\n",
      "61:\tlearn: 0.1463270\ttotal: 4.48s\tremaining: 15.6s\n",
      "62:\tlearn: 0.1462996\ttotal: 4.55s\tremaining: 15.5s\n",
      "63:\tlearn: 0.1462642\ttotal: 4.62s\tremaining: 15.5s\n",
      "64:\tlearn: 0.1462354\ttotal: 4.69s\tremaining: 15.4s\n",
      "65:\tlearn: 0.1462121\ttotal: 4.76s\tremaining: 15.3s\n",
      "66:\tlearn: 0.1461884\ttotal: 4.83s\tremaining: 15.2s\n",
      "67:\tlearn: 0.1461658\ttotal: 4.9s\tremaining: 15.1s\n",
      "68:\tlearn: 0.1461450\ttotal: 4.97s\tremaining: 15.1s\n",
      "69:\tlearn: 0.1461131\ttotal: 5.05s\tremaining: 15s\n",
      "70:\tlearn: 0.1460931\ttotal: 5.12s\tremaining: 14.9s\n",
      "71:\tlearn: 0.1460759\ttotal: 5.18s\tremaining: 14.8s\n",
      "72:\tlearn: 0.1460533\ttotal: 5.25s\tremaining: 14.8s\n",
      "73:\tlearn: 0.1460315\ttotal: 5.33s\tremaining: 14.7s\n",
      "74:\tlearn: 0.1460071\ttotal: 5.39s\tremaining: 14.6s\n",
      "75:\tlearn: 0.1459860\ttotal: 5.47s\tremaining: 14.5s\n",
      "76:\tlearn: 0.1459669\ttotal: 5.54s\tremaining: 14.5s\n",
      "77:\tlearn: 0.1459470\ttotal: 5.62s\tremaining: 14.4s\n",
      "78:\tlearn: 0.1459333\ttotal: 5.68s\tremaining: 14.3s\n",
      "79:\tlearn: 0.1459131\ttotal: 5.75s\tremaining: 14.2s\n",
      "80:\tlearn: 0.1458996\ttotal: 5.82s\tremaining: 14.2s\n",
      "81:\tlearn: 0.1458787\ttotal: 5.89s\tremaining: 14.1s\n",
      "82:\tlearn: 0.1458598\ttotal: 5.96s\tremaining: 14s\n",
      "83:\tlearn: 0.1458490\ttotal: 6.03s\tremaining: 13.9s\n",
      "84:\tlearn: 0.1458324\ttotal: 6.1s\tremaining: 13.9s\n",
      "85:\tlearn: 0.1458122\ttotal: 6.18s\tremaining: 13.8s\n",
      "86:\tlearn: 0.1457918\ttotal: 6.25s\tremaining: 13.7s\n",
      "87:\tlearn: 0.1457824\ttotal: 6.32s\tremaining: 13.6s\n",
      "88:\tlearn: 0.1457646\ttotal: 6.39s\tremaining: 13.6s\n",
      "89:\tlearn: 0.1457496\ttotal: 6.47s\tremaining: 13.5s\n",
      "90:\tlearn: 0.1457373\ttotal: 6.54s\tremaining: 13.4s\n",
      "91:\tlearn: 0.1457175\ttotal: 6.62s\tremaining: 13.4s\n",
      "92:\tlearn: 0.1457086\ttotal: 6.68s\tremaining: 13.3s\n",
      "93:\tlearn: 0.1456967\ttotal: 6.76s\tremaining: 13.2s\n",
      "94:\tlearn: 0.1456837\ttotal: 6.83s\tremaining: 13.2s\n",
      "95:\tlearn: 0.1456771\ttotal: 6.9s\tremaining: 13.1s\n",
      "96:\tlearn: 0.1456598\ttotal: 6.96s\tremaining: 13s\n",
      "97:\tlearn: 0.1456448\ttotal: 7.03s\tremaining: 12.9s\n",
      "98:\tlearn: 0.1456343\ttotal: 7.1s\tremaining: 12.8s\n",
      "99:\tlearn: 0.1456296\ttotal: 7.17s\tremaining: 12.8s\n",
      "100:\tlearn: 0.1456140\ttotal: 7.24s\tremaining: 12.7s\n",
      "101:\tlearn: 0.1456028\ttotal: 7.31s\tremaining: 12.6s\n",
      "102:\tlearn: 0.1455937\ttotal: 7.37s\tremaining: 12.5s\n",
      "103:\tlearn: 0.1455833\ttotal: 7.44s\tremaining: 12.4s\n",
      "104:\tlearn: 0.1455717\ttotal: 7.51s\tremaining: 12.4s\n",
      "105:\tlearn: 0.1455601\ttotal: 7.59s\tremaining: 12.3s\n",
      "106:\tlearn: 0.1455538\ttotal: 7.66s\tremaining: 12.2s\n",
      "107:\tlearn: 0.1455421\ttotal: 7.73s\tremaining: 12.2s\n",
      "108:\tlearn: 0.1455309\ttotal: 7.8s\tremaining: 12.1s\n",
      "109:\tlearn: 0.1455223\ttotal: 7.87s\tremaining: 12s\n",
      "110:\tlearn: 0.1455080\ttotal: 7.93s\tremaining: 11.9s\n",
      "111:\tlearn: 0.1454944\ttotal: 8.01s\tremaining: 11.9s\n",
      "112:\tlearn: 0.1454835\ttotal: 8.08s\tremaining: 11.8s\n",
      "113:\tlearn: 0.1454749\ttotal: 8.14s\tremaining: 11.7s\n",
      "114:\tlearn: 0.1454656\ttotal: 8.21s\tremaining: 11.6s\n",
      "115:\tlearn: 0.1454594\ttotal: 8.28s\tremaining: 11.6s\n",
      "116:\tlearn: 0.1454496\ttotal: 8.35s\tremaining: 11.5s\n",
      "117:\tlearn: 0.1454426\ttotal: 8.42s\tremaining: 11.4s\n",
      "118:\tlearn: 0.1454301\ttotal: 8.49s\tremaining: 11.3s\n",
      "119:\tlearn: 0.1454244\ttotal: 8.56s\tremaining: 11.3s\n",
      "120:\tlearn: 0.1454083\ttotal: 8.64s\tremaining: 11.2s\n",
      "121:\tlearn: 0.1453998\ttotal: 8.71s\tremaining: 11.1s\n",
      "122:\tlearn: 0.1453873\ttotal: 8.78s\tremaining: 11.1s\n",
      "123:\tlearn: 0.1453777\ttotal: 8.85s\tremaining: 11s\n",
      "124:\tlearn: 0.1453690\ttotal: 8.92s\tremaining: 10.9s\n",
      "125:\tlearn: 0.1453625\ttotal: 8.99s\tremaining: 10.8s\n",
      "126:\tlearn: 0.1453507\ttotal: 9.06s\tremaining: 10.8s\n",
      "127:\tlearn: 0.1453431\ttotal: 9.12s\tremaining: 10.7s\n",
      "128:\tlearn: 0.1453356\ttotal: 9.19s\tremaining: 10.6s\n",
      "129:\tlearn: 0.1453255\ttotal: 9.26s\tremaining: 10.5s\n",
      "130:\tlearn: 0.1453196\ttotal: 9.34s\tremaining: 10.5s\n",
      "131:\tlearn: 0.1453161\ttotal: 9.4s\tremaining: 10.4s\n",
      "132:\tlearn: 0.1453061\ttotal: 9.48s\tremaining: 10.3s\n",
      "133:\tlearn: 0.1453003\ttotal: 9.55s\tremaining: 10.3s\n",
      "134:\tlearn: 0.1452930\ttotal: 9.61s\tremaining: 10.2s\n",
      "135:\tlearn: 0.1452851\ttotal: 9.68s\tremaining: 10.1s\n",
      "136:\tlearn: 0.1452812\ttotal: 9.74s\tremaining: 10s\n",
      "137:\tlearn: 0.1452723\ttotal: 9.81s\tremaining: 9.95s\n",
      "138:\tlearn: 0.1452640\ttotal: 9.88s\tremaining: 9.88s\n",
      "139:\tlearn: 0.1452582\ttotal: 9.96s\tremaining: 9.81s\n",
      "140:\tlearn: 0.1452516\ttotal: 10s\tremaining: 9.74s\n",
      "141:\tlearn: 0.1452484\ttotal: 10.1s\tremaining: 9.66s\n",
      "142:\tlearn: 0.1452429\ttotal: 10.2s\tremaining: 9.58s\n",
      "143:\tlearn: 0.1452365\ttotal: 10.2s\tremaining: 9.51s\n",
      "144:\tlearn: 0.1452319\ttotal: 10.3s\tremaining: 9.44s\n",
      "145:\tlearn: 0.1452224\ttotal: 10.4s\tremaining: 9.37s\n",
      "146:\tlearn: 0.1452169\ttotal: 10.4s\tremaining: 9.29s\n",
      "147:\tlearn: 0.1452119\ttotal: 10.5s\tremaining: 9.23s\n",
      "148:\tlearn: 0.1452070\ttotal: 10.6s\tremaining: 9.15s\n",
      "149:\tlearn: 0.1452007\ttotal: 10.6s\tremaining: 9.08s\n",
      "150:\tlearn: 0.1451938\ttotal: 10.7s\tremaining: 9.01s\n",
      "151:\tlearn: 0.1451856\ttotal: 10.8s\tremaining: 8.94s\n",
      "152:\tlearn: 0.1451738\ttotal: 10.9s\tremaining: 8.87s\n",
      "153:\tlearn: 0.1451693\ttotal: 10.9s\tremaining: 8.8s\n",
      "154:\tlearn: 0.1451639\ttotal: 11s\tremaining: 8.73s\n",
      "155:\tlearn: 0.1451579\ttotal: 11.1s\tremaining: 8.66s\n",
      "156:\tlearn: 0.1451509\ttotal: 11.2s\tremaining: 8.6s\n",
      "157:\tlearn: 0.1451434\ttotal: 11.2s\tremaining: 8.53s\n",
      "158:\tlearn: 0.1451383\ttotal: 11.3s\tremaining: 8.45s\n",
      "159:\tlearn: 0.1451343\ttotal: 11.4s\tremaining: 8.37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160:\tlearn: 0.1451226\ttotal: 11.4s\tremaining: 8.3s\n",
      "161:\tlearn: 0.1451177\ttotal: 11.5s\tremaining: 8.23s\n",
      "162:\tlearn: 0.1451138\ttotal: 11.6s\tremaining: 8.16s\n",
      "163:\tlearn: 0.1451097\ttotal: 11.6s\tremaining: 8.09s\n",
      "164:\tlearn: 0.1451062\ttotal: 11.7s\tremaining: 8.01s\n",
      "165:\tlearn: 0.1450988\ttotal: 11.8s\tremaining: 7.94s\n",
      "166:\tlearn: 0.1450887\ttotal: 11.8s\tremaining: 7.87s\n",
      "167:\tlearn: 0.1450820\ttotal: 11.9s\tremaining: 7.8s\n",
      "168:\tlearn: 0.1450761\ttotal: 12s\tremaining: 7.73s\n",
      "169:\tlearn: 0.1450713\ttotal: 12.1s\tremaining: 7.66s\n",
      "170:\tlearn: 0.1450672\ttotal: 12.1s\tremaining: 7.59s\n",
      "171:\tlearn: 0.1450582\ttotal: 12.2s\tremaining: 7.52s\n",
      "172:\tlearn: 0.1450497\ttotal: 12.3s\tremaining: 7.45s\n",
      "173:\tlearn: 0.1450436\ttotal: 12.3s\tremaining: 7.38s\n",
      "174:\tlearn: 0.1450391\ttotal: 12.4s\tremaining: 7.31s\n",
      "175:\tlearn: 0.1450369\ttotal: 12.5s\tremaining: 7.24s\n",
      "176:\tlearn: 0.1450322\ttotal: 12.6s\tremaining: 7.16s\n",
      "177:\tlearn: 0.1450220\ttotal: 12.6s\tremaining: 7.09s\n",
      "178:\tlearn: 0.1450163\ttotal: 12.7s\tremaining: 7.02s\n",
      "179:\tlearn: 0.1450096\ttotal: 12.8s\tremaining: 6.95s\n",
      "180:\tlearn: 0.1450063\ttotal: 12.8s\tremaining: 6.88s\n",
      "181:\tlearn: 0.1450007\ttotal: 12.9s\tremaining: 6.81s\n",
      "182:\tlearn: 0.1449967\ttotal: 13s\tremaining: 6.74s\n",
      "183:\tlearn: 0.1449919\ttotal: 13.1s\tremaining: 6.67s\n",
      "184:\tlearn: 0.1449868\ttotal: 13.1s\tremaining: 6.6s\n",
      "185:\tlearn: 0.1449814\ttotal: 13.2s\tremaining: 6.53s\n",
      "186:\tlearn: 0.1449793\ttotal: 13.3s\tremaining: 6.46s\n",
      "187:\tlearn: 0.1449747\ttotal: 13.3s\tremaining: 6.38s\n",
      "188:\tlearn: 0.1449716\ttotal: 13.4s\tremaining: 6.31s\n",
      "189:\tlearn: 0.1449658\ttotal: 13.5s\tremaining: 6.25s\n",
      "190:\tlearn: 0.1449592\ttotal: 13.6s\tremaining: 6.18s\n",
      "191:\tlearn: 0.1449515\ttotal: 13.6s\tremaining: 6.11s\n",
      "192:\tlearn: 0.1449485\ttotal: 13.7s\tremaining: 6.04s\n",
      "193:\tlearn: 0.1449393\ttotal: 13.8s\tremaining: 5.97s\n",
      "194:\tlearn: 0.1449339\ttotal: 13.9s\tremaining: 5.9s\n",
      "195:\tlearn: 0.1449311\ttotal: 13.9s\tremaining: 5.83s\n",
      "196:\tlearn: 0.1449289\ttotal: 14s\tremaining: 5.76s\n",
      "197:\tlearn: 0.1449233\ttotal: 14.1s\tremaining: 5.69s\n",
      "198:\tlearn: 0.1449181\ttotal: 14.2s\tremaining: 5.62s\n",
      "199:\tlearn: 0.1449146\ttotal: 14.2s\tremaining: 5.55s\n",
      "200:\tlearn: 0.1449090\ttotal: 14.3s\tremaining: 5.48s\n",
      "201:\tlearn: 0.1449023\ttotal: 14.4s\tremaining: 5.41s\n",
      "202:\tlearn: 0.1448972\ttotal: 14.4s\tremaining: 5.34s\n",
      "203:\tlearn: 0.1448946\ttotal: 14.5s\tremaining: 5.26s\n",
      "204:\tlearn: 0.1448868\ttotal: 14.6s\tremaining: 5.19s\n",
      "205:\tlearn: 0.1448834\ttotal: 14.7s\tremaining: 5.12s\n",
      "206:\tlearn: 0.1448778\ttotal: 14.7s\tremaining: 5.05s\n",
      "207:\tlearn: 0.1448732\ttotal: 14.8s\tremaining: 4.98s\n",
      "208:\tlearn: 0.1448642\ttotal: 14.9s\tremaining: 4.91s\n",
      "209:\tlearn: 0.1448606\ttotal: 14.9s\tremaining: 4.84s\n",
      "210:\tlearn: 0.1448572\ttotal: 15s\tremaining: 4.77s\n",
      "211:\tlearn: 0.1448544\ttotal: 15.1s\tremaining: 4.7s\n",
      "212:\tlearn: 0.1448525\ttotal: 15.1s\tremaining: 4.62s\n",
      "213:\tlearn: 0.1448477\ttotal: 15.2s\tremaining: 4.55s\n",
      "214:\tlearn: 0.1448426\ttotal: 15.3s\tremaining: 4.48s\n",
      "215:\tlearn: 0.1448396\ttotal: 15.4s\tremaining: 4.41s\n",
      "216:\tlearn: 0.1448375\ttotal: 15.4s\tremaining: 4.34s\n",
      "217:\tlearn: 0.1448340\ttotal: 15.5s\tremaining: 4.27s\n",
      "218:\tlearn: 0.1448283\ttotal: 15.6s\tremaining: 4.2s\n",
      "219:\tlearn: 0.1448266\ttotal: 15.7s\tremaining: 4.13s\n",
      "220:\tlearn: 0.1448216\ttotal: 15.7s\tremaining: 4.06s\n",
      "221:\tlearn: 0.1448121\ttotal: 15.8s\tremaining: 3.99s\n",
      "222:\tlearn: 0.1448082\ttotal: 15.9s\tremaining: 3.92s\n",
      "223:\tlearn: 0.1448031\ttotal: 16s\tremaining: 3.85s\n",
      "224:\tlearn: 0.1447957\ttotal: 16s\tremaining: 3.78s\n",
      "225:\tlearn: 0.1447941\ttotal: 16.1s\tremaining: 3.7s\n",
      "226:\tlearn: 0.1447893\ttotal: 16.2s\tremaining: 3.63s\n",
      "227:\tlearn: 0.1447846\ttotal: 16.2s\tremaining: 3.56s\n",
      "228:\tlearn: 0.1447773\ttotal: 16.3s\tremaining: 3.49s\n",
      "229:\tlearn: 0.1447738\ttotal: 16.4s\tremaining: 3.42s\n",
      "230:\tlearn: 0.1447721\ttotal: 16.4s\tremaining: 3.35s\n",
      "231:\tlearn: 0.1447693\ttotal: 16.5s\tremaining: 3.27s\n",
      "232:\tlearn: 0.1447663\ttotal: 16.6s\tremaining: 3.2s\n",
      "233:\tlearn: 0.1447620\ttotal: 16.7s\tremaining: 3.13s\n",
      "234:\tlearn: 0.1447559\ttotal: 16.7s\tremaining: 3.06s\n",
      "235:\tlearn: 0.1447503\ttotal: 16.8s\tremaining: 2.99s\n",
      "236:\tlearn: 0.1447437\ttotal: 16.9s\tremaining: 2.92s\n",
      "237:\tlearn: 0.1447399\ttotal: 17s\tremaining: 2.85s\n",
      "238:\tlearn: 0.1447345\ttotal: 17s\tremaining: 2.78s\n",
      "239:\tlearn: 0.1447288\ttotal: 17.1s\tremaining: 2.71s\n",
      "240:\tlearn: 0.1447231\ttotal: 17.2s\tremaining: 2.64s\n",
      "241:\tlearn: 0.1447192\ttotal: 17.2s\tremaining: 2.56s\n",
      "242:\tlearn: 0.1447152\ttotal: 17.3s\tremaining: 2.49s\n",
      "243:\tlearn: 0.1447084\ttotal: 17.4s\tremaining: 2.42s\n",
      "244:\tlearn: 0.1447035\ttotal: 17.5s\tremaining: 2.35s\n",
      "245:\tlearn: 0.1447014\ttotal: 17.5s\tremaining: 2.28s\n",
      "246:\tlearn: 0.1446979\ttotal: 17.6s\tremaining: 2.21s\n",
      "247:\tlearn: 0.1446937\ttotal: 17.7s\tremaining: 2.14s\n",
      "248:\tlearn: 0.1446923\ttotal: 17.8s\tremaining: 2.07s\n",
      "249:\tlearn: 0.1446887\ttotal: 17.8s\tremaining: 2s\n",
      "250:\tlearn: 0.1446828\ttotal: 17.9s\tremaining: 1.93s\n",
      "251:\tlearn: 0.1446783\ttotal: 18s\tremaining: 1.85s\n",
      "252:\tlearn: 0.1446698\ttotal: 18s\tremaining: 1.78s\n",
      "253:\tlearn: 0.1446635\ttotal: 18.1s\tremaining: 1.71s\n",
      "254:\tlearn: 0.1446617\ttotal: 18.2s\tremaining: 1.64s\n",
      "255:\tlearn: 0.1446572\ttotal: 18.3s\tremaining: 1.57s\n",
      "256:\tlearn: 0.1446553\ttotal: 18.3s\tremaining: 1.5s\n",
      "257:\tlearn: 0.1446524\ttotal: 18.4s\tremaining: 1.43s\n",
      "258:\tlearn: 0.1446460\ttotal: 18.5s\tremaining: 1.36s\n",
      "259:\tlearn: 0.1446409\ttotal: 18.6s\tremaining: 1.28s\n",
      "260:\tlearn: 0.1446363\ttotal: 18.6s\tremaining: 1.21s\n",
      "261:\tlearn: 0.1446319\ttotal: 18.7s\tremaining: 1.14s\n",
      "262:\tlearn: 0.1446261\ttotal: 18.8s\tremaining: 1.07s\n",
      "263:\tlearn: 0.1446232\ttotal: 18.8s\tremaining: 999ms\n",
      "264:\tlearn: 0.1446179\ttotal: 18.9s\tremaining: 927ms\n",
      "265:\tlearn: 0.1446152\ttotal: 19s\tremaining: 856ms\n",
      "266:\tlearn: 0.1446125\ttotal: 19s\tremaining: 785ms\n",
      "267:\tlearn: 0.1446070\ttotal: 19.1s\tremaining: 713ms\n",
      "268:\tlearn: 0.1446055\ttotal: 19.2s\tremaining: 642ms\n",
      "269:\tlearn: 0.1446006\ttotal: 19.3s\tremaining: 570ms\n",
      "270:\tlearn: 0.1445967\ttotal: 19.3s\tremaining: 499ms\n",
      "271:\tlearn: 0.1445937\ttotal: 19.4s\tremaining: 428ms\n",
      "272:\tlearn: 0.1445877\ttotal: 19.5s\tremaining: 357ms\n",
      "273:\tlearn: 0.1445863\ttotal: 19.5s\tremaining: 285ms\n",
      "274:\tlearn: 0.1445826\ttotal: 19.6s\tremaining: 214ms\n",
      "275:\tlearn: 0.1445812\ttotal: 19.7s\tremaining: 143ms\n",
      "276:\tlearn: 0.1445761\ttotal: 19.8s\tremaining: 71.4ms\n",
      "277:\tlearn: 0.1445716\ttotal: 19.8s\tremaining: 0us\n",
      "Финальный ROC-AUC: 0.6865942379239678\n"
     ]
    }
   ],
   "source": [
    "# Тестируем на CatBoostClassifier, подбирая параметры с помощью optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,\n",
    "        'class_weights': class_weights_dict\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "final_preds = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, final_preds)\n",
    "print(\"Финальный ROC-AUC:\", final_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ff37d",
   "metadata": {},
   "source": [
    "Итог: 0.6865942379239678"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a1b53",
   "metadata": {},
   "source": [
    "### 5 эксперимент\n",
    "Объдиняем создание признаков из 1 эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8a1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем данные\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"train_data\")\n",
    "train_target = pd.read_csv(\"train_target.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f59726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим enc_paym_N к одному диапазону\n",
    "import numpy as np\n",
    "value_mapping = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3\n",
    "}\n",
    "\n",
    "columns_to_transform = ['enc_paym_11', 'enc_paym_20', 'enc_paym_24']\n",
    "\n",
    "for column in columns_to_transform:\n",
    "    df[column] = df[column].replace(value_mapping)\n",
    "    \n",
    "# Подсчитываем кол-во статусов\n",
    "enc_paym_columns = [f'enc_paym_{i}' for i in range(25)] \n",
    "df[f'enc_paym_status_0'] = np.sum(df[enc_paym_columns].values == 0, axis=1)\n",
    "df[f'enc_paym_status_1'] = np.sum(df[enc_paym_columns].values == 1, axis=1)\n",
    "df[f'enc_paym_status_2'] = np.sum(df[enc_paym_columns].values == 2, axis=1)\n",
    "df[f'enc_paym_status_3'] = np.sum(df[enc_paym_columns].values == 3, axis=1)\n",
    "df.drop(enc_paym_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe2dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем новые признаки на основе других, по описанию как в 1 эксперименте.\n",
    "df[\"total_overdue_count\"] = df[\"pre_loans5\"] + df[\"pre_loans530\"] + df[\"pre_loans3060\"] + df[\"pre_loans6090\"] + df[\"pre_loans90\"]\n",
    "df.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)\n",
    "df[\"has_no_debt_flag\"] = df[\"is_zero_util\"] & df[\"is_zero_over2limit\"] & df[\"is_zero_maxover2limit\"]\n",
    "df.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)\n",
    "df[\"has_overdue_flag\"] = 1 - (df[\"is_zero_loans5\"] & df[\"is_zero_loans530\"] & df[\"is_zero_loans3060\"] & df[\"is_zero_loans6090\"] & df[\"is_zero_loans90\"])\n",
    "df.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)\n",
    "df[\"term_difference\"] = df[\"pre_pterm\"] - df[\"pre_fterm\"]\n",
    "df[\"close_difference\"] = df[\"pre_till_pclose\"] - df[\"pre_till_fclose\"]\n",
    "df.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0bb0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подсчёта уникальных значений каждого признака\n",
    "def create_count_columns_and_remove(df, columns_to_count):\n",
    "    for column in columns_to_count:\n",
    "        if column in df.columns and pd.api.types.is_numeric_dtype(df[column]):\n",
    "            unique_values = df[column].unique()\n",
    "            for value in unique_values:\n",
    "                df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
    "            df.drop(columns=[column], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "728b8b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\549500933.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Опредеяем признаки, которые следует подсчитать и преобразуем\n",
    "columns_to_count = ['pre_since_opened', 'pre_since_confirmed', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ', 'pre_loans_outstanding', 'pre_loans_total_overdue', 'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_util', 'pre_over2limit', 'pre_maxover2limit', 'enc_loans_account_holder_type', 'enc_loans_credit_status', 'enc_loans_credit_type', 'enc_loans_account_cur', 'pclose_flag', 'fclose_flag']\n",
    "df_with_counts = create_count_columns_and_remove(df, columns_to_count)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046f0fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'rn', 'enc_paym_status_0', 'enc_paym_status_1',\n",
       "       'enc_paym_status_2', 'enc_paym_status_3', 'total_overdue_count',\n",
       "       'has_no_debt_flag', 'has_overdue_flag', 'term_difference',\n",
       "       'close_difference', 'pre_since_opened_18_count',\n",
       "       'pre_since_opened_4_count', 'pre_since_opened_5_count',\n",
       "       'pre_since_opened_3_count', 'pre_since_opened_2_count',\n",
       "       'pre_since_opened_1_count', 'pre_since_opened_7_count',\n",
       "       'pre_since_opened_8_count', 'pre_since_opened_15_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_counts.columns[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0145c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем правила аггрегации\n",
    "aggregations = {\n",
    "    'rn': 'max', \n",
    "    'has_no_debt_flag': 'median',\n",
    "    'has_overdue_flag': 'median',\n",
    "    'term_difference': 'mean',\n",
    "    'close_difference': 'mean',\n",
    "    **{col: 'sum' for col in df_with_counts.columns if col not in ['rn', 'has_no_debt_flag', 'has_overdue_flag', 'term_difference', 'close_difference', 'id']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f356758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группируем данные\n",
    "grouped_df = df_with_counts.groupby('id').agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2677163",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_with_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d940539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем с таргетом\n",
    "grouped_df = grouped_df.merge(train_target, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15cae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>has_no_debt_flag</th>\n",
       "      <th>has_overdue_flag</th>\n",
       "      <th>term_difference</th>\n",
       "      <th>close_difference</th>\n",
       "      <th>enc_paym_status_0</th>\n",
       "      <th>enc_paym_status_1</th>\n",
       "      <th>enc_paym_status_2</th>\n",
       "      <th>enc_paym_status_3</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_loans_credit_type_6_count</th>\n",
       "      <th>enc_loans_account_cur_1_count</th>\n",
       "      <th>enc_loans_account_cur_2_count</th>\n",
       "      <th>enc_loans_account_cur_0_count</th>\n",
       "      <th>enc_loans_account_cur_3_count</th>\n",
       "      <th>pclose_flag_0_count</th>\n",
       "      <th>pclose_flag_1_count</th>\n",
       "      <th>fclose_flag_0_count</th>\n",
       "      <th>fclose_flag_1_count</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>152</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-2.933333</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rn  has_no_debt_flag  has_overdue_flag  term_difference  \\\n",
       "0   0  10               1.0               0.0        -0.400000   \n",
       "1   1  14               1.0               1.0        -1.285714   \n",
       "2   2   3               0.0               0.0         1.000000   \n",
       "3   3  15               1.0               0.0        -0.200000   \n",
       "4   4   1               1.0               0.0        -4.000000   \n",
       "\n",
       "   close_difference  enc_paym_status_0  enc_paym_status_1  enc_paym_status_2  \\\n",
       "0          0.700000                117                  1                  0   \n",
       "1          3.071429                152                  7                  2   \n",
       "2         -4.000000                 21                 10                  2   \n",
       "3         -2.933333                246                  0                  0   \n",
       "4        -10.000000                  0                  0                  0   \n",
       "\n",
       "   enc_paym_status_3  ...  enc_loans_credit_type_6_count  \\\n",
       "0                132  ...                              0   \n",
       "1                189  ...                              0   \n",
       "2                 42  ...                              0   \n",
       "3                129  ...                              0   \n",
       "4                 25  ...                              0   \n",
       "\n",
       "   enc_loans_account_cur_1_count  enc_loans_account_cur_2_count  \\\n",
       "0                             10                              0   \n",
       "1                             14                              0   \n",
       "2                              3                              0   \n",
       "3                             15                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   enc_loans_account_cur_0_count  enc_loans_account_cur_3_count  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   pclose_flag_0_count  pclose_flag_1_count  fclose_flag_0_count  \\\n",
       "0                    9                    1                    8   \n",
       "1                   13                    1                   12   \n",
       "2                    1                    2                    1   \n",
       "3                   10                    5                    9   \n",
       "4                    0                    1                    0   \n",
       "\n",
       "   fclose_flag_1_count  flag  \n",
       "0                    2     0  \n",
       "1                    2     0  \n",
       "2                    2     0  \n",
       "3                    6     0  \n",
       "4                    1     0  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d2c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем значения на X, y, train/test и стандартизируем их.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "X = grouped_df.drop(columns=['id', 'flag'])\n",
    "y = grouped_df['flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Здесь мы убираем из списка для стандартизации бинарные признаки.\n",
    "features_to_scale = X_train.columns.difference(['has_no_debt_flag', 'has_overdue_flag'])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, features_to_scale),\n",
    "        ('passthrough', 'passthrough', ['has_no_debt_flag', 'has_overdue_flag'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=list(features_to_scale) + ['has_no_debt_flag', 'has_overdue_flag'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=list(features_to_scale) + ['has_no_debt_flag', 'has_overdue_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6b85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-21 11:00:52,575] A new study created in memory with name: no-name-ee2e9f32-0e32-48eb-875a-6176a3d20bbd\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:01:45,704] Trial 0 finished with value: 0.7138660903116149 and parameters: {'iterations': 179, 'learning_rate': 0.0021202434561103114, 'depth': 9, 'l2_leaf_reg': 3}. Best is trial 0 with value: 0.7138660903116149.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:02:14,864] Trial 1 finished with value: 0.6984954075393497 and parameters: {'iterations': 128, 'learning_rate': 0.0023195243414088507, 'depth': 6, 'l2_leaf_reg': 5}. Best is trial 0 with value: 0.7138660903116149.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:04:27,402] Trial 2 finished with value: 0.7211251451166132 and parameters: {'iterations': 735, 'learning_rate': 0.0035082706783929065, 'depth': 4, 'l2_leaf_reg': 10}. Best is trial 2 with value: 0.7211251451166132.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:07:23,825] Trial 3 finished with value: 0.7305171965186888 and parameters: {'iterations': 882, 'learning_rate': 0.004195008070754569, 'depth': 5, 'l2_leaf_reg': 7}. Best is trial 3 with value: 0.7305171965186888.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:10:19,037] Trial 4 finished with value: 0.7410539194891081 and parameters: {'iterations': 718, 'learning_rate': 0.007530735171713188, 'depth': 7, 'l2_leaf_reg': 6}. Best is trial 4 with value: 0.7410539194891081.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:20:38,914] Trial 5 finished with value: 0.7417640578263907 and parameters: {'iterations': 960, 'learning_rate': 0.0037372097494305367, 'depth': 10, 'l2_leaf_reg': 10}. Best is trial 5 with value: 0.7417640578263907.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:22:45,804] Trial 6 finished with value: 0.7403875723394907 and parameters: {'iterations': 483, 'learning_rate': 0.008738125969628528, 'depth': 8, 'l2_leaf_reg': 2}. Best is trial 5 with value: 0.7417640578263907.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:24:18,550] Trial 7 finished with value: 0.7528255479379675 and parameters: {'iterations': 361, 'learning_rate': 0.07525302007219146, 'depth': 8, 'l2_leaf_reg': 1}. Best is trial 7 with value: 0.7528255479379675.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:24:38,076] Trial 8 finished with value: 0.6752926060028781 and parameters: {'iterations': 521, 'learning_rate': 1.7748297429393065e-05, 'depth': 4, 'l2_leaf_reg': 3}. Best is trial 7 with value: 0.7528255479379675.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18476\\743734264.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-21 11:25:02,761] Trial 9 finished with value: 0.7097110260795494 and parameters: {'iterations': 377, 'learning_rate': 1.884759900638052e-05, 'depth': 9, 'l2_leaf_reg': 10}. Best is trial 7 with value: 0.7528255479379675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'iterations': 361, 'learning_rate': 0.07525302007219146, 'depth': 8, 'l2_leaf_reg': 1}\n",
      "Лучший ROC-AUC: 0.7528255479379675\n",
      "0:\tlearn: 0.5836798\ttotal: 181ms\tremaining: 1m 5s\n",
      "1:\tlearn: 0.4962392\ttotal: 333ms\tremaining: 59.8s\n",
      "2:\tlearn: 0.4281020\ttotal: 521ms\tremaining: 1m 2s\n",
      "3:\tlearn: 0.3739988\ttotal: 670ms\tremaining: 59.8s\n",
      "4:\tlearn: 0.3304111\ttotal: 802ms\tremaining: 57.1s\n",
      "5:\tlearn: 0.2962838\ttotal: 944ms\tremaining: 55.9s\n",
      "6:\tlearn: 0.2682574\ttotal: 1.13s\tremaining: 56.9s\n",
      "7:\tlearn: 0.2463348\ttotal: 1.29s\tremaining: 57.1s\n",
      "8:\tlearn: 0.2275873\ttotal: 1.5s\tremaining: 58.8s\n",
      "9:\tlearn: 0.2131081\ttotal: 1.66s\tremaining: 58.2s\n",
      "10:\tlearn: 0.2011463\ttotal: 1.85s\tremaining: 59s\n",
      "11:\tlearn: 0.1910770\ttotal: 2.06s\tremaining: 59.8s\n",
      "12:\tlearn: 0.1830643\ttotal: 2.25s\tremaining: 1m\n",
      "13:\tlearn: 0.1770041\ttotal: 2.4s\tremaining: 59.6s\n",
      "14:\tlearn: 0.1718037\ttotal: 2.59s\tremaining: 59.7s\n",
      "15:\tlearn: 0.1670133\ttotal: 2.8s\tremaining: 1m\n",
      "16:\tlearn: 0.1632394\ttotal: 3.01s\tremaining: 1m\n",
      "17:\tlearn: 0.1604247\ttotal: 3.2s\tremaining: 1m 1s\n",
      "18:\tlearn: 0.1577232\ttotal: 3.42s\tremaining: 1m 1s\n",
      "19:\tlearn: 0.1553413\ttotal: 3.63s\tremaining: 1m 1s\n",
      "20:\tlearn: 0.1533829\ttotal: 3.84s\tremaining: 1m 2s\n",
      "21:\tlearn: 0.1518033\ttotal: 4.05s\tremaining: 1m 2s\n",
      "22:\tlearn: 0.1504807\ttotal: 4.27s\tremaining: 1m 2s\n",
      "23:\tlearn: 0.1490927\ttotal: 4.51s\tremaining: 1m 3s\n",
      "24:\tlearn: 0.1481691\ttotal: 4.72s\tremaining: 1m 3s\n",
      "25:\tlearn: 0.1472762\ttotal: 4.95s\tremaining: 1m 3s\n",
      "26:\tlearn: 0.1466162\ttotal: 5.14s\tremaining: 1m 3s\n",
      "27:\tlearn: 0.1459458\ttotal: 5.37s\tremaining: 1m 3s\n",
      "28:\tlearn: 0.1453915\ttotal: 5.59s\tremaining: 1m 3s\n",
      "29:\tlearn: 0.1448969\ttotal: 5.81s\tremaining: 1m 4s\n",
      "30:\tlearn: 0.1445201\ttotal: 6.04s\tremaining: 1m 4s\n",
      "31:\tlearn: 0.1441776\ttotal: 6.27s\tremaining: 1m 4s\n",
      "32:\tlearn: 0.1437830\ttotal: 6.48s\tremaining: 1m 4s\n",
      "33:\tlearn: 0.1434881\ttotal: 6.71s\tremaining: 1m 4s\n",
      "34:\tlearn: 0.1432121\ttotal: 6.93s\tremaining: 1m 4s\n",
      "35:\tlearn: 0.1429941\ttotal: 7.16s\tremaining: 1m 4s\n",
      "36:\tlearn: 0.1427916\ttotal: 7.39s\tremaining: 1m 4s\n",
      "37:\tlearn: 0.1425761\ttotal: 7.61s\tremaining: 1m 4s\n",
      "38:\tlearn: 0.1423867\ttotal: 7.84s\tremaining: 1m 4s\n",
      "39:\tlearn: 0.1421804\ttotal: 8.06s\tremaining: 1m 4s\n",
      "40:\tlearn: 0.1420482\ttotal: 8.28s\tremaining: 1m 4s\n",
      "41:\tlearn: 0.1419192\ttotal: 8.5s\tremaining: 1m 4s\n",
      "42:\tlearn: 0.1417705\ttotal: 8.71s\tremaining: 1m 4s\n",
      "43:\tlearn: 0.1416087\ttotal: 8.95s\tremaining: 1m 4s\n",
      "44:\tlearn: 0.1414730\ttotal: 9.18s\tremaining: 1m 4s\n",
      "45:\tlearn: 0.1413737\ttotal: 9.4s\tremaining: 1m 4s\n",
      "46:\tlearn: 0.1412558\ttotal: 9.63s\tremaining: 1m 4s\n",
      "47:\tlearn: 0.1411672\ttotal: 9.86s\tremaining: 1m 4s\n",
      "48:\tlearn: 0.1410915\ttotal: 10.1s\tremaining: 1m 4s\n",
      "49:\tlearn: 0.1410187\ttotal: 10.3s\tremaining: 1m 4s\n",
      "50:\tlearn: 0.1409540\ttotal: 10.5s\tremaining: 1m 3s\n",
      "51:\tlearn: 0.1408828\ttotal: 10.7s\tremaining: 1m 3s\n",
      "52:\tlearn: 0.1408224\ttotal: 11s\tremaining: 1m 3s\n",
      "53:\tlearn: 0.1407352\ttotal: 11.2s\tremaining: 1m 3s\n",
      "54:\tlearn: 0.1406774\ttotal: 11.4s\tremaining: 1m 3s\n",
      "55:\tlearn: 0.1406352\ttotal: 11.6s\tremaining: 1m 3s\n",
      "56:\tlearn: 0.1405747\ttotal: 11.8s\tremaining: 1m 3s\n",
      "57:\tlearn: 0.1405174\ttotal: 12s\tremaining: 1m 2s\n",
      "58:\tlearn: 0.1404650\ttotal: 12.2s\tremaining: 1m 2s\n",
      "59:\tlearn: 0.1404169\ttotal: 12.4s\tremaining: 1m 2s\n",
      "60:\tlearn: 0.1403545\ttotal: 12.7s\tremaining: 1m 2s\n",
      "61:\tlearn: 0.1403210\ttotal: 12.9s\tremaining: 1m 1s\n",
      "62:\tlearn: 0.1402665\ttotal: 13.1s\tremaining: 1m 1s\n",
      "63:\tlearn: 0.1402078\ttotal: 13.3s\tremaining: 1m 1s\n",
      "64:\tlearn: 0.1401525\ttotal: 13.5s\tremaining: 1m 1s\n",
      "65:\tlearn: 0.1401015\ttotal: 13.8s\tremaining: 1m 1s\n",
      "66:\tlearn: 0.1400687\ttotal: 14s\tremaining: 1m 1s\n",
      "67:\tlearn: 0.1400363\ttotal: 14.2s\tremaining: 1m 1s\n",
      "68:\tlearn: 0.1399985\ttotal: 14.4s\tremaining: 1m\n",
      "69:\tlearn: 0.1399631\ttotal: 14.6s\tremaining: 1m\n",
      "70:\tlearn: 0.1399254\ttotal: 14.8s\tremaining: 1m\n",
      "71:\tlearn: 0.1398831\ttotal: 15.1s\tremaining: 1m\n",
      "72:\tlearn: 0.1398383\ttotal: 15.3s\tremaining: 1m\n",
      "73:\tlearn: 0.1397908\ttotal: 15.5s\tremaining: 1m\n",
      "74:\tlearn: 0.1397538\ttotal: 15.7s\tremaining: 1m\n",
      "75:\tlearn: 0.1397251\ttotal: 15.9s\tremaining: 59.7s\n",
      "76:\tlearn: 0.1396929\ttotal: 16.1s\tremaining: 59.5s\n",
      "77:\tlearn: 0.1396557\ttotal: 16.4s\tremaining: 59.4s\n",
      "78:\tlearn: 0.1396143\ttotal: 16.6s\tremaining: 59.2s\n",
      "79:\tlearn: 0.1395879\ttotal: 16.8s\tremaining: 59s\n",
      "80:\tlearn: 0.1395457\ttotal: 17s\tremaining: 58.8s\n",
      "81:\tlearn: 0.1395220\ttotal: 17.2s\tremaining: 58.6s\n",
      "82:\tlearn: 0.1394827\ttotal: 17.4s\tremaining: 58.4s\n",
      "83:\tlearn: 0.1394520\ttotal: 17.6s\tremaining: 58.2s\n",
      "84:\tlearn: 0.1394251\ttotal: 17.9s\tremaining: 58s\n",
      "85:\tlearn: 0.1394021\ttotal: 18.1s\tremaining: 57.8s\n",
      "86:\tlearn: 0.1393587\ttotal: 18.3s\tremaining: 57.6s\n",
      "87:\tlearn: 0.1393188\ttotal: 18.5s\tremaining: 57.4s\n",
      "88:\tlearn: 0.1392874\ttotal: 18.7s\tremaining: 57.2s\n",
      "89:\tlearn: 0.1392670\ttotal: 18.9s\tremaining: 56.9s\n",
      "90:\tlearn: 0.1392333\ttotal: 19.1s\tremaining: 56.8s\n",
      "91:\tlearn: 0.1392061\ttotal: 19.4s\tremaining: 56.7s\n",
      "92:\tlearn: 0.1391830\ttotal: 19.6s\tremaining: 56.4s\n",
      "93:\tlearn: 0.1391551\ttotal: 19.8s\tremaining: 56.3s\n",
      "94:\tlearn: 0.1391158\ttotal: 20s\tremaining: 56.1s\n",
      "95:\tlearn: 0.1390943\ttotal: 20.2s\tremaining: 55.9s\n",
      "96:\tlearn: 0.1390638\ttotal: 20.5s\tremaining: 55.7s\n",
      "97:\tlearn: 0.1390437\ttotal: 20.7s\tremaining: 55.4s\n",
      "98:\tlearn: 0.1390259\ttotal: 20.8s\tremaining: 55.2s\n",
      "99:\tlearn: 0.1390055\ttotal: 21s\tremaining: 54.9s\n",
      "100:\tlearn: 0.1389866\ttotal: 21.2s\tremaining: 54.7s\n",
      "101:\tlearn: 0.1389660\ttotal: 21.4s\tremaining: 54.5s\n",
      "102:\tlearn: 0.1389457\ttotal: 21.7s\tremaining: 54.2s\n",
      "103:\tlearn: 0.1389250\ttotal: 21.9s\tremaining: 54.1s\n",
      "104:\tlearn: 0.1388990\ttotal: 22.1s\tremaining: 53.9s\n",
      "105:\tlearn: 0.1388745\ttotal: 22.3s\tremaining: 53.7s\n",
      "106:\tlearn: 0.1388652\ttotal: 22.5s\tremaining: 53.5s\n",
      "107:\tlearn: 0.1388374\ttotal: 22.8s\tremaining: 53.3s\n",
      "108:\tlearn: 0.1388177\ttotal: 23s\tremaining: 53.1s\n",
      "109:\tlearn: 0.1388064\ttotal: 23.2s\tremaining: 52.9s\n",
      "110:\tlearn: 0.1387902\ttotal: 23.4s\tremaining: 52.6s\n",
      "111:\tlearn: 0.1387647\ttotal: 23.6s\tremaining: 52.4s\n",
      "112:\tlearn: 0.1387421\ttotal: 23.8s\tremaining: 52.2s\n",
      "113:\tlearn: 0.1387275\ttotal: 23.9s\tremaining: 51.9s\n",
      "114:\tlearn: 0.1387177\ttotal: 24.1s\tremaining: 51.6s\n",
      "115:\tlearn: 0.1386993\ttotal: 24.3s\tremaining: 51.4s\n",
      "116:\tlearn: 0.1386746\ttotal: 24.6s\tremaining: 51.2s\n",
      "117:\tlearn: 0.1386587\ttotal: 24.7s\tremaining: 51s\n",
      "118:\tlearn: 0.1386483\ttotal: 24.9s\tremaining: 50.7s\n",
      "119:\tlearn: 0.1386274\ttotal: 25.1s\tremaining: 50.4s\n",
      "120:\tlearn: 0.1386133\ttotal: 25.3s\tremaining: 50.2s\n",
      "121:\tlearn: 0.1386018\ttotal: 25.5s\tremaining: 49.9s\n",
      "122:\tlearn: 0.1385832\ttotal: 25.7s\tremaining: 49.7s\n",
      "123:\tlearn: 0.1385644\ttotal: 25.9s\tremaining: 49.6s\n",
      "124:\tlearn: 0.1385395\ttotal: 26.1s\tremaining: 49.4s\n",
      "125:\tlearn: 0.1385112\ttotal: 26.3s\tremaining: 49.1s\n",
      "126:\tlearn: 0.1384976\ttotal: 26.6s\tremaining: 48.9s\n",
      "127:\tlearn: 0.1384827\ttotal: 26.8s\tremaining: 48.7s\n",
      "128:\tlearn: 0.1384753\ttotal: 26.9s\tremaining: 48.4s\n",
      "129:\tlearn: 0.1384603\ttotal: 27.1s\tremaining: 48.1s\n",
      "130:\tlearn: 0.1384416\ttotal: 27.3s\tremaining: 48s\n",
      "131:\tlearn: 0.1384224\ttotal: 27.5s\tremaining: 47.7s\n",
      "132:\tlearn: 0.1384028\ttotal: 27.7s\tremaining: 47.5s\n",
      "133:\tlearn: 0.1383887\ttotal: 27.9s\tremaining: 47.3s\n",
      "134:\tlearn: 0.1383735\ttotal: 28.1s\tremaining: 47.1s\n",
      "135:\tlearn: 0.1383632\ttotal: 28.3s\tremaining: 46.8s\n",
      "136:\tlearn: 0.1383486\ttotal: 28.5s\tremaining: 46.6s\n",
      "137:\tlearn: 0.1383380\ttotal: 28.7s\tremaining: 46.4s\n",
      "138:\tlearn: 0.1383202\ttotal: 28.9s\tremaining: 46.2s\n",
      "139:\tlearn: 0.1382973\ttotal: 29.2s\tremaining: 46s\n",
      "140:\tlearn: 0.1382792\ttotal: 29.4s\tremaining: 45.8s\n",
      "141:\tlearn: 0.1382676\ttotal: 29.6s\tremaining: 45.6s\n",
      "142:\tlearn: 0.1382496\ttotal: 29.7s\tremaining: 45.3s\n",
      "143:\tlearn: 0.1382329\ttotal: 29.9s\tremaining: 45.1s\n",
      "144:\tlearn: 0.1382181\ttotal: 30.1s\tremaining: 44.9s\n",
      "145:\tlearn: 0.1382002\ttotal: 30.4s\tremaining: 44.7s\n",
      "146:\tlearn: 0.1381836\ttotal: 30.6s\tremaining: 44.5s\n",
      "147:\tlearn: 0.1381677\ttotal: 30.8s\tremaining: 44.3s\n",
      "148:\tlearn: 0.1381539\ttotal: 31s\tremaining: 44.1s\n",
      "149:\tlearn: 0.1381438\ttotal: 31.2s\tremaining: 43.9s\n",
      "150:\tlearn: 0.1381307\ttotal: 31.4s\tremaining: 43.6s\n",
      "151:\tlearn: 0.1381189\ttotal: 31.6s\tremaining: 43.4s\n",
      "152:\tlearn: 0.1381121\ttotal: 31.7s\tremaining: 43.2s\n",
      "153:\tlearn: 0.1380838\ttotal: 32s\tremaining: 43s\n",
      "154:\tlearn: 0.1380676\ttotal: 32.2s\tremaining: 42.8s\n",
      "155:\tlearn: 0.1380533\ttotal: 32.4s\tremaining: 42.6s\n",
      "156:\tlearn: 0.1380394\ttotal: 32.6s\tremaining: 42.4s\n",
      "157:\tlearn: 0.1380245\ttotal: 32.8s\tremaining: 42.2s\n",
      "158:\tlearn: 0.1380141\ttotal: 33s\tremaining: 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.1379984\ttotal: 33.3s\tremaining: 41.8s\n",
      "160:\tlearn: 0.1379777\ttotal: 33.5s\tremaining: 41.6s\n",
      "161:\tlearn: 0.1379614\ttotal: 33.7s\tremaining: 41.4s\n",
      "162:\tlearn: 0.1379474\ttotal: 33.9s\tremaining: 41.2s\n",
      "163:\tlearn: 0.1379400\ttotal: 34.1s\tremaining: 40.9s\n",
      "164:\tlearn: 0.1379269\ttotal: 34.3s\tremaining: 40.7s\n",
      "165:\tlearn: 0.1379154\ttotal: 34.5s\tremaining: 40.6s\n",
      "166:\tlearn: 0.1379095\ttotal: 34.7s\tremaining: 40.3s\n",
      "167:\tlearn: 0.1378966\ttotal: 34.9s\tremaining: 40.1s\n",
      "168:\tlearn: 0.1378782\ttotal: 35.1s\tremaining: 39.9s\n",
      "169:\tlearn: 0.1378642\ttotal: 35.3s\tremaining: 39.7s\n",
      "170:\tlearn: 0.1378549\ttotal: 35.5s\tremaining: 39.4s\n",
      "171:\tlearn: 0.1378283\ttotal: 35.7s\tremaining: 39.2s\n",
      "172:\tlearn: 0.1378191\ttotal: 35.9s\tremaining: 39s\n",
      "173:\tlearn: 0.1378103\ttotal: 36.1s\tremaining: 38.8s\n",
      "174:\tlearn: 0.1377956\ttotal: 36.3s\tremaining: 38.6s\n",
      "175:\tlearn: 0.1377880\ttotal: 36.5s\tremaining: 38.3s\n",
      "176:\tlearn: 0.1377791\ttotal: 36.6s\tremaining: 38.1s\n",
      "177:\tlearn: 0.1377604\ttotal: 36.9s\tremaining: 37.9s\n",
      "178:\tlearn: 0.1377486\ttotal: 37.1s\tremaining: 37.7s\n",
      "179:\tlearn: 0.1377414\ttotal: 37.2s\tremaining: 37.5s\n",
      "180:\tlearn: 0.1377303\ttotal: 37.5s\tremaining: 37.3s\n",
      "181:\tlearn: 0.1377114\ttotal: 37.7s\tremaining: 37.1s\n",
      "182:\tlearn: 0.1377021\ttotal: 37.9s\tremaining: 36.8s\n",
      "183:\tlearn: 0.1376906\ttotal: 38.1s\tremaining: 36.6s\n",
      "184:\tlearn: 0.1376826\ttotal: 38.3s\tremaining: 36.4s\n",
      "185:\tlearn: 0.1376715\ttotal: 38.5s\tremaining: 36.2s\n",
      "186:\tlearn: 0.1376659\ttotal: 38.6s\tremaining: 36s\n",
      "187:\tlearn: 0.1376522\ttotal: 38.9s\tremaining: 35.8s\n",
      "188:\tlearn: 0.1376388\ttotal: 39.1s\tremaining: 35.5s\n",
      "189:\tlearn: 0.1376295\ttotal: 39.2s\tremaining: 35.3s\n",
      "190:\tlearn: 0.1376161\ttotal: 39.4s\tremaining: 35.1s\n",
      "191:\tlearn: 0.1376073\ttotal: 39.6s\tremaining: 34.9s\n",
      "192:\tlearn: 0.1375989\ttotal: 39.8s\tremaining: 34.7s\n",
      "193:\tlearn: 0.1375901\ttotal: 40s\tremaining: 34.4s\n",
      "194:\tlearn: 0.1375694\ttotal: 40.2s\tremaining: 34.2s\n",
      "195:\tlearn: 0.1375655\ttotal: 40.4s\tremaining: 34s\n",
      "196:\tlearn: 0.1375589\ttotal: 40.5s\tremaining: 33.8s\n",
      "197:\tlearn: 0.1375434\ttotal: 40.8s\tremaining: 33.6s\n",
      "198:\tlearn: 0.1375352\ttotal: 41s\tremaining: 33.3s\n",
      "199:\tlearn: 0.1375243\ttotal: 41.1s\tremaining: 33.1s\n",
      "200:\tlearn: 0.1375031\ttotal: 41.4s\tremaining: 32.9s\n",
      "201:\tlearn: 0.1374919\ttotal: 41.6s\tremaining: 32.7s\n",
      "202:\tlearn: 0.1374862\ttotal: 41.7s\tremaining: 32.5s\n",
      "203:\tlearn: 0.1374713\ttotal: 42s\tremaining: 32.3s\n",
      "204:\tlearn: 0.1374577\ttotal: 42.1s\tremaining: 32.1s\n",
      "205:\tlearn: 0.1374470\ttotal: 42.3s\tremaining: 31.8s\n",
      "206:\tlearn: 0.1374338\ttotal: 42.5s\tremaining: 31.6s\n",
      "207:\tlearn: 0.1374251\ttotal: 42.7s\tremaining: 31.4s\n",
      "208:\tlearn: 0.1374183\ttotal: 42.9s\tremaining: 31.2s\n",
      "209:\tlearn: 0.1374075\ttotal: 43.1s\tremaining: 31s\n",
      "210:\tlearn: 0.1373931\ttotal: 43.3s\tremaining: 30.8s\n",
      "211:\tlearn: 0.1373787\ttotal: 43.5s\tremaining: 30.6s\n",
      "212:\tlearn: 0.1373593\ttotal: 43.7s\tremaining: 30.4s\n",
      "213:\tlearn: 0.1373411\ttotal: 44s\tremaining: 30.2s\n",
      "214:\tlearn: 0.1373315\ttotal: 44.2s\tremaining: 30s\n",
      "215:\tlearn: 0.1373154\ttotal: 44.4s\tremaining: 29.8s\n",
      "216:\tlearn: 0.1373061\ttotal: 44.6s\tremaining: 29.6s\n",
      "217:\tlearn: 0.1372930\ttotal: 44.8s\tremaining: 29.4s\n",
      "218:\tlearn: 0.1372746\ttotal: 45s\tremaining: 29.2s\n",
      "219:\tlearn: 0.1372700\ttotal: 45.1s\tremaining: 28.9s\n",
      "220:\tlearn: 0.1372626\ttotal: 45.3s\tremaining: 28.7s\n",
      "221:\tlearn: 0.1372520\ttotal: 45.5s\tremaining: 28.5s\n",
      "222:\tlearn: 0.1372409\ttotal: 45.7s\tremaining: 28.3s\n",
      "223:\tlearn: 0.1372305\ttotal: 45.9s\tremaining: 28.1s\n",
      "224:\tlearn: 0.1372172\ttotal: 46.1s\tremaining: 27.9s\n",
      "225:\tlearn: 0.1372123\ttotal: 46.3s\tremaining: 27.6s\n",
      "226:\tlearn: 0.1372037\ttotal: 46.5s\tremaining: 27.4s\n",
      "227:\tlearn: 0.1371954\ttotal: 46.7s\tremaining: 27.2s\n",
      "228:\tlearn: 0.1371868\ttotal: 46.8s\tremaining: 27s\n",
      "229:\tlearn: 0.1371757\ttotal: 47s\tremaining: 26.8s\n",
      "230:\tlearn: 0.1371678\ttotal: 47.2s\tremaining: 26.6s\n",
      "231:\tlearn: 0.1371511\ttotal: 47.5s\tremaining: 26.4s\n",
      "232:\tlearn: 0.1371431\ttotal: 47.6s\tremaining: 26.2s\n",
      "233:\tlearn: 0.1371290\ttotal: 47.8s\tremaining: 26s\n",
      "234:\tlearn: 0.1371080\ttotal: 48.1s\tremaining: 25.8s\n",
      "235:\tlearn: 0.1371019\ttotal: 48.3s\tremaining: 25.6s\n",
      "236:\tlearn: 0.1370947\ttotal: 48.4s\tremaining: 25.3s\n",
      "237:\tlearn: 0.1370869\ttotal: 48.6s\tremaining: 25.1s\n",
      "238:\tlearn: 0.1370763\ttotal: 48.8s\tremaining: 24.9s\n",
      "239:\tlearn: 0.1370619\ttotal: 49s\tremaining: 24.7s\n",
      "240:\tlearn: 0.1370553\ttotal: 49.2s\tremaining: 24.5s\n",
      "241:\tlearn: 0.1370455\ttotal: 49.4s\tremaining: 24.3s\n",
      "242:\tlearn: 0.1370406\ttotal: 49.6s\tremaining: 24.1s\n",
      "243:\tlearn: 0.1370269\ttotal: 49.8s\tremaining: 23.9s\n",
      "244:\tlearn: 0.1370098\ttotal: 50s\tremaining: 23.7s\n",
      "245:\tlearn: 0.1370046\ttotal: 50.2s\tremaining: 23.5s\n",
      "246:\tlearn: 0.1369883\ttotal: 50.4s\tremaining: 23.3s\n",
      "247:\tlearn: 0.1369843\ttotal: 50.5s\tremaining: 23s\n",
      "248:\tlearn: 0.1369778\ttotal: 50.7s\tremaining: 22.8s\n",
      "249:\tlearn: 0.1369689\ttotal: 50.9s\tremaining: 22.6s\n",
      "250:\tlearn: 0.1369605\ttotal: 51.1s\tremaining: 22.4s\n",
      "251:\tlearn: 0.1369509\ttotal: 51.3s\tremaining: 22.2s\n",
      "252:\tlearn: 0.1369416\ttotal: 51.5s\tremaining: 22s\n",
      "253:\tlearn: 0.1369353\ttotal: 51.7s\tremaining: 21.8s\n",
      "254:\tlearn: 0.1369249\ttotal: 51.9s\tremaining: 21.6s\n",
      "255:\tlearn: 0.1369186\ttotal: 52.1s\tremaining: 21.4s\n",
      "256:\tlearn: 0.1369080\ttotal: 52.3s\tremaining: 21.1s\n",
      "257:\tlearn: 0.1368976\ttotal: 52.5s\tremaining: 21s\n",
      "258:\tlearn: 0.1368824\ttotal: 52.7s\tremaining: 20.8s\n",
      "259:\tlearn: 0.1368743\ttotal: 52.9s\tremaining: 20.5s\n",
      "260:\tlearn: 0.1368635\ttotal: 53.1s\tremaining: 20.3s\n",
      "261:\tlearn: 0.1368522\ttotal: 53.3s\tremaining: 20.1s\n",
      "262:\tlearn: 0.1368419\ttotal: 53.5s\tremaining: 19.9s\n",
      "263:\tlearn: 0.1368296\ttotal: 53.7s\tremaining: 19.7s\n",
      "264:\tlearn: 0.1368211\ttotal: 53.9s\tremaining: 19.5s\n",
      "265:\tlearn: 0.1368147\ttotal: 54.1s\tremaining: 19.3s\n",
      "266:\tlearn: 0.1368092\ttotal: 54.2s\tremaining: 19.1s\n",
      "267:\tlearn: 0.1368018\ttotal: 54.4s\tremaining: 18.9s\n",
      "268:\tlearn: 0.1367940\ttotal: 54.6s\tremaining: 18.7s\n",
      "269:\tlearn: 0.1367850\ttotal: 54.8s\tremaining: 18.5s\n",
      "270:\tlearn: 0.1367792\ttotal: 55s\tremaining: 18.3s\n",
      "271:\tlearn: 0.1367728\ttotal: 55.2s\tremaining: 18.1s\n",
      "272:\tlearn: 0.1367641\ttotal: 55.4s\tremaining: 17.9s\n",
      "273:\tlearn: 0.1367501\ttotal: 55.6s\tremaining: 17.7s\n",
      "274:\tlearn: 0.1367428\ttotal: 55.8s\tremaining: 17.4s\n",
      "275:\tlearn: 0.1367382\ttotal: 56s\tremaining: 17.2s\n",
      "276:\tlearn: 0.1367332\ttotal: 56.1s\tremaining: 17s\n",
      "277:\tlearn: 0.1367288\ttotal: 56.3s\tremaining: 16.8s\n",
      "278:\tlearn: 0.1367197\ttotal: 56.5s\tremaining: 16.6s\n",
      "279:\tlearn: 0.1367142\ttotal: 56.6s\tremaining: 16.4s\n",
      "280:\tlearn: 0.1367041\ttotal: 56.8s\tremaining: 16.2s\n",
      "281:\tlearn: 0.1366969\ttotal: 57s\tremaining: 16s\n",
      "282:\tlearn: 0.1366878\ttotal: 57.2s\tremaining: 15.8s\n",
      "283:\tlearn: 0.1366703\ttotal: 57.4s\tremaining: 15.6s\n",
      "284:\tlearn: 0.1366604\ttotal: 57.6s\tremaining: 15.4s\n",
      "285:\tlearn: 0.1366529\ttotal: 57.8s\tremaining: 15.2s\n",
      "286:\tlearn: 0.1366406\ttotal: 58s\tremaining: 15s\n",
      "287:\tlearn: 0.1366342\ttotal: 58.2s\tremaining: 14.8s\n",
      "288:\tlearn: 0.1366246\ttotal: 58.4s\tremaining: 14.5s\n",
      "289:\tlearn: 0.1366182\ttotal: 58.6s\tremaining: 14.3s\n",
      "290:\tlearn: 0.1366102\ttotal: 58.8s\tremaining: 14.1s\n",
      "291:\tlearn: 0.1366056\ttotal: 58.9s\tremaining: 13.9s\n",
      "292:\tlearn: 0.1365940\ttotal: 59.1s\tremaining: 13.7s\n",
      "293:\tlearn: 0.1365864\ttotal: 59.4s\tremaining: 13.5s\n",
      "294:\tlearn: 0.1365801\ttotal: 59.5s\tremaining: 13.3s\n",
      "295:\tlearn: 0.1365760\ttotal: 59.7s\tremaining: 13.1s\n",
      "296:\tlearn: 0.1365631\ttotal: 59.9s\tremaining: 12.9s\n",
      "297:\tlearn: 0.1365555\ttotal: 1m\tremaining: 12.7s\n",
      "298:\tlearn: 0.1365481\ttotal: 1m\tremaining: 12.5s\n",
      "299:\tlearn: 0.1365420\ttotal: 1m\tremaining: 12.3s\n",
      "300:\tlearn: 0.1365259\ttotal: 1m\tremaining: 12.1s\n",
      "301:\tlearn: 0.1365169\ttotal: 1m\tremaining: 11.9s\n",
      "302:\tlearn: 0.1365072\ttotal: 1m 1s\tremaining: 11.7s\n",
      "303:\tlearn: 0.1365034\ttotal: 1m 1s\tremaining: 11.5s\n",
      "304:\tlearn: 0.1364943\ttotal: 1m 1s\tremaining: 11.3s\n",
      "305:\tlearn: 0.1364880\ttotal: 1m 1s\tremaining: 11.1s\n",
      "306:\tlearn: 0.1364793\ttotal: 1m 1s\tremaining: 10.9s\n",
      "307:\tlearn: 0.1364713\ttotal: 1m 1s\tremaining: 10.7s\n",
      "308:\tlearn: 0.1364664\ttotal: 1m 2s\tremaining: 10.5s\n",
      "309:\tlearn: 0.1364582\ttotal: 1m 2s\tremaining: 10.3s\n",
      "310:\tlearn: 0.1364509\ttotal: 1m 2s\tremaining: 10s\n",
      "311:\tlearn: 0.1364414\ttotal: 1m 2s\tremaining: 9.85s\n",
      "312:\tlearn: 0.1364355\ttotal: 1m 2s\tremaining: 9.64s\n",
      "313:\tlearn: 0.1364324\ttotal: 1m 3s\tremaining: 9.44s\n",
      "314:\tlearn: 0.1364233\ttotal: 1m 3s\tremaining: 9.24s\n",
      "315:\tlearn: 0.1364156\ttotal: 1m 3s\tremaining: 9.04s\n",
      "316:\tlearn: 0.1364058\ttotal: 1m 3s\tremaining: 8.84s\n",
      "317:\tlearn: 0.1364019\ttotal: 1m 3s\tremaining: 8.63s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318:\tlearn: 0.1363961\ttotal: 1m 3s\tremaining: 8.43s\n",
      "319:\tlearn: 0.1363896\ttotal: 1m 4s\tremaining: 8.22s\n",
      "320:\tlearn: 0.1363785\ttotal: 1m 4s\tremaining: 8.02s\n",
      "321:\tlearn: 0.1363736\ttotal: 1m 4s\tremaining: 7.82s\n",
      "322:\tlearn: 0.1363646\ttotal: 1m 4s\tremaining: 7.61s\n",
      "323:\tlearn: 0.1363576\ttotal: 1m 4s\tremaining: 7.41s\n",
      "324:\tlearn: 0.1363500\ttotal: 1m 5s\tremaining: 7.21s\n",
      "325:\tlearn: 0.1363434\ttotal: 1m 5s\tremaining: 7.01s\n",
      "326:\tlearn: 0.1363254\ttotal: 1m 5s\tremaining: 6.81s\n",
      "327:\tlearn: 0.1363181\ttotal: 1m 5s\tremaining: 6.61s\n",
      "328:\tlearn: 0.1363102\ttotal: 1m 5s\tremaining: 6.41s\n",
      "329:\tlearn: 0.1363034\ttotal: 1m 6s\tremaining: 6.21s\n",
      "330:\tlearn: 0.1362993\ttotal: 1m 6s\tremaining: 6s\n",
      "331:\tlearn: 0.1362887\ttotal: 1m 6s\tremaining: 5.8s\n",
      "332:\tlearn: 0.1362806\ttotal: 1m 6s\tremaining: 5.6s\n",
      "333:\tlearn: 0.1362742\ttotal: 1m 6s\tremaining: 5.4s\n",
      "334:\tlearn: 0.1362623\ttotal: 1m 7s\tremaining: 5.2s\n",
      "335:\tlearn: 0.1362540\ttotal: 1m 7s\tremaining: 5s\n",
      "336:\tlearn: 0.1362482\ttotal: 1m 7s\tremaining: 4.8s\n",
      "337:\tlearn: 0.1362439\ttotal: 1m 7s\tremaining: 4.6s\n",
      "338:\tlearn: 0.1362375\ttotal: 1m 7s\tremaining: 4.4s\n",
      "339:\tlearn: 0.1362279\ttotal: 1m 8s\tremaining: 4.2s\n",
      "340:\tlearn: 0.1362245\ttotal: 1m 8s\tremaining: 4s\n",
      "341:\tlearn: 0.1362136\ttotal: 1m 8s\tremaining: 3.8s\n",
      "342:\tlearn: 0.1362064\ttotal: 1m 8s\tremaining: 3.6s\n",
      "343:\tlearn: 0.1362015\ttotal: 1m 8s\tremaining: 3.4s\n",
      "344:\tlearn: 0.1361961\ttotal: 1m 8s\tremaining: 3.2s\n",
      "345:\tlearn: 0.1361883\ttotal: 1m 9s\tremaining: 3s\n",
      "346:\tlearn: 0.1361797\ttotal: 1m 9s\tremaining: 2.79s\n",
      "347:\tlearn: 0.1361703\ttotal: 1m 9s\tremaining: 2.6s\n",
      "348:\tlearn: 0.1361646\ttotal: 1m 9s\tremaining: 2.4s\n",
      "349:\tlearn: 0.1361557\ttotal: 1m 9s\tremaining: 2.2s\n",
      "350:\tlearn: 0.1361489\ttotal: 1m 10s\tremaining: 2s\n",
      "351:\tlearn: 0.1361376\ttotal: 1m 10s\tremaining: 1.8s\n",
      "352:\tlearn: 0.1361282\ttotal: 1m 10s\tremaining: 1.6s\n",
      "353:\tlearn: 0.1361219\ttotal: 1m 10s\tremaining: 1.4s\n",
      "354:\tlearn: 0.1361142\ttotal: 1m 10s\tremaining: 1.2s\n",
      "355:\tlearn: 0.1361083\ttotal: 1m 11s\tremaining: 998ms\n",
      "356:\tlearn: 0.1361005\ttotal: 1m 11s\tremaining: 799ms\n",
      "357:\tlearn: 0.1360982\ttotal: 1m 11s\tremaining: 598ms\n",
      "358:\tlearn: 0.1360909\ttotal: 1m 11s\tremaining: 399ms\n",
      "359:\tlearn: 0.1360849\ttotal: 1m 11s\tremaining: 199ms\n",
      "360:\tlearn: 0.1360738\ttotal: 1m 11s\tremaining: 0us\n",
      "Финальный ROC-AUC: 0.7517875198132905\n"
     ]
    }
   ],
   "source": [
    "# Тестируем на CatBoostClassifier, подбирая параметры с помощью optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,\n",
    "        'class_weights': class_weights_dict\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "final_preds = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, final_preds)\n",
    "print(\"Финальный ROC-AUC:\", final_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f440247",
   "metadata": {},
   "source": [
    "Итог: Более 0.75, берём данные преобразования в рассмотрение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c367b5a",
   "metadata": {},
   "source": [
    "### 6 эксперимент\n",
    "Используя успехи 5 эксперимента, добавляем средние значения каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66c34f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Имопртируем данные\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"train_data\")\n",
    "train_target = pd.read_csv(\"train_target.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f4ee4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим enc_paym_N к одному диапазону\n",
    "import numpy as np\n",
    "value_mapping = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3\n",
    "}\n",
    "\n",
    "columns_to_transform = ['enc_paym_11', 'enc_paym_20', 'enc_paym_24']\n",
    "\n",
    "for column in columns_to_transform:\n",
    "    df[column] = df[column].replace(value_mapping)\n",
    "# Подсчитываем кол-во статусов\n",
    "enc_paym_columns = [f'enc_paym_{i}' for i in range(25)] \n",
    "df[f'enc_paym_status_0'] = np.sum(df[enc_paym_columns].values == 0, axis=1)\n",
    "df[f'enc_paym_status_1'] = np.sum(df[enc_paym_columns].values == 1, axis=1)\n",
    "df[f'enc_paym_status_2'] = np.sum(df[enc_paym_columns].values == 2, axis=1)\n",
    "df[f'enc_paym_status_3'] = np.sum(df[enc_paym_columns].values == 3, axis=1)\n",
    "df.drop(enc_paym_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f36843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем новые признаки на основе других, по описанию как в 1 эксперименте.\n",
    "df[\"total_overdue_count\"] = df[\"pre_loans5\"] + df[\"pre_loans530\"] + df[\"pre_loans3060\"] + df[\"pre_loans6090\"] + df[\"pre_loans90\"]\n",
    "df.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)\n",
    "df[\"has_no_debt_flag\"] = df[\"is_zero_util\"] & df[\"is_zero_over2limit\"] & df[\"is_zero_maxover2limit\"]\n",
    "df.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)\n",
    "df[\"has_overdue_flag\"] = 1 - (df[\"is_zero_loans5\"] & df[\"is_zero_loans530\"] & df[\"is_zero_loans3060\"] & df[\"is_zero_loans6090\"] & df[\"is_zero_loans90\"])\n",
    "df.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)\n",
    "df[\"term_difference\"] = df[\"pre_pterm\"] - df[\"pre_fterm\"]\n",
    "df[\"close_difference\"] = df[\"pre_till_pclose\"] - df[\"pre_till_fclose\"]\n",
    "df.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "425a6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подсчёта уникальных значений каждого признака\n",
    "def create_count_columns_and_remove(df, columns_to_count):\n",
    "    for column in columns_to_count:\n",
    "        if column in df.columns and pd.api.types.is_numeric_dtype(df[column]):\n",
    "            unique_values = df[column].unique()\n",
    "            for value in unique_values:\n",
    "                df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42573d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\3627480594.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Опредеяем признаки, которые следует подсчитать и преобразуем. Прежде убрал бинарные признаки fclose/pclose_flag\n",
    "columns_to_agg = ['pre_since_opened', 'pre_since_confirmed', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ', 'pre_loans_outstanding', 'pre_loans_total_overdue', 'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_util', 'pre_over2limit', 'pre_maxover2limit', 'enc_loans_account_holder_type', 'enc_loans_credit_status', 'enc_loans_credit_type', 'enc_loans_account_cur']\n",
    "df_with_counts_max_means = create_count_columns_and_remove(df, columns_to_agg)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87c26275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определил правила аггрегации и сгруппировал данные\n",
    "aggregations = {\n",
    "    'has_no_debt_flag': 'median',\n",
    "    'has_overdue_flag': 'median',\n",
    "    'pclose_flag': 'median',\n",
    "    'fclose_flag': 'median',\n",
    "    **{col: 'sum' for col in df_with_counts_max_means.columns if col.endswith('_count')},\n",
    "    **{col: 'mean' for col in df_with_counts_max_means.columns if col not in ['has_no_debt_flag', 'has_overdue_flag', 'id', 'fclose_flag', 'pclose_flag']}\n",
    "}\n",
    "grouped_df = df_with_counts_max_means.groupby('id').agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ee86dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_with_counts_max_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4a89a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение с таргетом\n",
    "grouped_df = grouped_df.merge(train_target, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25f52f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем значения на X, y, train/test и стандартизируем их.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "X = grouped_df.drop(columns=['id', 'flag'])\n",
    "y = grouped_df['flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "# Здесь мы убираем из списка для стандартизации бинарные признаки\n",
    "features_to_scale = X_train.columns.difference(['has_no_debt_flag', 'has_overdue_flag', 'fclose_flag', 'pclose_flag'])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, features_to_scale),\n",
    "        ('passthrough', 'passthrough', ['has_no_debt_flag', 'has_overdue_flag', 'fclose_flag', 'pclose_flag'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=list(features_to_scale) + ['has_no_debt_flag', 'has_overdue_flag', 'fclose_flag', 'pclose_flag'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=list(features_to_scale) + ['has_no_debt_flag', 'has_overdue_flag', 'fclose_flag', 'pclose_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4d059ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чекпоинт скалера\n",
    "import pickle\n",
    "with open('scaler.pkl','wb') as f:\n",
    "    pickle.dump(preprocessor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем на CatBoostClassifier\n",
    "# Взял параметры из предыдущего эксперимента\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "params = {\n",
    "    'iterations': 361,\n",
    "    'learning_rate': 0.07525302007219146,\n",
    "    'depth': 8,\n",
    "    'l2_leaf_reg': 1,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0,\n",
    "    'class_weights': class_weights_dict\n",
    "}\n",
    "    \n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39dce1",
   "metadata": {},
   "source": [
    "Итог: 0.7532005635650828. Эти данные лучше всего подходят, так как имеют самую высокую метрику на одной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845118d",
   "metadata": {},
   "source": [
    "### Эксперименты с моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a58d8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 15:29:45,361] A new study created in memory with name: no-name-d0d4938d-8705-421a-88ca-486afe2a734a\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:30:40,925] Trial 0 finished with value: 0.7542534786574895 and parameters: {'iterations': 387, 'learning_rate': 0.08538574222674168, 'depth': 7, 'l2_leaf_reg': 9}. Best is trial 0 with value: 0.7542534786574895.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:33:39,945] Trial 1 finished with value: 0.7503892726431716 and parameters: {'iterations': 960, 'learning_rate': 0.07298846903025896, 'depth': 9, 'l2_leaf_reg': 2}. Best is trial 0 with value: 0.7542534786574895.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:34:02,393] Trial 2 finished with value: 0.6860244358714618 and parameters: {'iterations': 211, 'learning_rate': 3.869704859051864e-05, 'depth': 4, 'l2_leaf_reg': 6}. Best is trial 0 with value: 0.7542534786574895.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:34:22,464] Trial 3 finished with value: 0.7291308484357344 and parameters: {'iterations': 192, 'learning_rate': 0.023864700616617794, 'depth': 4, 'l2_leaf_reg': 2}. Best is trial 0 with value: 0.7542534786574895.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:35:45,344] Trial 4 finished with value: 0.7447095458880124 and parameters: {'iterations': 826, 'learning_rate': 0.021680135983389207, 'depth': 4, 'l2_leaf_reg': 9}. Best is trial 0 with value: 0.7542534786574895.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:36:29,164] Trial 5 finished with value: 0.7230686144905623 and parameters: {'iterations': 292, 'learning_rate': 0.004902517400150301, 'depth': 7, 'l2_leaf_reg': 2}. Best is trial 0 with value: 0.7542534786574895.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:39:09,147] Trial 6 finished with value: 0.710818276305287 and parameters: {'iterations': 969, 'learning_rate': 1.0703658658382422e-05, 'depth': 8, 'l2_leaf_reg': 5}. Best is trial 0 with value: 0.7542534786574895.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:41:08,187] Trial 7 finished with value: 0.7551199922862032 and parameters: {'iterations': 935, 'learning_rate': 0.05312609024208735, 'depth': 6, 'l2_leaf_reg': 1}. Best is trial 7 with value: 0.7551199922862032.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:41:25,096] Trial 8 finished with value: 0.7026611097286809 and parameters: {'iterations': 137, 'learning_rate': 0.002413321130653255, 'depth': 5, 'l2_leaf_reg': 5}. Best is trial 7 with value: 0.7551199922862032.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\626325385.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:42:27,798] Trial 9 finished with value: 0.7469819006127186 and parameters: {'iterations': 486, 'learning_rate': 0.029452972212970822, 'depth': 6, 'l2_leaf_reg': 7}. Best is trial 7 with value: 0.7551199922862032.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'iterations': 935, 'learning_rate': 0.05312609024208735, 'depth': 6, 'l2_leaf_reg': 1}\n",
      "Лучший ROC-AUC: 0.7551199922862032\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров CatBoost на финальных данных.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,\n",
    "        'class_weights': class_weights_dict\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5a131",
   "metadata": {},
   "source": [
    "Лучшие гиперпараметры: {'iterations': 935, 'learning_rate': 0.05312609024208735, 'depth': 6, 'l2_leaf_reg': 1}\n",
    "Лучший ROC-AUC: 0.7551199922862032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8e8f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:53:44,066] A new study created in memory with name: no-name-bcd484c7-1343-447b-9411-8774ac1cfa56\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.505227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:54:20,554] Trial 0 finished with value: 0.736452417419333 and parameters: {'n_estimators': 599, 'learning_rate': 0.008857730135169845, 'max_depth': 4, 'num_leaves': 55}. Best is trial 0 with value: 0.736452417419333.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.480728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:55:44,064] Trial 1 finished with value: 0.6967378149714947 and parameters: {'n_estimators': 926, 'learning_rate': 1.729600045148328e-05, 'max_depth': 5, 'num_leaves': 97}. Best is trial 0 with value: 0.736452417419333.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.525218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:56:11,023] Trial 2 finished with value: 0.70818645571019 and parameters: {'n_estimators': 132, 'learning_rate': 4.331610449633374e-05, 'max_depth': 9, 'num_leaves': 65}. Best is trial 0 with value: 0.736452417419333.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.455533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:57:43,598] Trial 3 finished with value: 0.7055935228727128 and parameters: {'n_estimators': 804, 'learning_rate': 7.954908136093614e-05, 'max_depth': 6, 'num_leaves': 38}. Best is trial 0 with value: 0.736452417419333.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:58:35,019] Trial 4 finished with value: 0.7539273090731384 and parameters: {'n_estimators': 896, 'learning_rate': 0.034363631126211436, 'max_depth': 9, 'num_leaves': 27}. Best is trial 4 with value: 0.7539273090731384.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.181322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:59:20,105] Trial 5 finished with value: 0.7094946243635231 and parameters: {'n_estimators': 459, 'learning_rate': 0.00026523034448260746, 'max_depth': 7, 'num_leaves': 45}. Best is trial 4 with value: 0.7539273090731384.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.459845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 14:59:46,515] Trial 6 finished with value: 0.6860034284275083 and parameters: {'n_estimators': 349, 'learning_rate': 3.585158444231599e-05, 'max_depth': 4, 'num_leaves': 98}. Best is trial 4 with value: 0.7539273090731384.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.494391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 15:00:44,088] Trial 7 finished with value: 0.7137596746999739 and parameters: {'n_estimators': 407, 'learning_rate': 0.0009962133272080336, 'max_depth': 7, 'num_leaves': 38}. Best is trial 4 with value: 0.7539273090731384.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.539611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 15:01:32,884] Trial 8 finished with value: 0.7542063324714363 and parameters: {'n_estimators': 437, 'learning_rate': 0.04778428283852397, 'max_depth': 10, 'num_leaves': 81}. Best is trial 8 with value: 0.7542063324714363.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\3737844853.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.498510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 15:02:39,175] Trial 9 finished with value: 0.7498644216635804 and parameters: {'n_estimators': 586, 'learning_rate': 0.014747241514021354, 'max_depth': 7, 'num_leaves': 55}. Best is trial 8 with value: 0.7542063324714363.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'n_estimators': 437, 'learning_rate': 0.04778428283852397, 'max_depth': 10, 'num_leaves': 81}\n",
      "Лучший ROC-AUC: 0.7542063324714363\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров LGBM на финальных данных.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f56a5b",
   "metadata": {},
   "source": [
    "Лучшие гиперпараметры: {'n_estimators': 437, 'learning_rate': 0.04778428283852397, 'max_depth': 10, 'num_leaves': 81}\n",
    "Лучший ROC-AUC: 0.7542063324714363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "923081a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 15:14:56,909] A new study created in memory with name: no-name-6df32c6f-1a7c-4581-8e3d-72044e42ebb2\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:15:24,864] Trial 0 finished with value: 0.7412145704504709 and parameters: {'n_estimators': 264, 'learning_rate': 0.014657180347155012, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.9705712357453846, 'colsample_bytree': 0.8530119505529817}. Best is trial 0 with value: 0.7412145704504709.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:17:27,748] Trial 1 finished with value: 0.7454640599912297 and parameters: {'n_estimators': 892, 'learning_rate': 0.003042887596450597, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.7593033255073088, 'colsample_bytree': 0.799968608027691}. Best is trial 1 with value: 0.7454640599912297.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:18:48,323] Trial 2 finished with value: 0.7003544020253873 and parameters: {'n_estimators': 936, 'learning_rate': 0.00023426911480882478, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.6390847153330204, 'colsample_bytree': 0.861005045570837}. Best is trial 1 with value: 0.7454640599912297.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:20:33,207] Trial 3 finished with value: 0.7346491670862234 and parameters: {'n_estimators': 598, 'learning_rate': 0.0002484948015410326, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8872942341540448, 'colsample_bytree': 0.7851887235793489}. Best is trial 1 with value: 0.7454640599912297.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:21:28,125] Trial 4 finished with value: 0.7223276347388301 and parameters: {'n_estimators': 490, 'learning_rate': 0.0011679108534256065, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8122708757960283, 'colsample_bytree': 0.7589921676739442}. Best is trial 1 with value: 0.7454640599912297.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:23:27,196] Trial 5 finished with value: 0.7285831435644824 and parameters: {'n_estimators': 882, 'learning_rate': 2.6935696280990447e-05, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.9675107514807549, 'colsample_bytree': 0.6943206793111998}. Best is trial 1 with value: 0.7454640599912297.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:25:47,670] Trial 6 finished with value: 0.7469228142680477 and parameters: {'n_estimators': 927, 'learning_rate': 0.0027578302202928276, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.7070210071053376, 'colsample_bytree': 0.7003727494296246}. Best is trial 6 with value: 0.7469228142680477.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:26:46,428] Trial 7 finished with value: 0.7534491687454309 and parameters: {'n_estimators': 873, 'learning_rate': 0.09607318384069156, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.6109521676209237, 'colsample_bytree': 0.7385982319190236}. Best is trial 7 with value: 0.7534491687454309.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:27:07,505] Trial 8 finished with value: 0.725649964330529 and parameters: {'n_estimators': 143, 'learning_rate': 1.3677954933222774e-05, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.5608354766870467, 'colsample_bytree': 0.9058658056032923}. Best is trial 7 with value: 0.7534491687454309.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\1747364344.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "[I 2024-09-23 15:28:11,537] Trial 9 finished with value: 0.7015198763117331 and parameters: {'n_estimators': 762, 'learning_rate': 0.0006362709374710738, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8939950652820761, 'colsample_bytree': 0.9838193615901232}. Best is trial 7 with value: 0.7534491687454309.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'n_estimators': 873, 'learning_rate': 0.09607318384069156, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.6109521676209237, 'colsample_bytree': 0.7385982319190236}\n",
      "Лучший ROC-AUC: 0.7534491687454309\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров XGBoost на финальных данных.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'scale_pos_weight': class_weights_dict[1] / class_weights_dict[0]\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba8272",
   "metadata": {},
   "source": [
    "Лучшие гиперпараметры: {'n_estimators': 873, 'learning_rate': 0.09607318384069156, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.6109521676209237, 'colsample_bytree': 0.7385982319190236}\n",
    "Лучший ROC-AUC: 0.7534491687454309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d94e5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняю словарь с лучшими параметрами для каждой из модели\n",
    "best_params = {'cat_iterations': 935, 'cat_learning_rate': 0.05312609024208735, 'cat_depth': 6, 'cat_l2_leaf_reg': 1, 'lgb_n_estimators': 437, 'lgb_learning_rate': 0.04778428283852397, 'lgb_max_depth': 10, 'lgb_num_leaves': 81, 'xgb_n_estimators': 873, 'xgb_learning_rate': 0.09607318384069156, 'xgb_max_depth': 4, 'xgb_min_child_weight': 3, 'xgb_subsample': 0.6109521676209237, 'xgb_colsample_bytree': 0.7385982319190236}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8c81a",
   "metadata": {},
   "source": [
    "#### Объединение 3-х моделей бустинга по наилучшим параметрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a8165b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6867491\ttotal: 203ms\tremaining: 3m 9s\n",
      "1:\tlearn: 0.6812500\ttotal: 411ms\tremaining: 3m 11s\n",
      "2:\tlearn: 0.6759802\ttotal: 608ms\tremaining: 3m 9s\n",
      "3:\tlearn: 0.6713522\ttotal: 808ms\tremaining: 3m 8s\n",
      "4:\tlearn: 0.6673067\ttotal: 1.03s\tremaining: 3m 11s\n",
      "5:\tlearn: 0.6633780\ttotal: 1.24s\tremaining: 3m 12s\n",
      "6:\tlearn: 0.6598701\ttotal: 1.44s\tremaining: 3m 11s\n",
      "7:\tlearn: 0.6564973\ttotal: 1.65s\tremaining: 3m 11s\n",
      "8:\tlearn: 0.6534603\ttotal: 1.89s\tremaining: 3m 14s\n",
      "9:\tlearn: 0.6506242\ttotal: 2.1s\tremaining: 3m 13s\n",
      "10:\tlearn: 0.6480755\ttotal: 2.3s\tremaining: 3m 13s\n",
      "11:\tlearn: 0.6457556\ttotal: 2.52s\tremaining: 3m 13s\n",
      "12:\tlearn: 0.6436336\ttotal: 2.75s\tremaining: 3m 14s\n",
      "13:\tlearn: 0.6416114\ttotal: 2.96s\tremaining: 3m 15s\n",
      "14:\tlearn: 0.6396915\ttotal: 3.18s\tremaining: 3m 15s\n",
      "15:\tlearn: 0.6380700\ttotal: 3.41s\tremaining: 3m 15s\n",
      "16:\tlearn: 0.6362786\ttotal: 3.61s\tremaining: 3m 14s\n",
      "17:\tlearn: 0.6348180\ttotal: 3.82s\tremaining: 3m 14s\n",
      "18:\tlearn: 0.6333265\ttotal: 4.02s\tremaining: 3m 13s\n",
      "19:\tlearn: 0.6319169\ttotal: 4.23s\tremaining: 3m 13s\n",
      "20:\tlearn: 0.6307438\ttotal: 4.43s\tremaining: 3m 12s\n",
      "21:\tlearn: 0.6296071\ttotal: 4.63s\tremaining: 3m 12s\n",
      "22:\tlearn: 0.6284707\ttotal: 4.84s\tremaining: 3m 12s\n",
      "23:\tlearn: 0.6273770\ttotal: 5.05s\tremaining: 3m 11s\n",
      "24:\tlearn: 0.6264155\ttotal: 5.26s\tremaining: 3m 11s\n",
      "25:\tlearn: 0.6254947\ttotal: 5.47s\tremaining: 3m 11s\n",
      "26:\tlearn: 0.6246405\ttotal: 5.67s\tremaining: 3m 10s\n",
      "27:\tlearn: 0.6237751\ttotal: 5.89s\tremaining: 3m 10s\n",
      "28:\tlearn: 0.6229787\ttotal: 6.08s\tremaining: 3m 10s\n",
      "29:\tlearn: 0.6221672\ttotal: 6.28s\tremaining: 3m 9s\n",
      "30:\tlearn: 0.6214431\ttotal: 6.48s\tremaining: 3m 8s\n",
      "31:\tlearn: 0.6206986\ttotal: 6.69s\tremaining: 3m 8s\n",
      "32:\tlearn: 0.6199736\ttotal: 6.9s\tremaining: 3m 8s\n",
      "33:\tlearn: 0.6193347\ttotal: 7.09s\tremaining: 3m 7s\n",
      "34:\tlearn: 0.6187064\ttotal: 7.28s\tremaining: 3m 7s\n",
      "35:\tlearn: 0.6180850\ttotal: 7.48s\tremaining: 3m 6s\n",
      "36:\tlearn: 0.6175033\ttotal: 7.68s\tremaining: 3m 6s\n",
      "37:\tlearn: 0.6169699\ttotal: 7.89s\tremaining: 3m 6s\n",
      "38:\tlearn: 0.6163701\ttotal: 8.1s\tremaining: 3m 6s\n",
      "39:\tlearn: 0.6158642\ttotal: 8.3s\tremaining: 3m 5s\n",
      "40:\tlearn: 0.6153678\ttotal: 8.49s\tremaining: 3m 5s\n",
      "41:\tlearn: 0.6149264\ttotal: 8.7s\tremaining: 3m 5s\n",
      "42:\tlearn: 0.6144132\ttotal: 8.9s\tremaining: 3m 4s\n",
      "43:\tlearn: 0.6139748\ttotal: 9.1s\tremaining: 3m 4s\n",
      "44:\tlearn: 0.6135649\ttotal: 9.29s\tremaining: 3m 3s\n",
      "45:\tlearn: 0.6131723\ttotal: 9.49s\tremaining: 3m 3s\n",
      "46:\tlearn: 0.6127752\ttotal: 9.69s\tremaining: 3m 3s\n",
      "47:\tlearn: 0.6123398\ttotal: 9.89s\tremaining: 3m 2s\n",
      "48:\tlearn: 0.6119856\ttotal: 10.1s\tremaining: 3m 2s\n",
      "49:\tlearn: 0.6114845\ttotal: 10.3s\tremaining: 3m 2s\n",
      "50:\tlearn: 0.6110799\ttotal: 10.5s\tremaining: 3m 1s\n",
      "51:\tlearn: 0.6107841\ttotal: 10.7s\tremaining: 3m 1s\n",
      "52:\tlearn: 0.6104239\ttotal: 10.9s\tremaining: 3m\n",
      "53:\tlearn: 0.6100200\ttotal: 11.1s\tremaining: 3m\n",
      "54:\tlearn: 0.6096406\ttotal: 11.3s\tremaining: 3m\n",
      "55:\tlearn: 0.6093714\ttotal: 11.5s\tremaining: 2m 59s\n",
      "56:\tlearn: 0.6090353\ttotal: 11.7s\tremaining: 2m 59s\n",
      "57:\tlearn: 0.6087325\ttotal: 11.8s\tremaining: 2m 59s\n",
      "58:\tlearn: 0.6084504\ttotal: 12.1s\tremaining: 2m 58s\n",
      "59:\tlearn: 0.6081683\ttotal: 12.3s\tremaining: 2m 58s\n",
      "60:\tlearn: 0.6079111\ttotal: 12.4s\tremaining: 2m 58s\n",
      "61:\tlearn: 0.6075712\ttotal: 12.7s\tremaining: 2m 58s\n",
      "62:\tlearn: 0.6072920\ttotal: 12.9s\tremaining: 2m 57s\n",
      "63:\tlearn: 0.6070346\ttotal: 13.1s\tremaining: 2m 57s\n",
      "64:\tlearn: 0.6067014\ttotal: 13.3s\tremaining: 2m 57s\n",
      "65:\tlearn: 0.6064471\ttotal: 13.5s\tremaining: 2m 57s\n",
      "66:\tlearn: 0.6062100\ttotal: 13.7s\tremaining: 2m 57s\n",
      "67:\tlearn: 0.6059228\ttotal: 13.9s\tremaining: 2m 56s\n",
      "68:\tlearn: 0.6056844\ttotal: 14.1s\tremaining: 2m 56s\n",
      "69:\tlearn: 0.6054806\ttotal: 14.3s\tremaining: 2m 56s\n",
      "70:\tlearn: 0.6052225\ttotal: 14.5s\tremaining: 2m 56s\n",
      "71:\tlearn: 0.6049876\ttotal: 14.7s\tremaining: 2m 55s\n",
      "72:\tlearn: 0.6047562\ttotal: 14.9s\tremaining: 2m 55s\n",
      "73:\tlearn: 0.6045882\ttotal: 15s\tremaining: 2m 54s\n",
      "74:\tlearn: 0.6043777\ttotal: 15.2s\tremaining: 2m 54s\n",
      "75:\tlearn: 0.6041996\ttotal: 15.4s\tremaining: 2m 54s\n",
      "76:\tlearn: 0.6039567\ttotal: 15.6s\tremaining: 2m 54s\n",
      "77:\tlearn: 0.6037432\ttotal: 15.8s\tremaining: 2m 54s\n",
      "78:\tlearn: 0.6035797\ttotal: 16s\tremaining: 2m 53s\n",
      "79:\tlearn: 0.6033902\ttotal: 16.3s\tremaining: 2m 53s\n",
      "80:\tlearn: 0.6032161\ttotal: 16.5s\tremaining: 2m 53s\n",
      "81:\tlearn: 0.6030710\ttotal: 16.7s\tremaining: 2m 53s\n",
      "82:\tlearn: 0.6029029\ttotal: 16.8s\tremaining: 2m 52s\n",
      "83:\tlearn: 0.6027501\ttotal: 17s\tremaining: 2m 52s\n",
      "84:\tlearn: 0.6025701\ttotal: 17.2s\tremaining: 2m 52s\n",
      "85:\tlearn: 0.6024048\ttotal: 17.4s\tremaining: 2m 52s\n",
      "86:\tlearn: 0.6022607\ttotal: 17.6s\tremaining: 2m 51s\n",
      "87:\tlearn: 0.6020953\ttotal: 17.8s\tremaining: 2m 51s\n",
      "88:\tlearn: 0.6018873\ttotal: 18s\tremaining: 2m 51s\n",
      "89:\tlearn: 0.6017233\ttotal: 18.2s\tremaining: 2m 50s\n",
      "90:\tlearn: 0.6015638\ttotal: 18.4s\tremaining: 2m 50s\n",
      "91:\tlearn: 0.6014314\ttotal: 18.6s\tremaining: 2m 50s\n",
      "92:\tlearn: 0.6013089\ttotal: 18.8s\tremaining: 2m 50s\n",
      "93:\tlearn: 0.6011058\ttotal: 19s\tremaining: 2m 50s\n",
      "94:\tlearn: 0.6009579\ttotal: 19.2s\tremaining: 2m 49s\n",
      "95:\tlearn: 0.6007439\ttotal: 19.4s\tremaining: 2m 49s\n",
      "96:\tlearn: 0.6006161\ttotal: 19.6s\tremaining: 2m 49s\n",
      "97:\tlearn: 0.6004735\ttotal: 19.8s\tremaining: 2m 49s\n",
      "98:\tlearn: 0.6003253\ttotal: 20s\tremaining: 2m 48s\n",
      "99:\tlearn: 0.6002311\ttotal: 20.2s\tremaining: 2m 48s\n",
      "100:\tlearn: 0.6000794\ttotal: 20.4s\tremaining: 2m 48s\n",
      "101:\tlearn: 0.5999165\ttotal: 20.6s\tremaining: 2m 48s\n",
      "102:\tlearn: 0.5997498\ttotal: 20.8s\tremaining: 2m 47s\n",
      "103:\tlearn: 0.5996569\ttotal: 21s\tremaining: 2m 47s\n",
      "104:\tlearn: 0.5995022\ttotal: 21.2s\tremaining: 2m 47s\n",
      "105:\tlearn: 0.5994047\ttotal: 21.4s\tremaining: 2m 47s\n",
      "106:\tlearn: 0.5992581\ttotal: 21.6s\tremaining: 2m 46s\n",
      "107:\tlearn: 0.5991348\ttotal: 21.8s\tremaining: 2m 46s\n",
      "108:\tlearn: 0.5990025\ttotal: 22s\tremaining: 2m 46s\n",
      "109:\tlearn: 0.5989064\ttotal: 22.1s\tremaining: 2m 46s\n",
      "110:\tlearn: 0.5988084\ttotal: 22.3s\tremaining: 2m 45s\n",
      "111:\tlearn: 0.5986667\ttotal: 22.6s\tremaining: 2m 45s\n",
      "112:\tlearn: 0.5985341\ttotal: 22.8s\tremaining: 2m 45s\n",
      "113:\tlearn: 0.5984278\ttotal: 23s\tremaining: 2m 45s\n",
      "114:\tlearn: 0.5983273\ttotal: 23.2s\tremaining: 2m 45s\n",
      "115:\tlearn: 0.5982438\ttotal: 23.3s\tremaining: 2m 44s\n",
      "116:\tlearn: 0.5981441\ttotal: 23.6s\tremaining: 2m 44s\n",
      "117:\tlearn: 0.5980442\ttotal: 23.7s\tremaining: 2m 44s\n",
      "118:\tlearn: 0.5979572\ttotal: 23.9s\tremaining: 2m 44s\n",
      "119:\tlearn: 0.5978486\ttotal: 24.1s\tremaining: 2m 43s\n",
      "120:\tlearn: 0.5977428\ttotal: 24.3s\tremaining: 2m 43s\n",
      "121:\tlearn: 0.5976399\ttotal: 24.5s\tremaining: 2m 43s\n",
      "122:\tlearn: 0.5975608\ttotal: 24.7s\tremaining: 2m 43s\n",
      "123:\tlearn: 0.5974461\ttotal: 24.9s\tremaining: 2m 42s\n",
      "124:\tlearn: 0.5973564\ttotal: 25.1s\tremaining: 2m 42s\n",
      "125:\tlearn: 0.5972529\ttotal: 25.3s\tremaining: 2m 42s\n",
      "126:\tlearn: 0.5971579\ttotal: 25.5s\tremaining: 2m 42s\n",
      "127:\tlearn: 0.5970456\ttotal: 25.7s\tremaining: 2m 42s\n",
      "128:\tlearn: 0.5969476\ttotal: 25.9s\tremaining: 2m 42s\n",
      "129:\tlearn: 0.5968529\ttotal: 26.2s\tremaining: 2m 42s\n",
      "130:\tlearn: 0.5967891\ttotal: 26.3s\tremaining: 2m 41s\n",
      "131:\tlearn: 0.5966896\ttotal: 26.5s\tremaining: 2m 41s\n",
      "132:\tlearn: 0.5966010\ttotal: 26.7s\tremaining: 2m 41s\n",
      "133:\tlearn: 0.5965505\ttotal: 26.9s\tremaining: 2m 40s\n",
      "134:\tlearn: 0.5964354\ttotal: 27.1s\tremaining: 2m 40s\n",
      "135:\tlearn: 0.5963594\ttotal: 27.3s\tremaining: 2m 40s\n",
      "136:\tlearn: 0.5962900\ttotal: 27.5s\tremaining: 2m 40s\n",
      "137:\tlearn: 0.5962231\ttotal: 27.7s\tremaining: 2m 40s\n",
      "138:\tlearn: 0.5961520\ttotal: 27.9s\tremaining: 2m 39s\n",
      "139:\tlearn: 0.5960865\ttotal: 28.1s\tremaining: 2m 39s\n",
      "140:\tlearn: 0.5960087\ttotal: 28.3s\tremaining: 2m 39s\n",
      "141:\tlearn: 0.5959440\ttotal: 28.5s\tremaining: 2m 38s\n",
      "142:\tlearn: 0.5958193\ttotal: 28.7s\tremaining: 2m 38s\n",
      "143:\tlearn: 0.5957535\ttotal: 28.8s\tremaining: 2m 38s\n",
      "144:\tlearn: 0.5955957\ttotal: 29.1s\tremaining: 2m 38s\n",
      "145:\tlearn: 0.5955322\ttotal: 29.3s\tremaining: 2m 38s\n",
      "146:\tlearn: 0.5954318\ttotal: 29.5s\tremaining: 2m 38s\n",
      "147:\tlearn: 0.5953583\ttotal: 29.7s\tremaining: 2m 37s\n",
      "148:\tlearn: 0.5952876\ttotal: 29.9s\tremaining: 2m 37s\n",
      "149:\tlearn: 0.5951964\ttotal: 30.1s\tremaining: 2m 37s\n",
      "150:\tlearn: 0.5950638\ttotal: 30.3s\tremaining: 2m 37s\n",
      "151:\tlearn: 0.5950064\ttotal: 30.5s\tremaining: 2m 37s\n",
      "152:\tlearn: 0.5949224\ttotal: 30.7s\tremaining: 2m 36s\n",
      "153:\tlearn: 0.5948553\ttotal: 30.9s\tremaining: 2m 36s\n",
      "154:\tlearn: 0.5947944\ttotal: 31.1s\tremaining: 2m 36s\n",
      "155:\tlearn: 0.5947480\ttotal: 31.2s\tremaining: 2m 36s\n",
      "156:\tlearn: 0.5946782\ttotal: 31.4s\tremaining: 2m 35s\n",
      "157:\tlearn: 0.5946128\ttotal: 31.6s\tremaining: 2m 35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.5945679\ttotal: 31.8s\tremaining: 2m 35s\n",
      "159:\tlearn: 0.5944838\ttotal: 32s\tremaining: 2m 35s\n",
      "160:\tlearn: 0.5944114\ttotal: 32.2s\tremaining: 2m 35s\n",
      "161:\tlearn: 0.5943204\ttotal: 32.5s\tremaining: 2m 34s\n",
      "162:\tlearn: 0.5942501\ttotal: 32.7s\tremaining: 2m 34s\n",
      "163:\tlearn: 0.5941999\ttotal: 32.8s\tremaining: 2m 34s\n",
      "164:\tlearn: 0.5941543\ttotal: 33s\tremaining: 2m 34s\n",
      "165:\tlearn: 0.5940959\ttotal: 33.2s\tremaining: 2m 33s\n",
      "166:\tlearn: 0.5940155\ttotal: 33.4s\tremaining: 2m 33s\n",
      "167:\tlearn: 0.5939276\ttotal: 33.6s\tremaining: 2m 33s\n",
      "168:\tlearn: 0.5938663\ttotal: 33.8s\tremaining: 2m 33s\n",
      "169:\tlearn: 0.5938200\ttotal: 34s\tremaining: 2m 33s\n",
      "170:\tlearn: 0.5937609\ttotal: 34.2s\tremaining: 2m 32s\n",
      "171:\tlearn: 0.5936962\ttotal: 34.4s\tremaining: 2m 32s\n",
      "172:\tlearn: 0.5935966\ttotal: 34.6s\tremaining: 2m 32s\n",
      "173:\tlearn: 0.5935457\ttotal: 34.8s\tremaining: 2m 32s\n",
      "174:\tlearn: 0.5934972\ttotal: 35s\tremaining: 2m 32s\n",
      "175:\tlearn: 0.5934271\ttotal: 35.2s\tremaining: 2m 31s\n",
      "176:\tlearn: 0.5933425\ttotal: 35.4s\tremaining: 2m 31s\n",
      "177:\tlearn: 0.5932825\ttotal: 35.6s\tremaining: 2m 31s\n",
      "178:\tlearn: 0.5932308\ttotal: 35.8s\tremaining: 2m 31s\n",
      "179:\tlearn: 0.5931885\ttotal: 36s\tremaining: 2m 30s\n",
      "180:\tlearn: 0.5931101\ttotal: 36.2s\tremaining: 2m 30s\n",
      "181:\tlearn: 0.5930655\ttotal: 36.4s\tremaining: 2m 30s\n",
      "182:\tlearn: 0.5929920\ttotal: 36.6s\tremaining: 2m 30s\n",
      "183:\tlearn: 0.5929182\ttotal: 36.8s\tremaining: 2m 30s\n",
      "184:\tlearn: 0.5928685\ttotal: 37s\tremaining: 2m 30s\n",
      "185:\tlearn: 0.5928144\ttotal: 37.2s\tremaining: 2m 29s\n",
      "186:\tlearn: 0.5927323\ttotal: 37.4s\tremaining: 2m 29s\n",
      "187:\tlearn: 0.5926724\ttotal: 37.6s\tremaining: 2m 29s\n",
      "188:\tlearn: 0.5926265\ttotal: 37.8s\tremaining: 2m 29s\n",
      "189:\tlearn: 0.5925809\ttotal: 38s\tremaining: 2m 29s\n",
      "190:\tlearn: 0.5925477\ttotal: 38.2s\tremaining: 2m 28s\n",
      "191:\tlearn: 0.5924967\ttotal: 38.4s\tremaining: 2m 28s\n",
      "192:\tlearn: 0.5924419\ttotal: 38.6s\tremaining: 2m 28s\n",
      "193:\tlearn: 0.5923724\ttotal: 38.8s\tremaining: 2m 28s\n",
      "194:\tlearn: 0.5923239\ttotal: 39s\tremaining: 2m 28s\n",
      "195:\tlearn: 0.5922645\ttotal: 39.2s\tremaining: 2m 27s\n",
      "196:\tlearn: 0.5921996\ttotal: 39.4s\tremaining: 2m 27s\n",
      "197:\tlearn: 0.5921414\ttotal: 39.6s\tremaining: 2m 27s\n",
      "198:\tlearn: 0.5921031\ttotal: 39.8s\tremaining: 2m 27s\n",
      "199:\tlearn: 0.5920450\ttotal: 40s\tremaining: 2m 27s\n",
      "200:\tlearn: 0.5919883\ttotal: 40.2s\tremaining: 2m 26s\n",
      "201:\tlearn: 0.5919561\ttotal: 40.4s\tremaining: 2m 26s\n",
      "202:\tlearn: 0.5918988\ttotal: 40.6s\tremaining: 2m 26s\n",
      "203:\tlearn: 0.5918513\ttotal: 40.8s\tremaining: 2m 26s\n",
      "204:\tlearn: 0.5917644\ttotal: 41.1s\tremaining: 2m 26s\n",
      "205:\tlearn: 0.5916446\ttotal: 41.3s\tremaining: 2m 26s\n",
      "206:\tlearn: 0.5915715\ttotal: 41.5s\tremaining: 2m 25s\n",
      "207:\tlearn: 0.5915330\ttotal: 41.7s\tremaining: 2m 25s\n",
      "208:\tlearn: 0.5914898\ttotal: 41.9s\tremaining: 2m 25s\n",
      "209:\tlearn: 0.5914492\ttotal: 42.1s\tremaining: 2m 25s\n",
      "210:\tlearn: 0.5914078\ttotal: 42.3s\tremaining: 2m 24s\n",
      "211:\tlearn: 0.5913479\ttotal: 42.5s\tremaining: 2m 24s\n",
      "212:\tlearn: 0.5913053\ttotal: 42.7s\tremaining: 2m 24s\n",
      "213:\tlearn: 0.5912587\ttotal: 42.9s\tremaining: 2m 24s\n",
      "214:\tlearn: 0.5912023\ttotal: 43.1s\tremaining: 2m 24s\n",
      "215:\tlearn: 0.5911448\ttotal: 43.3s\tremaining: 2m 24s\n",
      "216:\tlearn: 0.5911008\ttotal: 43.5s\tremaining: 2m 23s\n",
      "217:\tlearn: 0.5910630\ttotal: 43.7s\tremaining: 2m 23s\n",
      "218:\tlearn: 0.5910255\ttotal: 43.9s\tremaining: 2m 23s\n",
      "219:\tlearn: 0.5909873\ttotal: 44.1s\tremaining: 2m 23s\n",
      "220:\tlearn: 0.5909569\ttotal: 44.3s\tremaining: 2m 23s\n",
      "221:\tlearn: 0.5908584\ttotal: 44.5s\tremaining: 2m 22s\n",
      "222:\tlearn: 0.5908020\ttotal: 44.7s\tremaining: 2m 22s\n",
      "223:\tlearn: 0.5907440\ttotal: 44.9s\tremaining: 2m 22s\n",
      "224:\tlearn: 0.5907055\ttotal: 45.1s\tremaining: 2m 22s\n",
      "225:\tlearn: 0.5906571\ttotal: 45.3s\tremaining: 2m 22s\n",
      "226:\tlearn: 0.5906338\ttotal: 45.5s\tremaining: 2m 21s\n",
      "227:\tlearn: 0.5905639\ttotal: 45.8s\tremaining: 2m 21s\n",
      "228:\tlearn: 0.5904973\ttotal: 46s\tremaining: 2m 21s\n",
      "229:\tlearn: 0.5904523\ttotal: 46.2s\tremaining: 2m 21s\n",
      "230:\tlearn: 0.5904163\ttotal: 46.4s\tremaining: 2m 21s\n",
      "231:\tlearn: 0.5903723\ttotal: 46.6s\tremaining: 2m 21s\n",
      "232:\tlearn: 0.5903350\ttotal: 46.8s\tremaining: 2m 21s\n",
      "233:\tlearn: 0.5902854\ttotal: 47s\tremaining: 2m 20s\n",
      "234:\tlearn: 0.5902508\ttotal: 47.2s\tremaining: 2m 20s\n",
      "235:\tlearn: 0.5901967\ttotal: 47.4s\tremaining: 2m 20s\n",
      "236:\tlearn: 0.5901392\ttotal: 47.6s\tremaining: 2m 20s\n",
      "237:\tlearn: 0.5900887\ttotal: 47.8s\tremaining: 2m 19s\n",
      "238:\tlearn: 0.5900412\ttotal: 48s\tremaining: 2m 19s\n",
      "239:\tlearn: 0.5899957\ttotal: 48.2s\tremaining: 2m 19s\n",
      "240:\tlearn: 0.5899480\ttotal: 48.4s\tremaining: 2m 19s\n",
      "241:\tlearn: 0.5898936\ttotal: 48.6s\tremaining: 2m 19s\n",
      "242:\tlearn: 0.5898597\ttotal: 48.8s\tremaining: 2m 18s\n",
      "243:\tlearn: 0.5898167\ttotal: 49s\tremaining: 2m 18s\n",
      "244:\tlearn: 0.5897587\ttotal: 49.2s\tremaining: 2m 18s\n",
      "245:\tlearn: 0.5897322\ttotal: 49.4s\tremaining: 2m 18s\n",
      "246:\tlearn: 0.5896712\ttotal: 49.6s\tremaining: 2m 18s\n",
      "247:\tlearn: 0.5896317\ttotal: 49.8s\tremaining: 2m 17s\n",
      "248:\tlearn: 0.5895917\ttotal: 50s\tremaining: 2m 17s\n",
      "249:\tlearn: 0.5895451\ttotal: 50.3s\tremaining: 2m 17s\n",
      "250:\tlearn: 0.5894924\ttotal: 50.5s\tremaining: 2m 17s\n",
      "251:\tlearn: 0.5894565\ttotal: 50.7s\tremaining: 2m 17s\n",
      "252:\tlearn: 0.5894018\ttotal: 50.9s\tremaining: 2m 17s\n",
      "253:\tlearn: 0.5893612\ttotal: 51.1s\tremaining: 2m 16s\n",
      "254:\tlearn: 0.5893315\ttotal: 51.3s\tremaining: 2m 16s\n",
      "255:\tlearn: 0.5892850\ttotal: 51.5s\tremaining: 2m 16s\n",
      "256:\tlearn: 0.5892451\ttotal: 51.7s\tremaining: 2m 16s\n",
      "257:\tlearn: 0.5891640\ttotal: 51.9s\tremaining: 2m 16s\n",
      "258:\tlearn: 0.5891207\ttotal: 52.1s\tremaining: 2m 15s\n",
      "259:\tlearn: 0.5890818\ttotal: 52.3s\tremaining: 2m 15s\n",
      "260:\tlearn: 0.5890374\ttotal: 52.5s\tremaining: 2m 15s\n",
      "261:\tlearn: 0.5889991\ttotal: 52.7s\tremaining: 2m 15s\n",
      "262:\tlearn: 0.5889591\ttotal: 52.9s\tremaining: 2m 15s\n",
      "263:\tlearn: 0.5889135\ttotal: 53.1s\tremaining: 2m 14s\n",
      "264:\tlearn: 0.5888712\ttotal: 53.3s\tremaining: 2m 14s\n",
      "265:\tlearn: 0.5888218\ttotal: 53.5s\tremaining: 2m 14s\n",
      "266:\tlearn: 0.5887720\ttotal: 53.7s\tremaining: 2m 14s\n",
      "267:\tlearn: 0.5887272\ttotal: 53.9s\tremaining: 2m 14s\n",
      "268:\tlearn: 0.5886761\ttotal: 54.1s\tremaining: 2m 13s\n",
      "269:\tlearn: 0.5886220\ttotal: 54.3s\tremaining: 2m 13s\n",
      "270:\tlearn: 0.5885736\ttotal: 54.5s\tremaining: 2m 13s\n",
      "271:\tlearn: 0.5885310\ttotal: 54.7s\tremaining: 2m 13s\n",
      "272:\tlearn: 0.5884990\ttotal: 54.9s\tremaining: 2m 13s\n",
      "273:\tlearn: 0.5884356\ttotal: 55.1s\tremaining: 2m 13s\n",
      "274:\tlearn: 0.5883789\ttotal: 55.3s\tremaining: 2m 12s\n",
      "275:\tlearn: 0.5883316\ttotal: 55.5s\tremaining: 2m 12s\n",
      "276:\tlearn: 0.5882801\ttotal: 55.7s\tremaining: 2m 12s\n",
      "277:\tlearn: 0.5882331\ttotal: 55.9s\tremaining: 2m 12s\n",
      "278:\tlearn: 0.5881682\ttotal: 56.1s\tremaining: 2m 12s\n",
      "279:\tlearn: 0.5881128\ttotal: 56.3s\tremaining: 2m 11s\n",
      "280:\tlearn: 0.5880748\ttotal: 56.5s\tremaining: 2m 11s\n",
      "281:\tlearn: 0.5880144\ttotal: 56.7s\tremaining: 2m 11s\n",
      "282:\tlearn: 0.5879272\ttotal: 56.9s\tremaining: 2m 11s\n",
      "283:\tlearn: 0.5878742\ttotal: 57.1s\tremaining: 2m 10s\n",
      "284:\tlearn: 0.5878155\ttotal: 57.3s\tremaining: 2m 10s\n",
      "285:\tlearn: 0.5877571\ttotal: 57.5s\tremaining: 2m 10s\n",
      "286:\tlearn: 0.5877121\ttotal: 57.7s\tremaining: 2m 10s\n",
      "287:\tlearn: 0.5876659\ttotal: 57.9s\tremaining: 2m 10s\n",
      "288:\tlearn: 0.5876113\ttotal: 58.1s\tremaining: 2m 9s\n",
      "289:\tlearn: 0.5875633\ttotal: 58.3s\tremaining: 2m 9s\n",
      "290:\tlearn: 0.5875272\ttotal: 58.5s\tremaining: 2m 9s\n",
      "291:\tlearn: 0.5874855\ttotal: 58.7s\tremaining: 2m 9s\n",
      "292:\tlearn: 0.5874256\ttotal: 58.9s\tremaining: 2m 9s\n",
      "293:\tlearn: 0.5873666\ttotal: 59.1s\tremaining: 2m 8s\n",
      "294:\tlearn: 0.5873138\ttotal: 59.3s\tremaining: 2m 8s\n",
      "295:\tlearn: 0.5872753\ttotal: 59.5s\tremaining: 2m 8s\n",
      "296:\tlearn: 0.5872341\ttotal: 59.7s\tremaining: 2m 8s\n",
      "297:\tlearn: 0.5871895\ttotal: 59.9s\tremaining: 2m 8s\n",
      "298:\tlearn: 0.5871280\ttotal: 1m\tremaining: 2m 7s\n",
      "299:\tlearn: 0.5870822\ttotal: 1m\tremaining: 2m 7s\n",
      "300:\tlearn: 0.5870193\ttotal: 1m\tremaining: 2m 7s\n",
      "301:\tlearn: 0.5869690\ttotal: 1m\tremaining: 2m 7s\n",
      "302:\tlearn: 0.5869221\ttotal: 1m\tremaining: 2m 7s\n",
      "303:\tlearn: 0.5868711\ttotal: 1m 1s\tremaining: 2m 6s\n",
      "304:\tlearn: 0.5868334\ttotal: 1m 1s\tremaining: 2m 6s\n",
      "305:\tlearn: 0.5867964\ttotal: 1m 1s\tremaining: 2m 6s\n",
      "306:\tlearn: 0.5867389\ttotal: 1m 1s\tremaining: 2m 6s\n",
      "307:\tlearn: 0.5866958\ttotal: 1m 1s\tremaining: 2m 6s\n",
      "308:\tlearn: 0.5866166\ttotal: 1m 2s\tremaining: 2m 5s\n",
      "309:\tlearn: 0.5865559\ttotal: 1m 2s\tremaining: 2m 5s\n",
      "310:\tlearn: 0.5865101\ttotal: 1m 2s\tremaining: 2m 5s\n",
      "311:\tlearn: 0.5864606\ttotal: 1m 2s\tremaining: 2m 5s\n",
      "312:\tlearn: 0.5864042\ttotal: 1m 2s\tremaining: 2m 5s\n",
      "313:\tlearn: 0.5863527\ttotal: 1m 3s\tremaining: 2m 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314:\tlearn: 0.5862997\ttotal: 1m 3s\tremaining: 2m 4s\n",
      "315:\tlearn: 0.5862465\ttotal: 1m 3s\tremaining: 2m 4s\n",
      "316:\tlearn: 0.5861935\ttotal: 1m 3s\tremaining: 2m 4s\n",
      "317:\tlearn: 0.5861521\ttotal: 1m 3s\tremaining: 2m 4s\n",
      "318:\tlearn: 0.5861059\ttotal: 1m 4s\tremaining: 2m 3s\n",
      "319:\tlearn: 0.5860378\ttotal: 1m 4s\tremaining: 2m 3s\n",
      "320:\tlearn: 0.5859810\ttotal: 1m 4s\tremaining: 2m 3s\n",
      "321:\tlearn: 0.5859397\ttotal: 1m 4s\tremaining: 2m 3s\n",
      "322:\tlearn: 0.5859007\ttotal: 1m 5s\tremaining: 2m 3s\n",
      "323:\tlearn: 0.5858520\ttotal: 1m 5s\tremaining: 2m 3s\n",
      "324:\tlearn: 0.5858081\ttotal: 1m 5s\tremaining: 2m 2s\n",
      "325:\tlearn: 0.5857561\ttotal: 1m 5s\tremaining: 2m 2s\n",
      "326:\tlearn: 0.5857238\ttotal: 1m 5s\tremaining: 2m 2s\n",
      "327:\tlearn: 0.5856682\ttotal: 1m 6s\tremaining: 2m 2s\n",
      "328:\tlearn: 0.5856166\ttotal: 1m 6s\tremaining: 2m 2s\n",
      "329:\tlearn: 0.5855617\ttotal: 1m 6s\tremaining: 2m 1s\n",
      "330:\tlearn: 0.5855120\ttotal: 1m 6s\tremaining: 2m 1s\n",
      "331:\tlearn: 0.5854684\ttotal: 1m 6s\tremaining: 2m 1s\n",
      "332:\tlearn: 0.5854143\ttotal: 1m 7s\tremaining: 2m 1s\n",
      "333:\tlearn: 0.5853743\ttotal: 1m 7s\tremaining: 2m 1s\n",
      "334:\tlearn: 0.5853305\ttotal: 1m 7s\tremaining: 2m\n",
      "335:\tlearn: 0.5852795\ttotal: 1m 7s\tremaining: 2m\n",
      "336:\tlearn: 0.5852377\ttotal: 1m 7s\tremaining: 2m\n",
      "337:\tlearn: 0.5851907\ttotal: 1m 8s\tremaining: 2m\n",
      "338:\tlearn: 0.5851458\ttotal: 1m 8s\tremaining: 2m\n",
      "339:\tlearn: 0.5851044\ttotal: 1m 8s\tremaining: 1m 59s\n",
      "340:\tlearn: 0.5850577\ttotal: 1m 8s\tremaining: 1m 59s\n",
      "341:\tlearn: 0.5850159\ttotal: 1m 8s\tremaining: 1m 59s\n",
      "342:\tlearn: 0.5849579\ttotal: 1m 9s\tremaining: 1m 59s\n",
      "343:\tlearn: 0.5849140\ttotal: 1m 9s\tremaining: 1m 59s\n",
      "344:\tlearn: 0.5848691\ttotal: 1m 9s\tremaining: 1m 58s\n",
      "345:\tlearn: 0.5848222\ttotal: 1m 9s\tremaining: 1m 58s\n",
      "346:\tlearn: 0.5847768\ttotal: 1m 9s\tremaining: 1m 58s\n",
      "347:\tlearn: 0.5847304\ttotal: 1m 10s\tremaining: 1m 58s\n",
      "348:\tlearn: 0.5846839\ttotal: 1m 10s\tremaining: 1m 58s\n",
      "349:\tlearn: 0.5846302\ttotal: 1m 10s\tremaining: 1m 57s\n",
      "350:\tlearn: 0.5845902\ttotal: 1m 10s\tremaining: 1m 57s\n",
      "351:\tlearn: 0.5845347\ttotal: 1m 10s\tremaining: 1m 57s\n",
      "352:\tlearn: 0.5845003\ttotal: 1m 11s\tremaining: 1m 57s\n",
      "353:\tlearn: 0.5844496\ttotal: 1m 11s\tremaining: 1m 56s\n",
      "354:\tlearn: 0.5844096\ttotal: 1m 11s\tremaining: 1m 56s\n",
      "355:\tlearn: 0.5843682\ttotal: 1m 11s\tremaining: 1m 56s\n",
      "356:\tlearn: 0.5843187\ttotal: 1m 11s\tremaining: 1m 56s\n",
      "357:\tlearn: 0.5842828\ttotal: 1m 12s\tremaining: 1m 56s\n",
      "358:\tlearn: 0.5842246\ttotal: 1m 12s\tremaining: 1m 55s\n",
      "359:\tlearn: 0.5841675\ttotal: 1m 12s\tremaining: 1m 55s\n",
      "360:\tlearn: 0.5841292\ttotal: 1m 12s\tremaining: 1m 55s\n",
      "361:\tlearn: 0.5840919\ttotal: 1m 12s\tremaining: 1m 55s\n",
      "362:\tlearn: 0.5840480\ttotal: 1m 13s\tremaining: 1m 55s\n",
      "363:\tlearn: 0.5840070\ttotal: 1m 13s\tremaining: 1m 54s\n",
      "364:\tlearn: 0.5839690\ttotal: 1m 13s\tremaining: 1m 54s\n",
      "365:\tlearn: 0.5839382\ttotal: 1m 13s\tremaining: 1m 54s\n",
      "366:\tlearn: 0.5838849\ttotal: 1m 13s\tremaining: 1m 54s\n",
      "367:\tlearn: 0.5838492\ttotal: 1m 14s\tremaining: 1m 54s\n",
      "368:\tlearn: 0.5837953\ttotal: 1m 14s\tremaining: 1m 53s\n",
      "369:\tlearn: 0.5837561\ttotal: 1m 14s\tremaining: 1m 53s\n",
      "370:\tlearn: 0.5837075\ttotal: 1m 14s\tremaining: 1m 53s\n",
      "371:\tlearn: 0.5836564\ttotal: 1m 14s\tremaining: 1m 53s\n",
      "372:\tlearn: 0.5836072\ttotal: 1m 15s\tremaining: 1m 53s\n",
      "373:\tlearn: 0.5835645\ttotal: 1m 15s\tremaining: 1m 52s\n",
      "374:\tlearn: 0.5835153\ttotal: 1m 15s\tremaining: 1m 52s\n",
      "375:\tlearn: 0.5834722\ttotal: 1m 15s\tremaining: 1m 52s\n",
      "376:\tlearn: 0.5834215\ttotal: 1m 15s\tremaining: 1m 52s\n",
      "377:\tlearn: 0.5833826\ttotal: 1m 16s\tremaining: 1m 52s\n",
      "378:\tlearn: 0.5833470\ttotal: 1m 16s\tremaining: 1m 51s\n",
      "379:\tlearn: 0.5832962\ttotal: 1m 16s\tremaining: 1m 51s\n",
      "380:\tlearn: 0.5832484\ttotal: 1m 16s\tremaining: 1m 51s\n",
      "381:\tlearn: 0.5832097\ttotal: 1m 16s\tremaining: 1m 51s\n",
      "382:\tlearn: 0.5831653\ttotal: 1m 17s\tremaining: 1m 51s\n",
      "383:\tlearn: 0.5831213\ttotal: 1m 17s\tremaining: 1m 50s\n",
      "384:\tlearn: 0.5830755\ttotal: 1m 17s\tremaining: 1m 50s\n",
      "385:\tlearn: 0.5830395\ttotal: 1m 17s\tremaining: 1m 50s\n",
      "386:\tlearn: 0.5830048\ttotal: 1m 17s\tremaining: 1m 50s\n",
      "387:\tlearn: 0.5829526\ttotal: 1m 18s\tremaining: 1m 49s\n",
      "388:\tlearn: 0.5829117\ttotal: 1m 18s\tremaining: 1m 49s\n",
      "389:\tlearn: 0.5828696\ttotal: 1m 18s\tremaining: 1m 49s\n",
      "390:\tlearn: 0.5828295\ttotal: 1m 18s\tremaining: 1m 49s\n",
      "391:\tlearn: 0.5827897\ttotal: 1m 18s\tremaining: 1m 49s\n",
      "392:\tlearn: 0.5827375\ttotal: 1m 19s\tremaining: 1m 48s\n",
      "393:\tlearn: 0.5827032\ttotal: 1m 19s\tremaining: 1m 48s\n",
      "394:\tlearn: 0.5826655\ttotal: 1m 19s\tremaining: 1m 48s\n",
      "395:\tlearn: 0.5826232\ttotal: 1m 19s\tremaining: 1m 48s\n",
      "396:\tlearn: 0.5825738\ttotal: 1m 19s\tremaining: 1m 48s\n",
      "397:\tlearn: 0.5825343\ttotal: 1m 20s\tremaining: 1m 47s\n",
      "398:\tlearn: 0.5824987\ttotal: 1m 20s\tremaining: 1m 47s\n",
      "399:\tlearn: 0.5824570\ttotal: 1m 20s\tremaining: 1m 47s\n",
      "400:\tlearn: 0.5824119\ttotal: 1m 20s\tremaining: 1m 47s\n",
      "401:\tlearn: 0.5823646\ttotal: 1m 20s\tremaining: 1m 47s\n",
      "402:\tlearn: 0.5823253\ttotal: 1m 21s\tremaining: 1m 46s\n",
      "403:\tlearn: 0.5822917\ttotal: 1m 21s\tremaining: 1m 46s\n",
      "404:\tlearn: 0.5822514\ttotal: 1m 21s\tremaining: 1m 46s\n",
      "405:\tlearn: 0.5822153\ttotal: 1m 21s\tremaining: 1m 46s\n",
      "406:\tlearn: 0.5821585\ttotal: 1m 21s\tremaining: 1m 46s\n",
      "407:\tlearn: 0.5821205\ttotal: 1m 22s\tremaining: 1m 45s\n",
      "408:\tlearn: 0.5820735\ttotal: 1m 22s\tremaining: 1m 45s\n",
      "409:\tlearn: 0.5820424\ttotal: 1m 22s\tremaining: 1m 45s\n",
      "410:\tlearn: 0.5820065\ttotal: 1m 22s\tremaining: 1m 45s\n",
      "411:\tlearn: 0.5819690\ttotal: 1m 22s\tremaining: 1m 45s\n",
      "412:\tlearn: 0.5819353\ttotal: 1m 23s\tremaining: 1m 44s\n",
      "413:\tlearn: 0.5818924\ttotal: 1m 23s\tremaining: 1m 44s\n",
      "414:\tlearn: 0.5818518\ttotal: 1m 23s\tremaining: 1m 44s\n",
      "415:\tlearn: 0.5818135\ttotal: 1m 23s\tremaining: 1m 44s\n",
      "416:\tlearn: 0.5817785\ttotal: 1m 23s\tremaining: 1m 44s\n",
      "417:\tlearn: 0.5817419\ttotal: 1m 24s\tremaining: 1m 43s\n",
      "418:\tlearn: 0.5816970\ttotal: 1m 24s\tremaining: 1m 43s\n",
      "419:\tlearn: 0.5816554\ttotal: 1m 24s\tremaining: 1m 43s\n",
      "420:\tlearn: 0.5816135\ttotal: 1m 24s\tremaining: 1m 43s\n",
      "421:\tlearn: 0.5815699\ttotal: 1m 24s\tremaining: 1m 43s\n",
      "422:\tlearn: 0.5815395\ttotal: 1m 25s\tremaining: 1m 42s\n",
      "423:\tlearn: 0.5815095\ttotal: 1m 25s\tremaining: 1m 42s\n",
      "424:\tlearn: 0.5814744\ttotal: 1m 25s\tremaining: 1m 42s\n",
      "425:\tlearn: 0.5814384\ttotal: 1m 25s\tremaining: 1m 42s\n",
      "426:\tlearn: 0.5814056\ttotal: 1m 25s\tremaining: 1m 42s\n",
      "427:\tlearn: 0.5813729\ttotal: 1m 26s\tremaining: 1m 41s\n",
      "428:\tlearn: 0.5813271\ttotal: 1m 26s\tremaining: 1m 41s\n",
      "429:\tlearn: 0.5812899\ttotal: 1m 26s\tremaining: 1m 41s\n",
      "430:\tlearn: 0.5812475\ttotal: 1m 26s\tremaining: 1m 41s\n",
      "431:\tlearn: 0.5812102\ttotal: 1m 26s\tremaining: 1m 41s\n",
      "432:\tlearn: 0.5811823\ttotal: 1m 27s\tremaining: 1m 40s\n",
      "433:\tlearn: 0.5811341\ttotal: 1m 27s\tremaining: 1m 40s\n",
      "434:\tlearn: 0.5811001\ttotal: 1m 27s\tremaining: 1m 40s\n",
      "435:\tlearn: 0.5810595\ttotal: 1m 27s\tremaining: 1m 40s\n",
      "436:\tlearn: 0.5810064\ttotal: 1m 27s\tremaining: 1m 40s\n",
      "437:\tlearn: 0.5809689\ttotal: 1m 27s\tremaining: 1m 39s\n",
      "438:\tlearn: 0.5809305\ttotal: 1m 28s\tremaining: 1m 39s\n",
      "439:\tlearn: 0.5808926\ttotal: 1m 28s\tremaining: 1m 39s\n",
      "440:\tlearn: 0.5808467\ttotal: 1m 28s\tremaining: 1m 39s\n",
      "441:\tlearn: 0.5808105\ttotal: 1m 28s\tremaining: 1m 39s\n",
      "442:\tlearn: 0.5807779\ttotal: 1m 28s\tremaining: 1m 38s\n",
      "443:\tlearn: 0.5807314\ttotal: 1m 29s\tremaining: 1m 38s\n",
      "444:\tlearn: 0.5806976\ttotal: 1m 29s\tremaining: 1m 38s\n",
      "445:\tlearn: 0.5806679\ttotal: 1m 29s\tremaining: 1m 38s\n",
      "446:\tlearn: 0.5806296\ttotal: 1m 29s\tremaining: 1m 37s\n",
      "447:\tlearn: 0.5805908\ttotal: 1m 29s\tremaining: 1m 37s\n",
      "448:\tlearn: 0.5805556\ttotal: 1m 30s\tremaining: 1m 37s\n",
      "449:\tlearn: 0.5805141\ttotal: 1m 30s\tremaining: 1m 37s\n",
      "450:\tlearn: 0.5804766\ttotal: 1m 30s\tremaining: 1m 37s\n",
      "451:\tlearn: 0.5804399\ttotal: 1m 30s\tremaining: 1m 36s\n",
      "452:\tlearn: 0.5804023\ttotal: 1m 30s\tremaining: 1m 36s\n",
      "453:\tlearn: 0.5803546\ttotal: 1m 31s\tremaining: 1m 36s\n",
      "454:\tlearn: 0.5803190\ttotal: 1m 31s\tremaining: 1m 36s\n",
      "455:\tlearn: 0.5802826\ttotal: 1m 31s\tremaining: 1m 36s\n",
      "456:\tlearn: 0.5802409\ttotal: 1m 31s\tremaining: 1m 35s\n",
      "457:\tlearn: 0.5801962\ttotal: 1m 31s\tremaining: 1m 35s\n",
      "458:\tlearn: 0.5801656\ttotal: 1m 32s\tremaining: 1m 35s\n",
      "459:\tlearn: 0.5801317\ttotal: 1m 32s\tremaining: 1m 35s\n",
      "460:\tlearn: 0.5800924\ttotal: 1m 32s\tremaining: 1m 35s\n",
      "461:\tlearn: 0.5800462\ttotal: 1m 32s\tremaining: 1m 34s\n",
      "462:\tlearn: 0.5799969\ttotal: 1m 33s\tremaining: 1m 34s\n",
      "463:\tlearn: 0.5799638\ttotal: 1m 33s\tremaining: 1m 34s\n",
      "464:\tlearn: 0.5799328\ttotal: 1m 33s\tremaining: 1m 34s\n",
      "465:\tlearn: 0.5798909\ttotal: 1m 33s\tremaining: 1m 34s\n",
      "466:\tlearn: 0.5798592\ttotal: 1m 33s\tremaining: 1m 34s\n",
      "467:\tlearn: 0.5798244\ttotal: 1m 34s\tremaining: 1m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468:\tlearn: 0.5797879\ttotal: 1m 34s\tremaining: 1m 33s\n",
      "469:\tlearn: 0.5797592\ttotal: 1m 34s\tremaining: 1m 33s\n",
      "470:\tlearn: 0.5797257\ttotal: 1m 34s\tremaining: 1m 33s\n",
      "471:\tlearn: 0.5796846\ttotal: 1m 34s\tremaining: 1m 33s\n",
      "472:\tlearn: 0.5796475\ttotal: 1m 35s\tremaining: 1m 32s\n",
      "473:\tlearn: 0.5796111\ttotal: 1m 35s\tremaining: 1m 32s\n",
      "474:\tlearn: 0.5795766\ttotal: 1m 35s\tremaining: 1m 32s\n",
      "475:\tlearn: 0.5795434\ttotal: 1m 35s\tremaining: 1m 32s\n",
      "476:\tlearn: 0.5795140\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "477:\tlearn: 0.5794838\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "478:\tlearn: 0.5794491\ttotal: 1m 36s\tremaining: 1m 31s\n",
      "479:\tlearn: 0.5794212\ttotal: 1m 36s\tremaining: 1m 31s\n",
      "480:\tlearn: 0.5793801\ttotal: 1m 36s\tremaining: 1m 31s\n",
      "481:\tlearn: 0.5793365\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "482:\tlearn: 0.5792976\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "483:\tlearn: 0.5792720\ttotal: 1m 37s\tremaining: 1m 30s\n",
      "484:\tlearn: 0.5792390\ttotal: 1m 37s\tremaining: 1m 30s\n",
      "485:\tlearn: 0.5792042\ttotal: 1m 37s\tremaining: 1m 30s\n",
      "486:\tlearn: 0.5791728\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "487:\tlearn: 0.5791400\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "488:\tlearn: 0.5791040\ttotal: 1m 38s\tremaining: 1m 29s\n",
      "489:\tlearn: 0.5790681\ttotal: 1m 38s\tremaining: 1m 29s\n",
      "490:\tlearn: 0.5790304\ttotal: 1m 38s\tremaining: 1m 29s\n",
      "491:\tlearn: 0.5789896\ttotal: 1m 38s\tremaining: 1m 28s\n",
      "492:\tlearn: 0.5789562\ttotal: 1m 38s\tremaining: 1m 28s\n",
      "493:\tlearn: 0.5789254\ttotal: 1m 39s\tremaining: 1m 28s\n",
      "494:\tlearn: 0.5788964\ttotal: 1m 39s\tremaining: 1m 28s\n",
      "495:\tlearn: 0.5788617\ttotal: 1m 39s\tremaining: 1m 28s\n",
      "496:\tlearn: 0.5788227\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "497:\tlearn: 0.5787848\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "498:\tlearn: 0.5787486\ttotal: 1m 40s\tremaining: 1m 27s\n",
      "499:\tlearn: 0.5787174\ttotal: 1m 40s\tremaining: 1m 27s\n",
      "500:\tlearn: 0.5786824\ttotal: 1m 40s\tremaining: 1m 27s\n",
      "501:\tlearn: 0.5786509\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "502:\tlearn: 0.5786136\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "503:\tlearn: 0.5785757\ttotal: 1m 41s\tremaining: 1m 26s\n",
      "504:\tlearn: 0.5785438\ttotal: 1m 41s\tremaining: 1m 26s\n",
      "505:\tlearn: 0.5785165\ttotal: 1m 41s\tremaining: 1m 26s\n",
      "506:\tlearn: 0.5784819\ttotal: 1m 41s\tremaining: 1m 25s\n",
      "507:\tlearn: 0.5784472\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "508:\tlearn: 0.5784056\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "509:\tlearn: 0.5783757\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "510:\tlearn: 0.5783355\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "511:\tlearn: 0.5783028\ttotal: 1m 42s\tremaining: 1m 24s\n",
      "512:\tlearn: 0.5782707\ttotal: 1m 42s\tremaining: 1m 24s\n",
      "513:\tlearn: 0.5782318\ttotal: 1m 43s\tremaining: 1m 24s\n",
      "514:\tlearn: 0.5781983\ttotal: 1m 43s\tremaining: 1m 24s\n",
      "515:\tlearn: 0.5781694\ttotal: 1m 43s\tremaining: 1m 24s\n",
      "516:\tlearn: 0.5781301\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "517:\tlearn: 0.5780948\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "518:\tlearn: 0.5780612\ttotal: 1m 44s\tremaining: 1m 23s\n",
      "519:\tlearn: 0.5780160\ttotal: 1m 44s\tremaining: 1m 23s\n",
      "520:\tlearn: 0.5779792\ttotal: 1m 44s\tremaining: 1m 23s\n",
      "521:\tlearn: 0.5779489\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "522:\tlearn: 0.5779140\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "523:\tlearn: 0.5778855\ttotal: 1m 45s\tremaining: 1m 22s\n",
      "524:\tlearn: 0.5778541\ttotal: 1m 45s\tremaining: 1m 22s\n",
      "525:\tlearn: 0.5778221\ttotal: 1m 45s\tremaining: 1m 22s\n",
      "526:\tlearn: 0.5777845\ttotal: 1m 45s\tremaining: 1m 21s\n",
      "527:\tlearn: 0.5777558\ttotal: 1m 46s\tremaining: 1m 21s\n",
      "528:\tlearn: 0.5777183\ttotal: 1m 46s\tremaining: 1m 21s\n",
      "529:\tlearn: 0.5776881\ttotal: 1m 46s\tremaining: 1m 21s\n",
      "530:\tlearn: 0.5776550\ttotal: 1m 46s\tremaining: 1m 21s\n",
      "531:\tlearn: 0.5776189\ttotal: 1m 46s\tremaining: 1m 20s\n",
      "532:\tlearn: 0.5775846\ttotal: 1m 47s\tremaining: 1m 20s\n",
      "533:\tlearn: 0.5775582\ttotal: 1m 47s\tremaining: 1m 20s\n",
      "534:\tlearn: 0.5775190\ttotal: 1m 47s\tremaining: 1m 20s\n",
      "535:\tlearn: 0.5774660\ttotal: 1m 47s\tremaining: 1m 20s\n",
      "536:\tlearn: 0.5774376\ttotal: 1m 47s\tremaining: 1m 19s\n",
      "537:\tlearn: 0.5774090\ttotal: 1m 47s\tremaining: 1m 19s\n",
      "538:\tlearn: 0.5773764\ttotal: 1m 48s\tremaining: 1m 19s\n",
      "539:\tlearn: 0.5773329\ttotal: 1m 48s\tremaining: 1m 19s\n",
      "540:\tlearn: 0.5772991\ttotal: 1m 48s\tremaining: 1m 19s\n",
      "541:\tlearn: 0.5772724\ttotal: 1m 48s\tremaining: 1m 18s\n",
      "542:\tlearn: 0.5772402\ttotal: 1m 48s\tremaining: 1m 18s\n",
      "543:\tlearn: 0.5772104\ttotal: 1m 49s\tremaining: 1m 18s\n",
      "544:\tlearn: 0.5771813\ttotal: 1m 49s\tremaining: 1m 18s\n",
      "545:\tlearn: 0.5771503\ttotal: 1m 49s\tremaining: 1m 18s\n",
      "546:\tlearn: 0.5771033\ttotal: 1m 49s\tremaining: 1m 17s\n",
      "547:\tlearn: 0.5770634\ttotal: 1m 49s\tremaining: 1m 17s\n",
      "548:\tlearn: 0.5770329\ttotal: 1m 50s\tremaining: 1m 17s\n",
      "549:\tlearn: 0.5770104\ttotal: 1m 50s\tremaining: 1m 17s\n",
      "550:\tlearn: 0.5769747\ttotal: 1m 50s\tremaining: 1m 17s\n",
      "551:\tlearn: 0.5769393\ttotal: 1m 50s\tremaining: 1m 16s\n",
      "552:\tlearn: 0.5769055\ttotal: 1m 50s\tremaining: 1m 16s\n",
      "553:\tlearn: 0.5768801\ttotal: 1m 51s\tremaining: 1m 16s\n",
      "554:\tlearn: 0.5768468\ttotal: 1m 51s\tremaining: 1m 16s\n",
      "555:\tlearn: 0.5768158\ttotal: 1m 51s\tremaining: 1m 16s\n",
      "556:\tlearn: 0.5767769\ttotal: 1m 51s\tremaining: 1m 15s\n",
      "557:\tlearn: 0.5767404\ttotal: 1m 51s\tremaining: 1m 15s\n",
      "558:\tlearn: 0.5767041\ttotal: 1m 52s\tremaining: 1m 15s\n",
      "559:\tlearn: 0.5766606\ttotal: 1m 52s\tremaining: 1m 15s\n",
      "560:\tlearn: 0.5766315\ttotal: 1m 52s\tremaining: 1m 15s\n",
      "561:\tlearn: 0.5766000\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "562:\tlearn: 0.5765645\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "563:\tlearn: 0.5765261\ttotal: 1m 53s\tremaining: 1m 14s\n",
      "564:\tlearn: 0.5764884\ttotal: 1m 53s\tremaining: 1m 14s\n",
      "565:\tlearn: 0.5764583\ttotal: 1m 53s\tremaining: 1m 14s\n",
      "566:\tlearn: 0.5764232\ttotal: 1m 53s\tremaining: 1m 13s\n",
      "567:\tlearn: 0.5763923\ttotal: 1m 53s\tremaining: 1m 13s\n",
      "568:\tlearn: 0.5763628\ttotal: 1m 54s\tremaining: 1m 13s\n",
      "569:\tlearn: 0.5763280\ttotal: 1m 54s\tremaining: 1m 13s\n",
      "570:\tlearn: 0.5762895\ttotal: 1m 54s\tremaining: 1m 13s\n",
      "571:\tlearn: 0.5762524\ttotal: 1m 54s\tremaining: 1m 12s\n",
      "572:\tlearn: 0.5762170\ttotal: 1m 54s\tremaining: 1m 12s\n",
      "573:\tlearn: 0.5761833\ttotal: 1m 55s\tremaining: 1m 12s\n",
      "574:\tlearn: 0.5761440\ttotal: 1m 55s\tremaining: 1m 12s\n",
      "575:\tlearn: 0.5761175\ttotal: 1m 55s\tremaining: 1m 12s\n",
      "576:\tlearn: 0.5760909\ttotal: 1m 55s\tremaining: 1m 11s\n",
      "577:\tlearn: 0.5760516\ttotal: 1m 55s\tremaining: 1m 11s\n",
      "578:\tlearn: 0.5760129\ttotal: 1m 56s\tremaining: 1m 11s\n",
      "579:\tlearn: 0.5759828\ttotal: 1m 56s\tremaining: 1m 11s\n",
      "580:\tlearn: 0.5759468\ttotal: 1m 56s\tremaining: 1m 11s\n",
      "581:\tlearn: 0.5759128\ttotal: 1m 56s\tremaining: 1m 10s\n",
      "582:\tlearn: 0.5758807\ttotal: 1m 56s\tremaining: 1m 10s\n",
      "583:\tlearn: 0.5758484\ttotal: 1m 57s\tremaining: 1m 10s\n",
      "584:\tlearn: 0.5758170\ttotal: 1m 57s\tremaining: 1m 10s\n",
      "585:\tlearn: 0.5757854\ttotal: 1m 57s\tremaining: 1m 10s\n",
      "586:\tlearn: 0.5757572\ttotal: 1m 57s\tremaining: 1m 9s\n",
      "587:\tlearn: 0.5757254\ttotal: 1m 57s\tremaining: 1m 9s\n",
      "588:\tlearn: 0.5756959\ttotal: 1m 58s\tremaining: 1m 9s\n",
      "589:\tlearn: 0.5756622\ttotal: 1m 58s\tremaining: 1m 9s\n",
      "590:\tlearn: 0.5756401\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "591:\tlearn: 0.5756078\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "592:\tlearn: 0.5755775\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "593:\tlearn: 0.5755435\ttotal: 1m 59s\tremaining: 1m 8s\n",
      "594:\tlearn: 0.5755095\ttotal: 1m 59s\tremaining: 1m 8s\n",
      "595:\tlearn: 0.5754794\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "596:\tlearn: 0.5754463\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "597:\tlearn: 0.5754112\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "598:\tlearn: 0.5753797\ttotal: 2m\tremaining: 1m 7s\n",
      "599:\tlearn: 0.5753457\ttotal: 2m\tremaining: 1m 7s\n",
      "600:\tlearn: 0.5753188\ttotal: 2m\tremaining: 1m 6s\n",
      "601:\tlearn: 0.5752830\ttotal: 2m\tremaining: 1m 6s\n",
      "602:\tlearn: 0.5752557\ttotal: 2m\tremaining: 1m 6s\n",
      "603:\tlearn: 0.5752287\ttotal: 2m 1s\tremaining: 1m 6s\n",
      "604:\tlearn: 0.5751991\ttotal: 2m 1s\tremaining: 1m 6s\n",
      "605:\tlearn: 0.5751573\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "606:\tlearn: 0.5751266\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "607:\tlearn: 0.5750920\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "608:\tlearn: 0.5750672\ttotal: 2m 2s\tremaining: 1m 5s\n",
      "609:\tlearn: 0.5750305\ttotal: 2m 2s\tremaining: 1m 5s\n",
      "610:\tlearn: 0.5749967\ttotal: 2m 2s\tremaining: 1m 4s\n",
      "611:\tlearn: 0.5749613\ttotal: 2m 2s\tremaining: 1m 4s\n",
      "612:\tlearn: 0.5749304\ttotal: 2m 2s\tremaining: 1m 4s\n",
      "613:\tlearn: 0.5748977\ttotal: 2m 3s\tremaining: 1m 4s\n",
      "614:\tlearn: 0.5748656\ttotal: 2m 3s\tremaining: 1m 4s\n",
      "615:\tlearn: 0.5748369\ttotal: 2m 3s\tremaining: 1m 3s\n",
      "616:\tlearn: 0.5747967\ttotal: 2m 3s\tremaining: 1m 3s\n",
      "617:\tlearn: 0.5747606\ttotal: 2m 3s\tremaining: 1m 3s\n",
      "618:\tlearn: 0.5747332\ttotal: 2m 4s\tremaining: 1m 3s\n",
      "619:\tlearn: 0.5746941\ttotal: 2m 4s\tremaining: 1m 3s\n",
      "620:\tlearn: 0.5746597\ttotal: 2m 4s\tremaining: 1m 2s\n",
      "621:\tlearn: 0.5746281\ttotal: 2m 4s\tremaining: 1m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622:\tlearn: 0.5745896\ttotal: 2m 4s\tremaining: 1m 2s\n",
      "623:\tlearn: 0.5745531\ttotal: 2m 5s\tremaining: 1m 2s\n",
      "624:\tlearn: 0.5745241\ttotal: 2m 5s\tremaining: 1m 2s\n",
      "625:\tlearn: 0.5744930\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "626:\tlearn: 0.5744682\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "627:\tlearn: 0.5744339\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "628:\tlearn: 0.5744028\ttotal: 2m 6s\tremaining: 1m 1s\n",
      "629:\tlearn: 0.5743703\ttotal: 2m 6s\tremaining: 1m 1s\n",
      "630:\tlearn: 0.5743408\ttotal: 2m 6s\tremaining: 1m\n",
      "631:\tlearn: 0.5743000\ttotal: 2m 6s\tremaining: 1m\n",
      "632:\tlearn: 0.5742706\ttotal: 2m 6s\tremaining: 1m\n",
      "633:\tlearn: 0.5742448\ttotal: 2m 6s\tremaining: 1m\n",
      "634:\tlearn: 0.5742116\ttotal: 2m 7s\tremaining: 1m\n",
      "635:\tlearn: 0.5741851\ttotal: 2m 7s\tremaining: 59.9s\n",
      "636:\tlearn: 0.5741548\ttotal: 2m 7s\tremaining: 59.7s\n",
      "637:\tlearn: 0.5741224\ttotal: 2m 7s\tremaining: 59.5s\n",
      "638:\tlearn: 0.5740830\ttotal: 2m 7s\tremaining: 59.3s\n",
      "639:\tlearn: 0.5740501\ttotal: 2m 8s\tremaining: 59.1s\n",
      "640:\tlearn: 0.5740180\ttotal: 2m 8s\tremaining: 58.9s\n",
      "641:\tlearn: 0.5739816\ttotal: 2m 8s\tremaining: 58.7s\n",
      "642:\tlearn: 0.5739495\ttotal: 2m 8s\tremaining: 58.5s\n",
      "643:\tlearn: 0.5739169\ttotal: 2m 8s\tremaining: 58.3s\n",
      "644:\tlearn: 0.5738908\ttotal: 2m 9s\tremaining: 58.1s\n",
      "645:\tlearn: 0.5738643\ttotal: 2m 9s\tremaining: 57.9s\n",
      "646:\tlearn: 0.5738364\ttotal: 2m 9s\tremaining: 57.7s\n",
      "647:\tlearn: 0.5738046\ttotal: 2m 9s\tremaining: 57.5s\n",
      "648:\tlearn: 0.5737829\ttotal: 2m 9s\tremaining: 57.2s\n",
      "649:\tlearn: 0.5737516\ttotal: 2m 10s\tremaining: 57s\n",
      "650:\tlearn: 0.5737204\ttotal: 2m 10s\tremaining: 56.9s\n",
      "651:\tlearn: 0.5736847\ttotal: 2m 10s\tremaining: 56.6s\n",
      "652:\tlearn: 0.5736529\ttotal: 2m 10s\tremaining: 56.4s\n",
      "653:\tlearn: 0.5736295\ttotal: 2m 10s\tremaining: 56.2s\n",
      "654:\tlearn: 0.5735981\ttotal: 2m 11s\tremaining: 56s\n",
      "655:\tlearn: 0.5735681\ttotal: 2m 11s\tremaining: 55.8s\n",
      "656:\tlearn: 0.5735336\ttotal: 2m 11s\tremaining: 55.6s\n",
      "657:\tlearn: 0.5735025\ttotal: 2m 11s\tremaining: 55.4s\n",
      "658:\tlearn: 0.5734684\ttotal: 2m 11s\tremaining: 55.2s\n",
      "659:\tlearn: 0.5734324\ttotal: 2m 12s\tremaining: 55s\n",
      "660:\tlearn: 0.5733992\ttotal: 2m 12s\tremaining: 54.8s\n",
      "661:\tlearn: 0.5733715\ttotal: 2m 12s\tremaining: 54.7s\n",
      "662:\tlearn: 0.5733379\ttotal: 2m 12s\tremaining: 54.5s\n",
      "663:\tlearn: 0.5733012\ttotal: 2m 12s\tremaining: 54.3s\n",
      "664:\tlearn: 0.5732817\ttotal: 2m 13s\tremaining: 54s\n",
      "665:\tlearn: 0.5732483\ttotal: 2m 13s\tremaining: 53.8s\n",
      "666:\tlearn: 0.5732119\ttotal: 2m 13s\tremaining: 53.6s\n",
      "667:\tlearn: 0.5731845\ttotal: 2m 13s\tremaining: 53.4s\n",
      "668:\tlearn: 0.5731541\ttotal: 2m 13s\tremaining: 53.2s\n",
      "669:\tlearn: 0.5731228\ttotal: 2m 14s\tremaining: 53s\n",
      "670:\tlearn: 0.5730926\ttotal: 2m 14s\tremaining: 52.9s\n",
      "671:\tlearn: 0.5730617\ttotal: 2m 14s\tremaining: 52.7s\n",
      "672:\tlearn: 0.5730347\ttotal: 2m 14s\tremaining: 52.4s\n",
      "673:\tlearn: 0.5730034\ttotal: 2m 14s\tremaining: 52.2s\n",
      "674:\tlearn: 0.5729769\ttotal: 2m 15s\tremaining: 52s\n",
      "675:\tlearn: 0.5729473\ttotal: 2m 15s\tremaining: 51.8s\n",
      "676:\tlearn: 0.5729117\ttotal: 2m 15s\tremaining: 51.6s\n",
      "677:\tlearn: 0.5728733\ttotal: 2m 15s\tremaining: 51.4s\n",
      "678:\tlearn: 0.5728432\ttotal: 2m 15s\tremaining: 51.2s\n",
      "679:\tlearn: 0.5728175\ttotal: 2m 16s\tremaining: 51s\n",
      "680:\tlearn: 0.5727889\ttotal: 2m 16s\tremaining: 50.8s\n",
      "681:\tlearn: 0.5727609\ttotal: 2m 16s\tremaining: 50.6s\n",
      "682:\tlearn: 0.5727322\ttotal: 2m 16s\tremaining: 50.4s\n",
      "683:\tlearn: 0.5727019\ttotal: 2m 16s\tremaining: 50.2s\n",
      "684:\tlearn: 0.5726790\ttotal: 2m 17s\tremaining: 50s\n",
      "685:\tlearn: 0.5726481\ttotal: 2m 17s\tremaining: 49.8s\n",
      "686:\tlearn: 0.5726225\ttotal: 2m 17s\tremaining: 49.6s\n",
      "687:\tlearn: 0.5725814\ttotal: 2m 17s\tremaining: 49.4s\n",
      "688:\tlearn: 0.5725533\ttotal: 2m 17s\tremaining: 49.2s\n",
      "689:\tlearn: 0.5725180\ttotal: 2m 18s\tremaining: 49s\n",
      "690:\tlearn: 0.5724949\ttotal: 2m 18s\tremaining: 48.8s\n",
      "691:\tlearn: 0.5724610\ttotal: 2m 18s\tremaining: 48.6s\n",
      "692:\tlearn: 0.5724260\ttotal: 2m 18s\tremaining: 48.4s\n",
      "693:\tlearn: 0.5723985\ttotal: 2m 18s\tremaining: 48.2s\n",
      "694:\tlearn: 0.5723682\ttotal: 2m 19s\tremaining: 48s\n",
      "695:\tlearn: 0.5723417\ttotal: 2m 19s\tremaining: 47.8s\n",
      "696:\tlearn: 0.5723179\ttotal: 2m 19s\tremaining: 47.6s\n",
      "697:\tlearn: 0.5722822\ttotal: 2m 19s\tremaining: 47.4s\n",
      "698:\tlearn: 0.5722522\ttotal: 2m 19s\tremaining: 47.2s\n",
      "699:\tlearn: 0.5722247\ttotal: 2m 20s\tremaining: 47s\n",
      "700:\tlearn: 0.5721949\ttotal: 2m 20s\tremaining: 46.8s\n",
      "701:\tlearn: 0.5721665\ttotal: 2m 20s\tremaining: 46.6s\n",
      "702:\tlearn: 0.5721369\ttotal: 2m 20s\tremaining: 46.4s\n",
      "703:\tlearn: 0.5721096\ttotal: 2m 20s\tremaining: 46.2s\n",
      "704:\tlearn: 0.5720860\ttotal: 2m 20s\tremaining: 46s\n",
      "705:\tlearn: 0.5720550\ttotal: 2m 21s\tremaining: 45.8s\n",
      "706:\tlearn: 0.5720177\ttotal: 2m 21s\tremaining: 45.6s\n",
      "707:\tlearn: 0.5719857\ttotal: 2m 21s\tremaining: 45.4s\n",
      "708:\tlearn: 0.5719541\ttotal: 2m 21s\tremaining: 45.2s\n",
      "709:\tlearn: 0.5719323\ttotal: 2m 21s\tremaining: 45s\n",
      "710:\tlearn: 0.5719011\ttotal: 2m 22s\tremaining: 44.8s\n",
      "711:\tlearn: 0.5718691\ttotal: 2m 22s\tremaining: 44.6s\n",
      "712:\tlearn: 0.5718369\ttotal: 2m 22s\tremaining: 44.4s\n",
      "713:\tlearn: 0.5718064\ttotal: 2m 22s\tremaining: 44.2s\n",
      "714:\tlearn: 0.5717748\ttotal: 2m 23s\tremaining: 44s\n",
      "715:\tlearn: 0.5717518\ttotal: 2m 23s\tremaining: 43.8s\n",
      "716:\tlearn: 0.5717189\ttotal: 2m 23s\tremaining: 43.6s\n",
      "717:\tlearn: 0.5716908\ttotal: 2m 23s\tremaining: 43.4s\n",
      "718:\tlearn: 0.5716625\ttotal: 2m 23s\tremaining: 43.2s\n",
      "719:\tlearn: 0.5716372\ttotal: 2m 23s\tremaining: 43s\n",
      "720:\tlearn: 0.5716037\ttotal: 2m 24s\tremaining: 42.8s\n",
      "721:\tlearn: 0.5715802\ttotal: 2m 24s\tremaining: 42.6s\n",
      "722:\tlearn: 0.5715526\ttotal: 2m 24s\tremaining: 42.4s\n",
      "723:\tlearn: 0.5715221\ttotal: 2m 24s\tremaining: 42.2s\n",
      "724:\tlearn: 0.5714947\ttotal: 2m 24s\tremaining: 42s\n",
      "725:\tlearn: 0.5714542\ttotal: 2m 25s\tremaining: 41.8s\n",
      "726:\tlearn: 0.5714131\ttotal: 2m 25s\tremaining: 41.6s\n",
      "727:\tlearn: 0.5713845\ttotal: 2m 25s\tremaining: 41.4s\n",
      "728:\tlearn: 0.5713527\ttotal: 2m 25s\tremaining: 41.2s\n",
      "729:\tlearn: 0.5713287\ttotal: 2m 25s\tremaining: 41s\n",
      "730:\tlearn: 0.5712936\ttotal: 2m 26s\tremaining: 40.8s\n",
      "731:\tlearn: 0.5712636\ttotal: 2m 26s\tremaining: 40.6s\n",
      "732:\tlearn: 0.5712329\ttotal: 2m 26s\tremaining: 40.4s\n",
      "733:\tlearn: 0.5711945\ttotal: 2m 26s\tremaining: 40.2s\n",
      "734:\tlearn: 0.5711626\ttotal: 2m 26s\tremaining: 40s\n",
      "735:\tlearn: 0.5711253\ttotal: 2m 27s\tremaining: 39.8s\n",
      "736:\tlearn: 0.5710957\ttotal: 2m 27s\tremaining: 39.6s\n",
      "737:\tlearn: 0.5710629\ttotal: 2m 27s\tremaining: 39.4s\n",
      "738:\tlearn: 0.5710321\ttotal: 2m 27s\tremaining: 39.2s\n",
      "739:\tlearn: 0.5710102\ttotal: 2m 27s\tremaining: 39s\n",
      "740:\tlearn: 0.5709800\ttotal: 2m 28s\tremaining: 38.8s\n",
      "741:\tlearn: 0.5709484\ttotal: 2m 28s\tremaining: 38.6s\n",
      "742:\tlearn: 0.5709156\ttotal: 2m 28s\tremaining: 38.4s\n",
      "743:\tlearn: 0.5708752\ttotal: 2m 28s\tremaining: 38.2s\n",
      "744:\tlearn: 0.5708527\ttotal: 2m 28s\tremaining: 38s\n",
      "745:\tlearn: 0.5708206\ttotal: 2m 29s\tremaining: 37.8s\n",
      "746:\tlearn: 0.5707875\ttotal: 2m 29s\tremaining: 37.6s\n",
      "747:\tlearn: 0.5707536\ttotal: 2m 29s\tremaining: 37.4s\n",
      "748:\tlearn: 0.5707180\ttotal: 2m 29s\tremaining: 37.2s\n",
      "749:\tlearn: 0.5706865\ttotal: 2m 29s\tremaining: 37s\n",
      "750:\tlearn: 0.5706505\ttotal: 2m 30s\tremaining: 36.8s\n",
      "751:\tlearn: 0.5706277\ttotal: 2m 30s\tremaining: 36.6s\n",
      "752:\tlearn: 0.5705999\ttotal: 2m 30s\tremaining: 36.4s\n",
      "753:\tlearn: 0.5705754\ttotal: 2m 30s\tremaining: 36.2s\n",
      "754:\tlearn: 0.5705488\ttotal: 2m 30s\tremaining: 36s\n",
      "755:\tlearn: 0.5705206\ttotal: 2m 31s\tremaining: 35.8s\n",
      "756:\tlearn: 0.5704958\ttotal: 2m 31s\tremaining: 35.6s\n",
      "757:\tlearn: 0.5704647\ttotal: 2m 31s\tremaining: 35.4s\n",
      "758:\tlearn: 0.5704425\ttotal: 2m 31s\tremaining: 35.2s\n",
      "759:\tlearn: 0.5704182\ttotal: 2m 31s\tremaining: 35s\n",
      "760:\tlearn: 0.5703911\ttotal: 2m 31s\tremaining: 34.8s\n",
      "761:\tlearn: 0.5703635\ttotal: 2m 32s\tremaining: 34.6s\n",
      "762:\tlearn: 0.5703335\ttotal: 2m 32s\tremaining: 34.4s\n",
      "763:\tlearn: 0.5702959\ttotal: 2m 32s\tremaining: 34.2s\n",
      "764:\tlearn: 0.5702651\ttotal: 2m 32s\tremaining: 34s\n",
      "765:\tlearn: 0.5702380\ttotal: 2m 33s\tremaining: 33.8s\n",
      "766:\tlearn: 0.5702097\ttotal: 2m 33s\tremaining: 33.6s\n",
      "767:\tlearn: 0.5701794\ttotal: 2m 33s\tremaining: 33.4s\n",
      "768:\tlearn: 0.5701499\ttotal: 2m 33s\tremaining: 33.2s\n",
      "769:\tlearn: 0.5701216\ttotal: 2m 33s\tremaining: 33s\n",
      "770:\tlearn: 0.5700923\ttotal: 2m 33s\tremaining: 32.8s\n",
      "771:\tlearn: 0.5700688\ttotal: 2m 34s\tremaining: 32.6s\n",
      "772:\tlearn: 0.5700386\ttotal: 2m 34s\tremaining: 32.4s\n",
      "773:\tlearn: 0.5700143\ttotal: 2m 34s\tremaining: 32.2s\n",
      "774:\tlearn: 0.5699848\ttotal: 2m 34s\tremaining: 32s\n",
      "775:\tlearn: 0.5699550\ttotal: 2m 34s\tremaining: 31.8s\n",
      "776:\tlearn: 0.5699271\ttotal: 2m 35s\tremaining: 31.6s\n",
      "777:\tlearn: 0.5699006\ttotal: 2m 35s\tremaining: 31.4s\n",
      "778:\tlearn: 0.5698752\ttotal: 2m 35s\tremaining: 31.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779:\tlearn: 0.5698446\ttotal: 2m 35s\tremaining: 31s\n",
      "780:\tlearn: 0.5698135\ttotal: 2m 35s\tremaining: 30.8s\n",
      "781:\tlearn: 0.5697873\ttotal: 2m 36s\tremaining: 30.6s\n",
      "782:\tlearn: 0.5697562\ttotal: 2m 36s\tremaining: 30.4s\n",
      "783:\tlearn: 0.5697288\ttotal: 2m 36s\tremaining: 30.2s\n",
      "784:\tlearn: 0.5696923\ttotal: 2m 36s\tremaining: 30s\n",
      "785:\tlearn: 0.5696687\ttotal: 2m 36s\tremaining: 29.8s\n",
      "786:\tlearn: 0.5696408\ttotal: 2m 37s\tremaining: 29.6s\n",
      "787:\tlearn: 0.5696175\ttotal: 2m 37s\tremaining: 29.3s\n",
      "788:\tlearn: 0.5695873\ttotal: 2m 37s\tremaining: 29.2s\n",
      "789:\tlearn: 0.5695591\ttotal: 2m 37s\tremaining: 29s\n",
      "790:\tlearn: 0.5695312\ttotal: 2m 37s\tremaining: 28.8s\n",
      "791:\tlearn: 0.5695039\ttotal: 2m 38s\tremaining: 28.6s\n",
      "792:\tlearn: 0.5694754\ttotal: 2m 38s\tremaining: 28.4s\n",
      "793:\tlearn: 0.5694424\ttotal: 2m 38s\tremaining: 28.2s\n",
      "794:\tlearn: 0.5694170\ttotal: 2m 38s\tremaining: 28s\n",
      "795:\tlearn: 0.5693850\ttotal: 2m 38s\tremaining: 27.8s\n",
      "796:\tlearn: 0.5693533\ttotal: 2m 39s\tremaining: 27.6s\n",
      "797:\tlearn: 0.5693169\ttotal: 2m 39s\tremaining: 27.4s\n",
      "798:\tlearn: 0.5692845\ttotal: 2m 39s\tremaining: 27.2s\n",
      "799:\tlearn: 0.5692564\ttotal: 2m 39s\tremaining: 27s\n",
      "800:\tlearn: 0.5692283\ttotal: 2m 39s\tremaining: 26.8s\n",
      "801:\tlearn: 0.5692017\ttotal: 2m 40s\tremaining: 26.6s\n",
      "802:\tlearn: 0.5691766\ttotal: 2m 40s\tremaining: 26.4s\n",
      "803:\tlearn: 0.5691468\ttotal: 2m 40s\tremaining: 26.2s\n",
      "804:\tlearn: 0.5691197\ttotal: 2m 40s\tremaining: 26s\n",
      "805:\tlearn: 0.5690878\ttotal: 2m 40s\tremaining: 25.8s\n",
      "806:\tlearn: 0.5690608\ttotal: 2m 41s\tremaining: 25.6s\n",
      "807:\tlearn: 0.5690388\ttotal: 2m 41s\tremaining: 25.4s\n",
      "808:\tlearn: 0.5690154\ttotal: 2m 41s\tremaining: 25.1s\n",
      "809:\tlearn: 0.5689821\ttotal: 2m 41s\tremaining: 25s\n",
      "810:\tlearn: 0.5689528\ttotal: 2m 41s\tremaining: 24.7s\n",
      "811:\tlearn: 0.5689207\ttotal: 2m 42s\tremaining: 24.5s\n",
      "812:\tlearn: 0.5688960\ttotal: 2m 42s\tremaining: 24.3s\n",
      "813:\tlearn: 0.5688670\ttotal: 2m 42s\tremaining: 24.1s\n",
      "814:\tlearn: 0.5688354\ttotal: 2m 42s\tremaining: 23.9s\n",
      "815:\tlearn: 0.5688122\ttotal: 2m 42s\tremaining: 23.7s\n",
      "816:\tlearn: 0.5687856\ttotal: 2m 43s\tremaining: 23.5s\n",
      "817:\tlearn: 0.5687601\ttotal: 2m 43s\tremaining: 23.3s\n",
      "818:\tlearn: 0.5687246\ttotal: 2m 43s\tremaining: 23.1s\n",
      "819:\tlearn: 0.5686904\ttotal: 2m 43s\tremaining: 22.9s\n",
      "820:\tlearn: 0.5686639\ttotal: 2m 43s\tremaining: 22.7s\n",
      "821:\tlearn: 0.5686414\ttotal: 2m 44s\tremaining: 22.5s\n",
      "822:\tlearn: 0.5686170\ttotal: 2m 44s\tremaining: 22.3s\n",
      "823:\tlearn: 0.5685905\ttotal: 2m 44s\tremaining: 22.1s\n",
      "824:\tlearn: 0.5685629\ttotal: 2m 44s\tremaining: 21.9s\n",
      "825:\tlearn: 0.5685360\ttotal: 2m 44s\tremaining: 21.7s\n",
      "826:\tlearn: 0.5685013\ttotal: 2m 45s\tremaining: 21.5s\n",
      "827:\tlearn: 0.5684739\ttotal: 2m 45s\tremaining: 21.3s\n",
      "828:\tlearn: 0.5684436\ttotal: 2m 45s\tremaining: 21.1s\n",
      "829:\tlearn: 0.5684032\ttotal: 2m 45s\tremaining: 20.9s\n",
      "830:\tlearn: 0.5683758\ttotal: 2m 45s\tremaining: 20.7s\n",
      "831:\tlearn: 0.5683487\ttotal: 2m 46s\tremaining: 20.6s\n",
      "832:\tlearn: 0.5683184\ttotal: 2m 46s\tremaining: 20.4s\n",
      "833:\tlearn: 0.5682856\ttotal: 2m 46s\tremaining: 20.2s\n",
      "834:\tlearn: 0.5682656\ttotal: 2m 46s\tremaining: 19.9s\n",
      "835:\tlearn: 0.5682383\ttotal: 2m 46s\tremaining: 19.7s\n",
      "836:\tlearn: 0.5682159\ttotal: 2m 46s\tremaining: 19.5s\n",
      "837:\tlearn: 0.5681808\ttotal: 2m 47s\tremaining: 19.3s\n",
      "838:\tlearn: 0.5681551\ttotal: 2m 47s\tremaining: 19.1s\n",
      "839:\tlearn: 0.5681264\ttotal: 2m 47s\tremaining: 19s\n",
      "840:\tlearn: 0.5680947\ttotal: 2m 47s\tremaining: 18.8s\n",
      "841:\tlearn: 0.5680615\ttotal: 2m 47s\tremaining: 18.6s\n",
      "842:\tlearn: 0.5680413\ttotal: 2m 48s\tremaining: 18.4s\n",
      "843:\tlearn: 0.5680190\ttotal: 2m 48s\tremaining: 18.1s\n",
      "844:\tlearn: 0.5679997\ttotal: 2m 48s\tremaining: 17.9s\n",
      "845:\tlearn: 0.5679755\ttotal: 2m 48s\tremaining: 17.7s\n",
      "846:\tlearn: 0.5679529\ttotal: 2m 48s\tremaining: 17.5s\n",
      "847:\tlearn: 0.5679144\ttotal: 2m 49s\tremaining: 17.3s\n",
      "848:\tlearn: 0.5678816\ttotal: 2m 49s\tremaining: 17.1s\n",
      "849:\tlearn: 0.5678559\ttotal: 2m 49s\tremaining: 17s\n",
      "850:\tlearn: 0.5678277\ttotal: 2m 49s\tremaining: 16.8s\n",
      "851:\tlearn: 0.5678017\ttotal: 2m 49s\tremaining: 16.6s\n",
      "852:\tlearn: 0.5677720\ttotal: 2m 50s\tremaining: 16.4s\n",
      "853:\tlearn: 0.5677393\ttotal: 2m 50s\tremaining: 16.2s\n",
      "854:\tlearn: 0.5677147\ttotal: 2m 50s\tremaining: 16s\n",
      "855:\tlearn: 0.5676894\ttotal: 2m 50s\tremaining: 15.8s\n",
      "856:\tlearn: 0.5676579\ttotal: 2m 50s\tremaining: 15.6s\n",
      "857:\tlearn: 0.5676287\ttotal: 2m 51s\tremaining: 15.4s\n",
      "858:\tlearn: 0.5676072\ttotal: 2m 51s\tremaining: 15.2s\n",
      "859:\tlearn: 0.5675818\ttotal: 2m 51s\tremaining: 15s\n",
      "860:\tlearn: 0.5675532\ttotal: 2m 51s\tremaining: 14.8s\n",
      "861:\tlearn: 0.5675216\ttotal: 2m 51s\tremaining: 14.6s\n",
      "862:\tlearn: 0.5674902\ttotal: 2m 52s\tremaining: 14.4s\n",
      "863:\tlearn: 0.5674568\ttotal: 2m 52s\tremaining: 14.2s\n",
      "864:\tlearn: 0.5674305\ttotal: 2m 52s\tremaining: 14s\n",
      "865:\tlearn: 0.5674002\ttotal: 2m 52s\tremaining: 13.8s\n",
      "866:\tlearn: 0.5673726\ttotal: 2m 52s\tremaining: 13.6s\n",
      "867:\tlearn: 0.5673469\ttotal: 2m 53s\tremaining: 13.4s\n",
      "868:\tlearn: 0.5673246\ttotal: 2m 53s\tremaining: 13.2s\n",
      "869:\tlearn: 0.5672999\ttotal: 2m 53s\tremaining: 13s\n",
      "870:\tlearn: 0.5672731\ttotal: 2m 53s\tremaining: 12.8s\n",
      "871:\tlearn: 0.5672409\ttotal: 2m 53s\tremaining: 12.6s\n",
      "872:\tlearn: 0.5672114\ttotal: 2m 54s\tremaining: 12.4s\n",
      "873:\tlearn: 0.5671939\ttotal: 2m 54s\tremaining: 12.2s\n",
      "874:\tlearn: 0.5671641\ttotal: 2m 54s\tremaining: 12s\n",
      "875:\tlearn: 0.5671465\ttotal: 2m 54s\tremaining: 11.8s\n",
      "876:\tlearn: 0.5671194\ttotal: 2m 54s\tremaining: 11.6s\n",
      "877:\tlearn: 0.5670852\ttotal: 2m 55s\tremaining: 11.4s\n",
      "878:\tlearn: 0.5670563\ttotal: 2m 55s\tremaining: 11.2s\n",
      "879:\tlearn: 0.5670252\ttotal: 2m 55s\tremaining: 11s\n",
      "880:\tlearn: 0.5669955\ttotal: 2m 55s\tremaining: 10.8s\n",
      "881:\tlearn: 0.5669686\ttotal: 2m 55s\tremaining: 10.6s\n",
      "882:\tlearn: 0.5669449\ttotal: 2m 56s\tremaining: 10.4s\n",
      "883:\tlearn: 0.5669212\ttotal: 2m 56s\tremaining: 10.2s\n",
      "884:\tlearn: 0.5668948\ttotal: 2m 56s\tremaining: 9.97s\n",
      "885:\tlearn: 0.5668695\ttotal: 2m 56s\tremaining: 9.77s\n",
      "886:\tlearn: 0.5668512\ttotal: 2m 56s\tremaining: 9.57s\n",
      "887:\tlearn: 0.5668261\ttotal: 2m 57s\tremaining: 9.37s\n",
      "888:\tlearn: 0.5668042\ttotal: 2m 57s\tremaining: 9.17s\n",
      "889:\tlearn: 0.5667693\ttotal: 2m 57s\tremaining: 8.97s\n",
      "890:\tlearn: 0.5667419\ttotal: 2m 57s\tremaining: 8.77s\n",
      "891:\tlearn: 0.5667087\ttotal: 2m 57s\tremaining: 8.57s\n",
      "892:\tlearn: 0.5666760\ttotal: 2m 58s\tremaining: 8.37s\n",
      "893:\tlearn: 0.5666537\ttotal: 2m 58s\tremaining: 8.17s\n",
      "894:\tlearn: 0.5666347\ttotal: 2m 58s\tremaining: 7.97s\n",
      "895:\tlearn: 0.5666051\ttotal: 2m 58s\tremaining: 7.77s\n",
      "896:\tlearn: 0.5665723\ttotal: 2m 58s\tremaining: 7.57s\n",
      "897:\tlearn: 0.5665405\ttotal: 2m 58s\tremaining: 7.37s\n",
      "898:\tlearn: 0.5665174\ttotal: 2m 59s\tremaining: 7.17s\n",
      "899:\tlearn: 0.5664874\ttotal: 2m 59s\tremaining: 6.97s\n",
      "900:\tlearn: 0.5664576\ttotal: 2m 59s\tremaining: 6.78s\n",
      "901:\tlearn: 0.5664202\ttotal: 2m 59s\tremaining: 6.58s\n",
      "902:\tlearn: 0.5663949\ttotal: 2m 59s\tremaining: 6.38s\n",
      "903:\tlearn: 0.5663698\ttotal: 3m\tremaining: 6.18s\n",
      "904:\tlearn: 0.5663386\ttotal: 3m\tremaining: 5.98s\n",
      "905:\tlearn: 0.5663076\ttotal: 3m\tremaining: 5.78s\n",
      "906:\tlearn: 0.5662718\ttotal: 3m\tremaining: 5.58s\n",
      "907:\tlearn: 0.5662475\ttotal: 3m\tremaining: 5.38s\n",
      "908:\tlearn: 0.5662180\ttotal: 3m 1s\tremaining: 5.18s\n",
      "909:\tlearn: 0.5661886\ttotal: 3m 1s\tremaining: 4.98s\n",
      "910:\tlearn: 0.5661598\ttotal: 3m 1s\tremaining: 4.78s\n",
      "911:\tlearn: 0.5661396\ttotal: 3m 1s\tremaining: 4.58s\n",
      "912:\tlearn: 0.5661050\ttotal: 3m 1s\tremaining: 4.38s\n",
      "913:\tlearn: 0.5660780\ttotal: 3m 2s\tremaining: 4.18s\n",
      "914:\tlearn: 0.5660585\ttotal: 3m 2s\tremaining: 3.98s\n",
      "915:\tlearn: 0.5660340\ttotal: 3m 2s\tremaining: 3.79s\n",
      "916:\tlearn: 0.5660084\ttotal: 3m 2s\tremaining: 3.59s\n",
      "917:\tlearn: 0.5659795\ttotal: 3m 2s\tremaining: 3.39s\n",
      "918:\tlearn: 0.5659542\ttotal: 3m 3s\tremaining: 3.19s\n",
      "919:\tlearn: 0.5659305\ttotal: 3m 3s\tremaining: 2.99s\n",
      "920:\tlearn: 0.5658977\ttotal: 3m 3s\tremaining: 2.79s\n",
      "921:\tlearn: 0.5658716\ttotal: 3m 3s\tremaining: 2.59s\n",
      "922:\tlearn: 0.5658401\ttotal: 3m 3s\tremaining: 2.39s\n",
      "923:\tlearn: 0.5658018\ttotal: 3m 4s\tremaining: 2.19s\n",
      "924:\tlearn: 0.5657782\ttotal: 3m 4s\tremaining: 1.99s\n",
      "925:\tlearn: 0.5657613\ttotal: 3m 4s\tremaining: 1.79s\n",
      "926:\tlearn: 0.5657323\ttotal: 3m 4s\tremaining: 1.59s\n",
      "927:\tlearn: 0.5657033\ttotal: 3m 4s\tremaining: 1.39s\n",
      "928:\tlearn: 0.5656796\ttotal: 3m 5s\tremaining: 1.2s\n",
      "929:\tlearn: 0.5656506\ttotal: 3m 5s\tremaining: 996ms\n",
      "930:\tlearn: 0.5656185\ttotal: 3m 5s\tremaining: 797ms\n",
      "931:\tlearn: 0.5655891\ttotal: 3m 5s\tremaining: 598ms\n",
      "932:\tlearn: 0.5655555\ttotal: 3m 5s\tremaining: 399ms\n",
      "933:\tlearn: 0.5655295\ttotal: 3m 6s\tremaining: 199ms\n",
      "934:\tlearn: 0.5655102\ttotal: 3m 6s\tremaining: 0us\n",
      "[LightGBM] [Info] Number of positive: 74509, number of negative: 2025491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.746785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21992\n",
      "[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "ROC-AUC: 0.7564616310712784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['final_ensemble_model.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаю ансамлбя из трёх моделей на основе Voting Classifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "final_cat_model = CatBoostClassifier(class_weights = class_weights_dict, **{k[4:]: best_params[k] for k in best_params if 'cat_' in k})\n",
    "final_lgb_model = LGBMClassifier(class_weight = 'balanced', **{k[4:]: best_params[k] for k in best_params if 'lgb_' in k})\n",
    "final_xgb_model = XGBClassifier(scale_pos_weight = class_weights_dict[1] / class_weights_dict[0], **{k[4:]: best_params[k] for k in best_params if 'xgb_' in k})\n",
    "\n",
    "final_ensemble_model = VotingClassifier(estimators=[\n",
    "    ('catboost', final_cat_model),\n",
    "    ('lgbm', final_lgb_model),\n",
    "    ('xgb', final_xgb_model)\n",
    "], voting='soft')\n",
    "\n",
    "final_ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "final_preds = final_ensemble_model.predict_proba(X_test_scaled)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, final_preds)\n",
    "print(\"ROC-AUC:\", final_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc89308b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_ensemble_model.pkl']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(final_ensemble_model, \"final_ensemble_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "474251c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем файл с предиктами.\n",
    "predictions = final_ensemble_model.predict(X_test_scaled)\n",
    "predictions = pd.DataFrame(predictions, columns=['flag'])\n",
    "predictions.index.rename('id', inplace=True)\n",
    "predictions.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d02fe",
   "metadata": {},
   "source": [
    "Итог ансамбля: 0.7564616310712784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522182a",
   "metadata": {},
   "source": [
    "#### Нейросетевой метод с помощью PyTorch GRU RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "813a251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 16:44:39,916] A new study created in memory with name: no-name-506cbf81-61dc-4607-acbc-803ab1170483\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\2277790741.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.008, 0.042))\n",
      "[I 2024-09-23 16:48:10,205] Trial 0 finished with value: 0.7038999450795886 and parameters: {'hidden_size': 78, 'nn_learning_rate': 0.030119025598515585}. Best is trial 0 with value: 0.7038999450795886.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\2277790741.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.008, 0.042))\n",
      "[I 2024-09-23 16:53:51,030] Trial 1 finished with value: 0.7054451351221079 and parameters: {'hidden_size': 128, 'nn_learning_rate': 0.041033332276468173}. Best is trial 1 with value: 0.7054451351221079.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\2277790741.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.008, 0.042))\n",
      "[I 2024-09-23 16:57:11,624] Trial 2 finished with value: 0.6904154543203619 and parameters: {'hidden_size': 75, 'nn_learning_rate': 0.008992655736934575}. Best is trial 1 with value: 0.7054451351221079.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\2277790741.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.008, 0.042))\n",
      "[I 2024-09-23 17:02:17,373] Trial 3 finished with value: 0.7036605514667689 and parameters: {'hidden_size': 118, 'nn_learning_rate': 0.039534709588302075}. Best is trial 1 with value: 0.7054451351221079.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10904\\2277790741.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.008, 0.042))\n",
      "[I 2024-09-23 17:06:10,171] Trial 4 finished with value: 0.7013410093582938 and parameters: {'hidden_size': 89, 'nn_learning_rate': 0.02553596481939241}. Best is trial 1 with value: 0.7054451351221079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'hidden_size': 128, 'nn_learning_rate': 0.041033332276468173}\n",
      "Лучший ROC-AUC: 0.7054451351221079\n"
     ]
    }
   ],
   "source": [
    "# Реализую модель RNN с GRU слоем\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True, num_layers=2)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Подбираем гиперпараметры с помощью optuna\n",
    "def objective(trial):\n",
    "\n",
    "    input_size = X_train_scaled.shape[1]\n",
    "    hidden_size = trial.suggest_int('hidden_size', 64, 128)\n",
    "    \n",
    "    nn_model = SimpleRNN(input_size, hidden_size)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.01, 0.05))\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train_scaled.values).unsqueeze(1)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled.values).unsqueeze(1)\n",
    "    \n",
    "    nn_model.train()\n",
    "    for epoch in range(20):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = nn_model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    nn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        nn_preds = nn_model(X_test_tensor).numpy()\n",
    "    \n",
    "    auc = roc_auc_score(y_test, nn_preds.flatten())\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc2da0",
   "metadata": {},
   "source": [
    "Лучшие гиперпараметры: {'hidden_size': 94, 'nn_learning_rate': 0.020327253698045836}\n",
    "Лучший ROC-AUC: 0.7112043343992882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3079aafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7408235685764727 0.0\n"
     ]
    }
   ],
   "source": [
    "# Использую лучшие гиперпараметры и обучаю на 100 эпох.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True, num_layers=2)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "input_size = X_train_scaled.shape[1]\n",
    "hidden_size = 128\n",
    "\n",
    "nn_model = SimpleRNN(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=0.020327253698045836)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled.values).unsqueeze(1)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled.values).unsqueeze(1)\n",
    "\n",
    "nn_model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = nn_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    nn_preds = nn_model(X_test_tensor).numpy()\n",
    "\n",
    "auc = roc_auc_score(y_test, nn_preds.flatten())\n",
    "nn_preds_binary = (nn_preds.flatten() > -2.35).astype(int)\n",
    "f1 = f1_score(y_test, nn_preds_binary)\n",
    "print(auc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "031a9593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.8828955"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(nn_preds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7ebc1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_preds_binary = (nn_preds.flatten() > -2.35).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "74cada17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16432441880790072"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, nn_preds_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3f7fc4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[794981,  73086],\n",
       "       [ 22532,   9401]], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, nn_preds_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bba234da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняю лучшую модель (ячейка заполнена после проведения всех тестов с моделями)\n",
    "torch.save(nn_model.state_dict(), 'rnn_gru_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь реализован алгоритм по загрузке модели из файла.\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True, num_layers=2)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "nn_model = SimpleRNN(input_size=X_train_scaled.shape[1], hidden_size=128)\n",
    "nn_model.load_state_dict(torch.load('rnn_gru_model_weights.pth'))\n",
    "nn_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df52c3f",
   "metadata": {},
   "source": [
    "#### Нейросетевой метод с помощью PyTorch RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dafc893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-23 10:06:17,080] A new study created in memory with name: no-name-b415bc78-dc84-4019-b67f-aa0040bd443f\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\154700326.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.01116, 0.01118))\n",
      "[I 2024-09-23 10:07:49,694] Trial 0 finished with value: 0.6961709299120658 and parameters: {'hidden_size': 105, 'nn_learning_rate': 0.011178042097046028}. Best is trial 0 with value: 0.6961709299120658.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\154700326.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.01116, 0.01118))\n",
      "[I 2024-09-23 10:09:40,861] Trial 1 finished with value: 0.7028123600531386 and parameters: {'hidden_size': 119, 'nn_learning_rate': 0.011173626980773737}. Best is trial 1 with value: 0.7028123600531386.\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9764\\154700326.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.01116, 0.01118))\n",
      "[I 2024-09-23 10:11:30,000] Trial 2 finished with value: 0.6865238922652402 and parameters: {'hidden_size': 128, 'nn_learning_rate': 0.011164349767897657}. Best is trial 1 with value: 0.7028123600531386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'hidden_size': 119, 'nn_learning_rate': 0.011173626980773737}\n",
      "Лучший ROC-AUC: 0.7028123600531386\n"
     ]
    }
   ],
   "source": [
    "# Реализую простую модель RNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "def objective(trial):\n",
    "\n",
    "    input_size = X_train_scaled.shape[1]\n",
    "    hidden_size = trial.suggest_int('hidden_size', 100, 128)\n",
    "    num_layers = 3\n",
    "    \n",
    "    nn_model = SimpleRNN(input_size, hidden_size, num_layers)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(nn_model.parameters(), lr=trial.suggest_loguniform('nn_learning_rate', 0.01116, 0.01118))\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train_scaled.values).unsqueeze(1)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled.values).unsqueeze(1)\n",
    "    \n",
    "    nn_model.train()\n",
    "    for epoch in range(20):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = nn_model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    nn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        nn_preds = nn_model(X_test_tensor).numpy()\n",
    "    \n",
    "    auc = roc_auc_score(y_test, nn_preds.flatten())\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3)\n",
    "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
    "print(\"Лучший ROC-AUC:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbf2d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7358548122478354\n"
     ]
    }
   ],
   "source": [
    "# Использую лучшие гиперпараметры и обучаю на 100 эпох.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "input_size = X_train_scaled.shape[1]\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "nn_model = SimpleRNN(input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=0.01117498392633228)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled.values).unsqueeze(1)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled.values).unsqueeze(1)\n",
    "\n",
    "nn_model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = nn_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    nn_preds = nn_model(X_test_tensor).numpy()\n",
    "\n",
    "auc = roc_auc_score(y_test, nn_preds.flatten())\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e9fda",
   "metadata": {},
   "source": [
    "#### Нейросетевой метод с помощью PyTorch SimpleNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d59a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7341119871851572\n"
     ]
    }
   ],
   "source": [
    "# Опрелеяю простую нейросеть с 3-мя линейными слоями и Relu активатором c dropout слоем в конце\n",
    "# Использую гиперпараметры на основе своего опыта.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_size = X_train_scaled.shape[1]\n",
    "nn_model = SimpleNN(input_size)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=0.0407158632296223)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled.values)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled.values)\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "nn_model.train()\n",
    "for epoch in range(100): \n",
    "    optimizer.zero_grad()\n",
    "    outputs = nn_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if loss < best_train_loss:\n",
    "        best_train_loss = loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = nn_model.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch + 1}')\n",
    "        break\n",
    "\n",
    "nn_model.load_state_dict(best_model_state)\n",
    "\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    nn_preds = nn_model(X_test_tensor).numpy()\n",
    "\n",
    "auc = roc_auc_score(y_test, nn_preds.flatten())\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bf3a7",
   "metadata": {},
   "source": [
    "Лучший метод это RNN GRU с AUC: 0.7422890378103878 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40db8aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7477950390473449 1\n",
      "0.7545207456454753 2\n",
      "0.7570618447760735 3\n",
      "0.7576040956397523 4\n",
      "0.7575704787366386 5\n",
      "0.7574127691190169 6\n",
      "0.7572528356905486 7\n",
      "0.7571178125943583 8\n",
      "0.757009418482262 9\n",
      "0.7569227506457156 10\n",
      "0.7568539072786464 11\n",
      "0.7567986282414352 12\n",
      "0.7567539488137035 13\n",
      "0.7567170033371814 14\n",
      "0.7566867053754359 15\n",
      "0.7566613465580427 16\n",
      "0.7566398377068646 17\n",
      "0.756621594189519 18\n",
      "0.7566060206954067 19\n",
      "0.7565925582775863 20\n",
      "0.7565808568997745 21\n",
      "0.7565705250032968 22\n",
      "0.7565615848825387 23\n",
      "0.7565536159744796 24\n",
      "0.756546655003528 25\n",
      "0.7565403230733545 26\n",
      "0.7565348045275033 27\n",
      "0.7565297266384798 28\n",
      "0.7565251866646394 29\n",
      "0.7565210977733182 30\n",
      "0.7565174268115387 31\n",
      "0.7565140796234004 32\n",
      "0.7565110175725169 33\n",
      "0.756508153357249 34\n",
      "0.7565056274538706 35\n",
      "0.7565032690830593 36\n",
      "0.7565010674222981 37\n",
      "0.7564990971469558 38\n",
      "0.7564972105296719 39\n",
      "0.7564954804781376 40\n",
      "0.7564938662636133 41\n",
      "0.7564923528788747 42\n",
      "0.7564909626183075 43\n",
      "0.7564896655396138 44\n",
      "0.7564884022993241 45\n",
      "0.7564872769739794 46\n",
      "0.756486209513027 47\n",
      "0.7564851739424254 48\n",
      "0.7564842048220798 49\n"
     ]
    }
   ],
   "source": [
    "# Проводим объединение результатов ансамбля и нейросети, подбирая коэффициент объединения.\n",
    "for i in range(1, 50):\n",
    "    print(roc_auc_score(y_test, (preds_proba * i + nn_preds.flatten()/i)/2), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621847d",
   "metadata": {},
   "source": [
    "Итог: Объединение энсембла бустинга с RNN, GRU. + коэффициент 4. AUC_Score = 0.7576040956397523"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7286192",
   "metadata": {},
   "source": [
    "## Создание финального пайплайна (собственный класс)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "073e8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "\n",
    "class CustomPipeline:\n",
    "    def __init__(self):\n",
    "        self.preprocessor = None\n",
    "        self.final_ensemble_model = None\n",
    "        self.features_to_scale = []\n",
    "        self.value_mapping = {\n",
    "            1: 0,\n",
    "            2: 1,\n",
    "            3: 2,\n",
    "            4: 3\n",
    "        }\n",
    "        \n",
    "    def fit(self, train_data_path, train_target_path):\n",
    "        # Загрузка данных\n",
    "        df = pd.read_parquet(train_data_path)\n",
    "        train_target = pd.read_csv(train_target_path, index_col=\"id\")\n",
    "\n",
    "        # Преобразование данных\n",
    "        columns_to_transform = ['enc_paym_11', 'enc_paym_20', 'enc_paym_24']\n",
    "        for column in columns_to_transform:\n",
    "            df[column] = df[column].replace(self.value_mapping)\n",
    "\n",
    "        enc_paym_columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "        for status in range(4):\n",
    "            df[f'enc_paym_status_{status}'] = np.sum(df[enc_paym_columns].values == status, axis=1)\n",
    "        df.drop(enc_paym_columns, axis=1, inplace=True)\n",
    "\n",
    "        # Дополнительные вычисления\n",
    "        df[\"total_overdue_count\"] = df[[\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"]].sum(axis=1)\n",
    "        df.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)\n",
    "        \n",
    "        # Создание признаков\n",
    "        df[\"has_no_debt_flag\"] = df[\"is_zero_util\"] & df[\"is_zero_over2limit\"] & df[\"is_zero_maxover2limit\"]\n",
    "        df.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)\n",
    "        df[\"has_overdue_flag\"] = 1 - (df[[\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"]].all(axis=1))\n",
    "        df.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)\n",
    "        df[\"term_difference\"] = df[\"pre_pterm\"] - df[\"pre_fterm\"]\n",
    "        df[\"close_difference\"] = df[\"pre_till_pclose\"] - df[\"pre_till_fclose\"]\n",
    "        df.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)\n",
    "\n",
    "        # Обработка числовых признаков\n",
    "        columns_to_agg = ['pre_since_opened', 'pre_since_confirmed', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ', 'pre_loans_outstanding', 'pre_loans_total_overdue', 'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_util', 'pre_over2limit', 'pre_maxover2limit', 'enc_loans_account_holder_type', 'enc_loans_credit_status', 'enc_loans_credit_type', 'enc_loans_account_cur']\n",
    "        df_with_counts_max_means = self.create_count_columns(df, columns_to_agg)\n",
    "        del df\n",
    "\n",
    "        # Группировка и агрегация\n",
    "        grouped_df = df_with_counts_max_means.groupby('id').agg({\n",
    "            'has_no_debt_flag': 'median',\n",
    "            'has_overdue_flag': 'median',\n",
    "            'pclose_flag': 'median',\n",
    "            'fclose_flag': 'median',\n",
    "            **{col: 'sum' for col in df_with_counts_max_means.columns if col.endswith('_count')},\n",
    "            **{col: 'mean' for col in df_with_counts_max_means.columns if col not in ['has_no_debt_flag', 'has_overdue_flag', 'id', 'fclose_flag', 'pclose_flag']}\n",
    "        }).reset_index()\n",
    "        del df_with_counts_max_means\n",
    "        \n",
    "        # Объединение с целевой переменной\n",
    "        grouped_df = grouped_df.merge(train_target, how=\"left\", on=\"id\")\n",
    "        X = grouped_df.drop(columns=['id', 'flag'])\n",
    "        y = grouped_df['flag']\n",
    "\n",
    "        # Препроцессинг\n",
    "        self.features_to_scale = X.columns.difference(['has_no_debt_flag', 'has_overdue_flag', 'fclose_flag', 'pclose_flag'])\n",
    "        self.preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), self.features_to_scale),\n",
    "                ('passthrough', 'passthrough', ['has_no_debt_flag', 'has_overdue_flag', 'fclose_flag', 'pclose_flag'])\n",
    "            ]\n",
    "        )\n",
    "        X_scaled = self.preprocessor.fit_transform(X)\n",
    "        del X\n",
    "        \n",
    "        # Обучение моделей\n",
    "        class_weights = compute_class_weight('balanced', classes=[0, 1], y=y)\n",
    "        class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "        final_cat_model = CatBoostClassifier(class_weights=class_weights_dict, iterations=935, learning_rate=0.05312609024208735, depth=6, l2_leaf_reg=1)\n",
    "        final_lgb_model = LGBMClassifier(class_weight='balanced', n_estimators=437, learning_rate=0.04778428283852397, max_depth=10, num_leaves=81)\n",
    "        final_xgb_model = XGBClassifier(scale_pos_weight=class_weights_dict[1] / class_weights_dict[0], n_estimators=873, learning_rate=0.09607318384069156, max_depth=4, min_child_weight=3, subsample=0.6109521676209237, colsample_bytree=0.73859823191902369)\n",
    "\n",
    "        self.final_ensemble_model = VotingClassifier(estimators=[\n",
    "            ('catboost', final_cat_model),\n",
    "            ('lgbm', final_lgb_model),\n",
    "            ('xgb', final_xgb_model)\n",
    "        ], voting='soft')\n",
    "\n",
    "        self.final_ensemble_model.fit(X_scaled, y)\n",
    "        joblib.dump(self.final_ensemble_model, \"final_ensemble_model.pkl\")\n",
    "\n",
    "    def predict(self, test_data_path):\n",
    "        test_data = pd.read_parquet(test_data_path)\n",
    "        \n",
    "        # Преобразование данных\n",
    "        columns_to_transform = ['enc_paym_11', 'enc_paym_20', 'enc_paym_24']\n",
    "        for column in columns_to_transform:\n",
    "            test_data[column] = test_data[column].replace(self.value_mapping)\n",
    "\n",
    "        enc_paym_columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "        for status in range(4):\n",
    "            test_data[f'enc_paym_status_{status}'] = np.sum(test_data[enc_paym_columns].values == status, axis=1)\n",
    "        test_data.drop(enc_paym_columns, axis=1, inplace=True)\n",
    "\n",
    "        # Дополнительные вычисления\n",
    "        test_data[\"total_overdue_count\"] = test_data[[\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"]].sum(axis=1)\n",
    "        test_data.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)\n",
    "        \n",
    "        # Создание признаков\n",
    "        test_data[\"has_no_debt_flag\"] = test_data[\"is_zero_util\"] & test_data[\"is_zero_over2limit\"] & test_data[\"is_zero_maxover2limit\"]\n",
    "        test_data.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)\n",
    "        test_data[\"has_overdue_flag\"] = 1 - (test_data[[\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"]].all(axis=1))\n",
    "        test_data.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)\n",
    "        test_data[\"term_difference\"] = test_data[\"pre_pterm\"] - test_data[\"pre_fterm\"]\n",
    "        test_data[\"close_difference\"] = test_data[\"pre_till_pclose\"] - test_data[\"pre_till_fclose\"]\n",
    "        test_data.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)\n",
    "\n",
    "        # Обработка числовых признаков\n",
    "        columns_to_agg = ['pre_since_opened', 'pre_since_confirmed', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ', 'pre_loans_outstanding', 'pre_loans_total_overdue', 'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_util', 'pre_over2limit', 'pre_maxover2limit', 'enc_loans_account_holder_type', 'enc_loans_credit_status', 'enc_loans_credit_type', 'enc_loans_account_cur']\n",
    "        df_with_counts_max_means = self.create_count_columns(test_data, columns_to_agg)\n",
    "        del test_data\n",
    "\n",
    "        # Группировка и агрегация\n",
    "        grouped_df = df_with_counts_max_means.groupby('id').agg({\n",
    "            'has_no_debt_flag': 'median',\n",
    "            'has_overdue_flag': 'median',\n",
    "            'pclose_flag': 'median',\n",
    "            'fclose_flag': 'median',\n",
    "            **{col: 'sum' for col in df_with_counts_max_means.columns if col.endswith('_count')},\n",
    "            **{col: 'mean' for col in df_with_counts_max_means.columns if col not in ['has_no_debt_flag', 'has_overdue_flag', 'id', 'fclose_flag', 'pclose_flag']}\n",
    "        }).reset_index()\n",
    "        del df_with_counts_max_means\n",
    "        grouped_df.drop([\"id\"], axis=1, inplace=True)\n",
    "        test_scaled = self.preprocessor.transform(grouped_df)\n",
    "        return self.final_ensemble_model.predict(test_scaled)\n",
    "    \n",
    "    def predict_proba(self, test_data_path):\n",
    "        test_data = pd.read_parquet(test_data_path)\n",
    "        # Преобразование данных\n",
    "        columns_to_transform = ['enc_paym_11', 'enc_paym_20', 'enc_paym_24']\n",
    "        for column in columns_to_transform:\n",
    "            test_data[column] = test_data[column].replace(self.value_mapping)\n",
    "\n",
    "        enc_paym_columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "        for status in range(4):\n",
    "            test_data[f'enc_paym_status_{status}'] = np.sum(test_data[enc_paym_columns].values == status, axis=1)\n",
    "        test_data.drop(enc_paym_columns, axis=1, inplace=True)\n",
    "\n",
    "        # Дополнительные вычисления\n",
    "        test_data[\"total_overdue_count\"] = test_data[[\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"]].sum(axis=1)\n",
    "        test_data.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)\n",
    "        \n",
    "        # Создание признаков\n",
    "        test_data[\"has_no_debt_flag\"] = test_data[\"is_zero_util\"] & test_data[\"is_zero_over2limit\"] & test_data[\"is_zero_maxover2limit\"]\n",
    "        test_data.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)\n",
    "        test_data[\"has_overdue_flag\"] = 1 - (test_data[[\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"]].all(axis=1))\n",
    "        test_data.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)\n",
    "        test_data[\"term_difference\"] = test_data[\"pre_pterm\"] - test_data[\"pre_fterm\"]\n",
    "        test_data[\"close_difference\"] = test_data[\"pre_till_pclose\"] - test_data[\"pre_till_fclose\"]\n",
    "        test_data.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)\n",
    "\n",
    "        # Обработка числовых признаков\n",
    "        columns_to_agg = ['pre_since_opened', 'pre_since_confirmed', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ', 'pre_loans_outstanding', 'pre_loans_total_overdue', 'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_util', 'pre_over2limit', 'pre_maxover2limit', 'enc_loans_account_holder_type', 'enc_loans_credit_status', 'enc_loans_credit_type', 'enc_loans_account_cur']\n",
    "        df_with_counts_max_means = self.create_count_columns(test_data, columns_to_agg)\n",
    "        del test_data\n",
    "\n",
    "        # Группировка и агрегация\n",
    "        grouped_df = df_with_counts_max_means.groupby('id').agg({\n",
    "            'has_no_debt_flag': 'median',\n",
    "            'has_overdue_flag': 'median',\n",
    "            'pclose_flag': 'median',\n",
    "            'fclose_flag': 'median',\n",
    "            **{col: 'sum' for col in df_with_counts_max_means.columns if col.endswith('_count')},\n",
    "            **{col: 'mean' for col in df_with_counts_max_means.columns if col not in ['has_no_debt_flag', 'has_overdue_flag', 'id', 'fclose_flag', 'pclose_flag']}\n",
    "        }).reset_index()\n",
    "        del df_with_counts_max_means\n",
    "        grouped_df.drop([\"id\"], axis=1, inplace=True)\n",
    "        test_scaled = self.preprocessor.transform(grouped_df)\n",
    "        return self.final_ensemble_model.predict_proba(test_scaled)\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        with open(filepath, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, filepath):\n",
    "        with open(filepath, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "        \n",
    "    def create_count_columns(self, df, columns_to_count):\n",
    "        for column in columns_to_count:\n",
    "            if column in df.columns and pd.api.types.is_numeric_dtype(df[column]):\n",
    "                unique_values = df[column].unique()\n",
    "                for value in unique_values:\n",
    "                    df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "230b13de",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m CustomPipeline\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munfitted_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_target.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 37\u001b[0m, in \u001b[0;36mCustomPipeline.fit\u001b[1;34m(self, train_data_path, train_target_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m enc_paym_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menc_paym_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m)]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m---> 37\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menc_paym_status_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(df[enc_paym_columns]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m==\u001b[39m status, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     38\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(enc_paym_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Дополнительные вычисления\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3819\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   3817\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(indexer)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3819\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   3821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[0;32m   3826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   3827\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3896\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3900\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3901\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3902\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   3903\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:3884\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take\u001b[39m(\n\u001b[0;32m   3874\u001b[0m     \u001b[38;5;28mself\u001b[39m: NDFrameT,\n\u001b[0;32m   3875\u001b[0m     indices,\n\u001b[0;32m   3876\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   3877\u001b[0m     convert_indices: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3878\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3879\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3880\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` allowing specification of additional args.\u001b[39;00m\n\u001b[0;32m   3881\u001b[0m \n\u001b[0;32m   3882\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3883\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   3886\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   3887\u001b[0m         indices,\n\u001b[0;32m   3888\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   3889\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3890\u001b[0m         convert_indices\u001b[38;5;241m=\u001b[39mconvert_indices,\n\u001b[0;32m   3891\u001b[0m     )\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:5980\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[0;32m   5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n\u001b[1;32m-> 5980\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protect_consolidate(f)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:5968\u001b[0m, in \u001b[0;36mNDFrame._protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f()\n\u001b[0;32m   5967\u001b[0m blocks_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m-> 5968\u001b[0m result \u001b[38;5;241m=\u001b[39m f()\n\u001b[0;32m   5969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m!=\u001b[39m blocks_before:\n\u001b[0;32m   5970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:5978\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[1;32m-> 5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:686\u001b[0m, in \u001b[0;36mBaseBlockManager.consolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    684\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    685\u001b[0m bm\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m bm\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1871\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1873\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m _consolidate_with_refs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2329\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2327\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2329\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2330\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2391\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2388\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2389\u001b[0m     new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[1;32m-> 2391\u001b[0m     bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n\u001b[0;32m   2392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [new_block_2d(new_values, placement\u001b[38;5;241m=\u001b[39mbp)], \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2394\u001b[0m \u001b[38;5;66;03m# can't consolidate --> no merge\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = CustomPipeline()\n",
    "pipeline.fit('train_data', 'train_target.csv')\n",
    "pipeline.save_model('custom_pipeline_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d473035",
   "metadata": {},
   "source": [
    "## Пайплайн Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff246976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12608\\2490375048.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6869567\ttotal: 300ms\tremaining: 4m 40s\n",
      "1:\tlearn: 0.6812104\ttotal: 649ms\tremaining: 5m 2s\n",
      "2:\tlearn: 0.6761697\ttotal: 975ms\tremaining: 5m 2s\n",
      "3:\tlearn: 0.6716120\ttotal: 1.28s\tremaining: 4m 59s\n",
      "4:\tlearn: 0.6673141\ttotal: 1.6s\tremaining: 4m 57s\n",
      "5:\tlearn: 0.6635073\ttotal: 1.93s\tremaining: 4m 58s\n",
      "6:\tlearn: 0.6599179\ttotal: 2.22s\tremaining: 4m 54s\n",
      "7:\tlearn: 0.6567497\ttotal: 2.53s\tremaining: 4m 53s\n",
      "8:\tlearn: 0.6538219\ttotal: 2.87s\tremaining: 4m 55s\n",
      "9:\tlearn: 0.6512200\ttotal: 3.21s\tremaining: 4m 56s\n",
      "10:\tlearn: 0.6487638\ttotal: 3.53s\tremaining: 4m 56s\n",
      "11:\tlearn: 0.6464888\ttotal: 3.88s\tremaining: 4m 58s\n",
      "12:\tlearn: 0.6442096\ttotal: 4.21s\tremaining: 4m 58s\n",
      "13:\tlearn: 0.6421736\ttotal: 4.52s\tremaining: 4m 57s\n",
      "14:\tlearn: 0.6404621\ttotal: 4.86s\tremaining: 4m 58s\n",
      "15:\tlearn: 0.6387424\ttotal: 5.17s\tremaining: 4m 56s\n",
      "16:\tlearn: 0.6370087\ttotal: 5.48s\tremaining: 4m 55s\n",
      "17:\tlearn: 0.6355151\ttotal: 5.83s\tremaining: 4m 57s\n",
      "18:\tlearn: 0.6340831\ttotal: 6.15s\tremaining: 4m 56s\n",
      "19:\tlearn: 0.6328350\ttotal: 6.46s\tremaining: 4m 55s\n",
      "20:\tlearn: 0.6315033\ttotal: 6.77s\tremaining: 4m 54s\n",
      "21:\tlearn: 0.6303308\ttotal: 7.08s\tremaining: 4m 53s\n",
      "22:\tlearn: 0.6291647\ttotal: 7.41s\tremaining: 4m 54s\n",
      "23:\tlearn: 0.6280969\ttotal: 7.72s\tremaining: 4m 53s\n",
      "24:\tlearn: 0.6271250\ttotal: 8.04s\tremaining: 4m 52s\n",
      "25:\tlearn: 0.6261712\ttotal: 8.35s\tremaining: 4m 51s\n",
      "26:\tlearn: 0.6252852\ttotal: 8.67s\tremaining: 4m 51s\n",
      "27:\tlearn: 0.6243796\ttotal: 8.98s\tremaining: 4m 50s\n",
      "28:\tlearn: 0.6235701\ttotal: 9.27s\tremaining: 4m 49s\n",
      "29:\tlearn: 0.6227762\ttotal: 9.58s\tremaining: 4m 49s\n",
      "30:\tlearn: 0.6220302\ttotal: 9.91s\tremaining: 4m 48s\n",
      "31:\tlearn: 0.6213081\ttotal: 10.2s\tremaining: 4m 47s\n",
      "32:\tlearn: 0.6206549\ttotal: 10.5s\tremaining: 4m 46s\n",
      "33:\tlearn: 0.6198814\ttotal: 10.8s\tremaining: 4m 46s\n",
      "34:\tlearn: 0.6192402\ttotal: 11.1s\tremaining: 4m 45s\n",
      "35:\tlearn: 0.6186521\ttotal: 11.4s\tremaining: 4m 44s\n",
      "36:\tlearn: 0.6181186\ttotal: 11.7s\tremaining: 4m 43s\n",
      "37:\tlearn: 0.6175476\ttotal: 12s\tremaining: 4m 42s\n",
      "38:\tlearn: 0.6169987\ttotal: 12.3s\tremaining: 4m 41s\n",
      "39:\tlearn: 0.6164911\ttotal: 12.6s\tremaining: 4m 41s\n",
      "40:\tlearn: 0.6160291\ttotal: 12.9s\tremaining: 4m 40s\n",
      "41:\tlearn: 0.6155488\ttotal: 13.1s\tremaining: 4m 39s\n",
      "42:\tlearn: 0.6150538\ttotal: 13.4s\tremaining: 4m 38s\n",
      "43:\tlearn: 0.6145936\ttotal: 13.7s\tremaining: 4m 38s\n",
      "44:\tlearn: 0.6141804\ttotal: 14s\tremaining: 4m 37s\n",
      "45:\tlearn: 0.6137099\ttotal: 14.3s\tremaining: 4m 36s\n",
      "46:\tlearn: 0.6132995\ttotal: 14.6s\tremaining: 4m 36s\n",
      "47:\tlearn: 0.6129363\ttotal: 14.9s\tremaining: 4m 35s\n",
      "48:\tlearn: 0.6126044\ttotal: 15.2s\tremaining: 4m 34s\n",
      "49:\tlearn: 0.6122621\ttotal: 15.5s\tremaining: 4m 34s\n",
      "50:\tlearn: 0.6119123\ttotal: 15.8s\tremaining: 4m 33s\n",
      "51:\tlearn: 0.6115392\ttotal: 16.1s\tremaining: 4m 33s\n",
      "52:\tlearn: 0.6111943\ttotal: 16.4s\tremaining: 4m 33s\n",
      "53:\tlearn: 0.6108882\ttotal: 16.7s\tremaining: 4m 32s\n",
      "54:\tlearn: 0.6104530\ttotal: 17s\tremaining: 4m 31s\n",
      "55:\tlearn: 0.6100988\ttotal: 17.3s\tremaining: 4m 31s\n",
      "56:\tlearn: 0.6098355\ttotal: 17.6s\tremaining: 4m 30s\n",
      "57:\tlearn: 0.6094419\ttotal: 17.9s\tremaining: 4m 30s\n",
      "58:\tlearn: 0.6091676\ttotal: 18.2s\tremaining: 4m 30s\n",
      "59:\tlearn: 0.6088741\ttotal: 18.5s\tremaining: 4m 30s\n",
      "60:\tlearn: 0.6086398\ttotal: 18.8s\tremaining: 4m 29s\n",
      "61:\tlearn: 0.6083578\ttotal: 19.1s\tremaining: 4m 29s\n",
      "62:\tlearn: 0.6081071\ttotal: 19.4s\tremaining: 4m 28s\n",
      "63:\tlearn: 0.6078066\ttotal: 19.7s\tremaining: 4m 28s\n",
      "64:\tlearn: 0.6074659\ttotal: 20s\tremaining: 4m 27s\n",
      "65:\tlearn: 0.6072480\ttotal: 20.3s\tremaining: 4m 27s\n",
      "66:\tlearn: 0.6070191\ttotal: 20.6s\tremaining: 4m 26s\n",
      "67:\tlearn: 0.6068212\ttotal: 20.9s\tremaining: 4m 26s\n",
      "68:\tlearn: 0.6065975\ttotal: 21.2s\tremaining: 4m 25s\n",
      "69:\tlearn: 0.6063714\ttotal: 21.5s\tremaining: 4m 25s\n",
      "70:\tlearn: 0.6061419\ttotal: 21.8s\tremaining: 4m 24s\n",
      "71:\tlearn: 0.6058948\ttotal: 22.1s\tremaining: 4m 24s\n",
      "72:\tlearn: 0.6057073\ttotal: 22.3s\tremaining: 4m 23s\n",
      "73:\tlearn: 0.6054614\ttotal: 22.6s\tremaining: 4m 23s\n",
      "74:\tlearn: 0.6052745\ttotal: 22.9s\tremaining: 4m 23s\n",
      "75:\tlearn: 0.6050691\ttotal: 23.2s\tremaining: 4m 22s\n",
      "76:\tlearn: 0.6048498\ttotal: 23.5s\tremaining: 4m 22s\n",
      "77:\tlearn: 0.6046301\ttotal: 23.8s\tremaining: 4m 21s\n",
      "78:\tlearn: 0.6044454\ttotal: 24.1s\tremaining: 4m 21s\n",
      "79:\tlearn: 0.6042633\ttotal: 24.4s\tremaining: 4m 21s\n",
      "80:\tlearn: 0.6040679\ttotal: 24.8s\tremaining: 4m 21s\n",
      "81:\tlearn: 0.6038725\ttotal: 25.1s\tremaining: 4m 20s\n",
      "82:\tlearn: 0.6036327\ttotal: 25.4s\tremaining: 4m 20s\n",
      "83:\tlearn: 0.6034826\ttotal: 25.6s\tremaining: 4m 19s\n",
      "84:\tlearn: 0.6032479\ttotal: 26s\tremaining: 4m 19s\n",
      "85:\tlearn: 0.6030473\ttotal: 26.3s\tremaining: 4m 19s\n",
      "86:\tlearn: 0.6028606\ttotal: 26.6s\tremaining: 4m 19s\n",
      "87:\tlearn: 0.6025785\ttotal: 26.9s\tremaining: 4m 18s\n",
      "88:\tlearn: 0.6024054\ttotal: 27.2s\tremaining: 4m 18s\n",
      "89:\tlearn: 0.6022731\ttotal: 27.5s\tremaining: 4m 17s\n",
      "90:\tlearn: 0.6021365\ttotal: 27.8s\tremaining: 4m 17s\n",
      "91:\tlearn: 0.6019906\ttotal: 28.1s\tremaining: 4m 17s\n",
      "92:\tlearn: 0.6018143\ttotal: 28.4s\tremaining: 4m 16s\n",
      "93:\tlearn: 0.6016292\ttotal: 28.7s\tremaining: 4m 16s\n",
      "94:\tlearn: 0.6015014\ttotal: 29s\tremaining: 4m 16s\n",
      "95:\tlearn: 0.6013887\ttotal: 29.2s\tremaining: 4m 15s\n",
      "96:\tlearn: 0.6012856\ttotal: 29.5s\tremaining: 4m 15s\n",
      "97:\tlearn: 0.6011507\ttotal: 29.8s\tremaining: 4m 14s\n",
      "98:\tlearn: 0.6009949\ttotal: 30.1s\tremaining: 4m 14s\n",
      "99:\tlearn: 0.6008505\ttotal: 30.4s\tremaining: 4m 13s\n",
      "100:\tlearn: 0.6007171\ttotal: 30.7s\tremaining: 4m 13s\n",
      "101:\tlearn: 0.6005651\ttotal: 31s\tremaining: 4m 13s\n",
      "102:\tlearn: 0.6004143\ttotal: 31.3s\tremaining: 4m 12s\n",
      "103:\tlearn: 0.6003101\ttotal: 31.6s\tremaining: 4m 12s\n",
      "104:\tlearn: 0.6002135\ttotal: 31.9s\tremaining: 4m 12s\n",
      "105:\tlearn: 0.6000636\ttotal: 32.2s\tremaining: 4m 11s\n",
      "106:\tlearn: 0.5999752\ttotal: 32.5s\tremaining: 4m 11s\n",
      "107:\tlearn: 0.5998649\ttotal: 32.8s\tremaining: 4m 10s\n",
      "108:\tlearn: 0.5997436\ttotal: 33.1s\tremaining: 4m 10s\n",
      "109:\tlearn: 0.5996225\ttotal: 33.4s\tremaining: 4m 10s\n",
      "110:\tlearn: 0.5994915\ttotal: 33.7s\tremaining: 4m 9s\n",
      "111:\tlearn: 0.5993147\ttotal: 34s\tremaining: 4m 9s\n",
      "112:\tlearn: 0.5992249\ttotal: 34.2s\tremaining: 4m 9s\n",
      "113:\tlearn: 0.5991056\ttotal: 34.5s\tremaining: 4m 8s\n",
      "114:\tlearn: 0.5989999\ttotal: 34.8s\tremaining: 4m 8s\n",
      "115:\tlearn: 0.5989157\ttotal: 35.1s\tremaining: 4m 7s\n",
      "116:\tlearn: 0.5987946\ttotal: 35.4s\tremaining: 4m 7s\n",
      "117:\tlearn: 0.5986669\ttotal: 35.7s\tremaining: 4m 6s\n",
      "118:\tlearn: 0.5985810\ttotal: 35.9s\tremaining: 4m 6s\n",
      "119:\tlearn: 0.5984853\ttotal: 36.2s\tremaining: 4m 6s\n",
      "120:\tlearn: 0.5983914\ttotal: 36.5s\tremaining: 4m 5s\n",
      "121:\tlearn: 0.5983075\ttotal: 36.8s\tremaining: 4m 5s\n",
      "122:\tlearn: 0.5981879\ttotal: 37.1s\tremaining: 4m 5s\n",
      "123:\tlearn: 0.5981010\ttotal: 37.4s\tremaining: 4m 4s\n",
      "124:\tlearn: 0.5980343\ttotal: 37.7s\tremaining: 4m 4s\n",
      "125:\tlearn: 0.5979229\ttotal: 38s\tremaining: 4m 4s\n",
      "126:\tlearn: 0.5978505\ttotal: 38.3s\tremaining: 4m 3s\n",
      "127:\tlearn: 0.5977592\ttotal: 38.6s\tremaining: 4m 3s\n",
      "128:\tlearn: 0.5976260\ttotal: 38.9s\tremaining: 4m 2s\n",
      "129:\tlearn: 0.5975468\ttotal: 39.1s\tremaining: 4m 2s\n",
      "130:\tlearn: 0.5974701\ttotal: 39.4s\tremaining: 4m 1s\n",
      "131:\tlearn: 0.5973786\ttotal: 39.7s\tremaining: 4m 1s\n",
      "132:\tlearn: 0.5972999\ttotal: 40s\tremaining: 4m 1s\n",
      "133:\tlearn: 0.5972158\ttotal: 40.3s\tremaining: 4m\n",
      "134:\tlearn: 0.5970805\ttotal: 40.6s\tremaining: 4m\n",
      "135:\tlearn: 0.5969723\ttotal: 40.9s\tremaining: 4m\n",
      "136:\tlearn: 0.5968934\ttotal: 41.2s\tremaining: 4m\n",
      "137:\tlearn: 0.5968231\ttotal: 41.6s\tremaining: 4m\n",
      "138:\tlearn: 0.5967530\ttotal: 41.9s\tremaining: 3m 59s\n",
      "139:\tlearn: 0.5966788\ttotal: 42.2s\tremaining: 3m 59s\n",
      "140:\tlearn: 0.5965712\ttotal: 42.5s\tremaining: 3m 59s\n",
      "141:\tlearn: 0.5965095\ttotal: 42.7s\tremaining: 3m 58s\n",
      "142:\tlearn: 0.5964459\ttotal: 43s\tremaining: 3m 58s\n",
      "143:\tlearn: 0.5963874\ttotal: 43.3s\tremaining: 3m 57s\n",
      "144:\tlearn: 0.5963125\ttotal: 43.6s\tremaining: 3m 57s\n",
      "145:\tlearn: 0.5962470\ttotal: 43.9s\tremaining: 3m 57s\n",
      "146:\tlearn: 0.5961867\ttotal: 44.2s\tremaining: 3m 56s\n",
      "147:\tlearn: 0.5960918\ttotal: 44.5s\tremaining: 3m 56s\n",
      "148:\tlearn: 0.5960327\ttotal: 44.8s\tremaining: 3m 56s\n",
      "149:\tlearn: 0.5959483\ttotal: 45.1s\tremaining: 3m 56s\n",
      "150:\tlearn: 0.5958844\ttotal: 45.4s\tremaining: 3m 55s\n",
      "151:\tlearn: 0.5958300\ttotal: 45.7s\tremaining: 3m 55s\n",
      "152:\tlearn: 0.5957422\ttotal: 46s\tremaining: 3m 54s\n",
      "153:\tlearn: 0.5956774\ttotal: 46.2s\tremaining: 3m 54s\n",
      "154:\tlearn: 0.5955650\ttotal: 46.5s\tremaining: 3m 54s\n",
      "155:\tlearn: 0.5955126\ttotal: 46.8s\tremaining: 3m 53s\n",
      "156:\tlearn: 0.5954545\ttotal: 47.1s\tremaining: 3m 53s\n",
      "157:\tlearn: 0.5953676\ttotal: 47.4s\tremaining: 3m 53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.5953091\ttotal: 47.7s\tremaining: 3m 52s\n",
      "159:\tlearn: 0.5952530\ttotal: 48s\tremaining: 3m 52s\n",
      "160:\tlearn: 0.5951606\ttotal: 48.4s\tremaining: 3m 52s\n",
      "161:\tlearn: 0.5951038\ttotal: 48.6s\tremaining: 3m 52s\n",
      "162:\tlearn: 0.5950285\ttotal: 48.9s\tremaining: 3m 51s\n",
      "163:\tlearn: 0.5949856\ttotal: 49.2s\tremaining: 3m 51s\n",
      "164:\tlearn: 0.5949047\ttotal: 49.5s\tremaining: 3m 51s\n",
      "165:\tlearn: 0.5947706\ttotal: 49.8s\tremaining: 3m 50s\n",
      "166:\tlearn: 0.5947025\ttotal: 50.1s\tremaining: 3m 50s\n",
      "167:\tlearn: 0.5946201\ttotal: 50.4s\tremaining: 3m 49s\n",
      "168:\tlearn: 0.5945583\ttotal: 50.7s\tremaining: 3m 49s\n",
      "169:\tlearn: 0.5944985\ttotal: 50.9s\tremaining: 3m 49s\n",
      "170:\tlearn: 0.5944197\ttotal: 51.3s\tremaining: 3m 49s\n",
      "171:\tlearn: 0.5943501\ttotal: 51.6s\tremaining: 3m 48s\n",
      "172:\tlearn: 0.5942795\ttotal: 51.9s\tremaining: 3m 48s\n",
      "173:\tlearn: 0.5942402\ttotal: 52.1s\tremaining: 3m 48s\n",
      "174:\tlearn: 0.5941756\ttotal: 52.5s\tremaining: 3m 47s\n",
      "175:\tlearn: 0.5941169\ttotal: 52.8s\tremaining: 3m 47s\n",
      "176:\tlearn: 0.5940713\ttotal: 53.1s\tremaining: 3m 47s\n",
      "177:\tlearn: 0.5940255\ttotal: 53.3s\tremaining: 3m 46s\n",
      "178:\tlearn: 0.5939792\ttotal: 53.7s\tremaining: 3m 46s\n",
      "179:\tlearn: 0.5939201\ttotal: 54s\tremaining: 3m 46s\n",
      "180:\tlearn: 0.5938756\ttotal: 54.2s\tremaining: 3m 45s\n",
      "181:\tlearn: 0.5938160\ttotal: 54.5s\tremaining: 3m 45s\n",
      "182:\tlearn: 0.5937309\ttotal: 54.9s\tremaining: 3m 45s\n",
      "183:\tlearn: 0.5936764\ttotal: 55.2s\tremaining: 3m 45s\n",
      "184:\tlearn: 0.5936266\ttotal: 55.4s\tremaining: 3m 44s\n",
      "185:\tlearn: 0.5935802\ttotal: 55.7s\tremaining: 3m 44s\n",
      "186:\tlearn: 0.5934989\ttotal: 56s\tremaining: 3m 44s\n",
      "187:\tlearn: 0.5934697\ttotal: 56.3s\tremaining: 3m 43s\n",
      "188:\tlearn: 0.5934197\ttotal: 56.6s\tremaining: 3m 43s\n",
      "189:\tlearn: 0.5933538\ttotal: 56.9s\tremaining: 3m 43s\n",
      "190:\tlearn: 0.5932946\ttotal: 57.2s\tremaining: 3m 42s\n",
      "191:\tlearn: 0.5932560\ttotal: 57.5s\tremaining: 3m 42s\n",
      "192:\tlearn: 0.5931984\ttotal: 57.8s\tremaining: 3m 42s\n",
      "193:\tlearn: 0.5931423\ttotal: 58.2s\tremaining: 3m 42s\n",
      "194:\tlearn: 0.5930997\ttotal: 58.4s\tremaining: 3m 41s\n",
      "195:\tlearn: 0.5930579\ttotal: 58.7s\tremaining: 3m 41s\n",
      "196:\tlearn: 0.5930111\ttotal: 59s\tremaining: 3m 41s\n",
      "197:\tlearn: 0.5929689\ttotal: 59.3s\tremaining: 3m 40s\n",
      "198:\tlearn: 0.5929224\ttotal: 59.6s\tremaining: 3m 40s\n",
      "199:\tlearn: 0.5928651\ttotal: 59.9s\tremaining: 3m 40s\n",
      "200:\tlearn: 0.5928203\ttotal: 1m\tremaining: 3m 39s\n",
      "201:\tlearn: 0.5927635\ttotal: 1m\tremaining: 3m 39s\n",
      "202:\tlearn: 0.5927120\ttotal: 1m\tremaining: 3m 39s\n",
      "203:\tlearn: 0.5926698\ttotal: 1m 1s\tremaining: 3m 38s\n",
      "204:\tlearn: 0.5926190\ttotal: 1m 1s\tremaining: 3m 38s\n",
      "205:\tlearn: 0.5925564\ttotal: 1m 1s\tremaining: 3m 38s\n",
      "206:\tlearn: 0.5925032\ttotal: 1m 1s\tremaining: 3m 37s\n",
      "207:\tlearn: 0.5924662\ttotal: 1m 2s\tremaining: 3m 37s\n",
      "208:\tlearn: 0.5924139\ttotal: 1m 2s\tremaining: 3m 37s\n",
      "209:\tlearn: 0.5923841\ttotal: 1m 2s\tremaining: 3m 37s\n",
      "210:\tlearn: 0.5923426\ttotal: 1m 3s\tremaining: 3m 36s\n",
      "211:\tlearn: 0.5923030\ttotal: 1m 3s\tremaining: 3m 36s\n",
      "212:\tlearn: 0.5922582\ttotal: 1m 3s\tremaining: 3m 36s\n",
      "213:\tlearn: 0.5922165\ttotal: 1m 4s\tremaining: 3m 36s\n",
      "214:\tlearn: 0.5921730\ttotal: 1m 4s\tremaining: 3m 35s\n",
      "215:\tlearn: 0.5921431\ttotal: 1m 4s\tremaining: 3m 35s\n",
      "216:\tlearn: 0.5921135\ttotal: 1m 4s\tremaining: 3m 34s\n",
      "217:\tlearn: 0.5920808\ttotal: 1m 5s\tremaining: 3m 34s\n",
      "218:\tlearn: 0.5920345\ttotal: 1m 5s\tremaining: 3m 34s\n",
      "219:\tlearn: 0.5919867\ttotal: 1m 5s\tremaining: 3m 34s\n",
      "220:\tlearn: 0.5919539\ttotal: 1m 6s\tremaining: 3m 33s\n",
      "221:\tlearn: 0.5919189\ttotal: 1m 6s\tremaining: 3m 33s\n",
      "222:\tlearn: 0.5918775\ttotal: 1m 6s\tremaining: 3m 33s\n",
      "223:\tlearn: 0.5918285\ttotal: 1m 7s\tremaining: 3m 32s\n",
      "224:\tlearn: 0.5917646\ttotal: 1m 7s\tremaining: 3m 32s\n",
      "225:\tlearn: 0.5916865\ttotal: 1m 7s\tremaining: 3m 32s\n",
      "226:\tlearn: 0.5916518\ttotal: 1m 7s\tremaining: 3m 31s\n",
      "227:\tlearn: 0.5916048\ttotal: 1m 8s\tremaining: 3m 31s\n",
      "228:\tlearn: 0.5915554\ttotal: 1m 8s\tremaining: 3m 31s\n",
      "229:\tlearn: 0.5915276\ttotal: 1m 8s\tremaining: 3m 30s\n",
      "230:\tlearn: 0.5915011\ttotal: 1m 9s\tremaining: 3m 30s\n",
      "231:\tlearn: 0.5914688\ttotal: 1m 9s\tremaining: 3m 30s\n",
      "232:\tlearn: 0.5914271\ttotal: 1m 9s\tremaining: 3m 29s\n",
      "233:\tlearn: 0.5913666\ttotal: 1m 9s\tremaining: 3m 29s\n",
      "234:\tlearn: 0.5913311\ttotal: 1m 10s\tremaining: 3m 29s\n",
      "235:\tlearn: 0.5912978\ttotal: 1m 10s\tremaining: 3m 28s\n",
      "236:\tlearn: 0.5912362\ttotal: 1m 10s\tremaining: 3m 28s\n",
      "237:\tlearn: 0.5911902\ttotal: 1m 11s\tremaining: 3m 28s\n",
      "238:\tlearn: 0.5911524\ttotal: 1m 11s\tremaining: 3m 27s\n",
      "239:\tlearn: 0.5911064\ttotal: 1m 11s\tremaining: 3m 27s\n",
      "240:\tlearn: 0.5910578\ttotal: 1m 12s\tremaining: 3m 27s\n",
      "241:\tlearn: 0.5910163\ttotal: 1m 12s\tremaining: 3m 27s\n",
      "242:\tlearn: 0.5909861\ttotal: 1m 12s\tremaining: 3m 26s\n",
      "243:\tlearn: 0.5909132\ttotal: 1m 12s\tremaining: 3m 26s\n",
      "244:\tlearn: 0.5908632\ttotal: 1m 13s\tremaining: 3m 26s\n",
      "245:\tlearn: 0.5908244\ttotal: 1m 13s\tremaining: 3m 25s\n",
      "246:\tlearn: 0.5907775\ttotal: 1m 13s\tremaining: 3m 25s\n",
      "247:\tlearn: 0.5907062\ttotal: 1m 14s\tremaining: 3m 25s\n",
      "248:\tlearn: 0.5906763\ttotal: 1m 14s\tremaining: 3m 24s\n",
      "249:\tlearn: 0.5906407\ttotal: 1m 14s\tremaining: 3m 24s\n",
      "250:\tlearn: 0.5906030\ttotal: 1m 14s\tremaining: 3m 24s\n",
      "251:\tlearn: 0.5905181\ttotal: 1m 15s\tremaining: 3m 24s\n",
      "252:\tlearn: 0.5904819\ttotal: 1m 15s\tremaining: 3m 23s\n",
      "253:\tlearn: 0.5904457\ttotal: 1m 15s\tremaining: 3m 23s\n",
      "254:\tlearn: 0.5903844\ttotal: 1m 16s\tremaining: 3m 23s\n",
      "255:\tlearn: 0.5903489\ttotal: 1m 16s\tremaining: 3m 22s\n",
      "256:\tlearn: 0.5903265\ttotal: 1m 16s\tremaining: 3m 22s\n",
      "257:\tlearn: 0.5902899\ttotal: 1m 17s\tremaining: 3m 22s\n",
      "258:\tlearn: 0.5902557\ttotal: 1m 17s\tremaining: 3m 21s\n",
      "259:\tlearn: 0.5902161\ttotal: 1m 17s\tremaining: 3m 21s\n",
      "260:\tlearn: 0.5901786\ttotal: 1m 17s\tremaining: 3m 21s\n",
      "261:\tlearn: 0.5901322\ttotal: 1m 18s\tremaining: 3m 20s\n",
      "262:\tlearn: 0.5900937\ttotal: 1m 18s\tremaining: 3m 20s\n",
      "263:\tlearn: 0.5900690\ttotal: 1m 18s\tremaining: 3m 20s\n",
      "264:\tlearn: 0.5900349\ttotal: 1m 19s\tremaining: 3m 19s\n",
      "265:\tlearn: 0.5899920\ttotal: 1m 19s\tremaining: 3m 19s\n",
      "266:\tlearn: 0.5899494\ttotal: 1m 19s\tremaining: 3m 19s\n",
      "267:\tlearn: 0.5899057\ttotal: 1m 19s\tremaining: 3m 18s\n",
      "268:\tlearn: 0.5898595\ttotal: 1m 20s\tremaining: 3m 18s\n",
      "269:\tlearn: 0.5898044\ttotal: 1m 20s\tremaining: 3m 18s\n",
      "270:\tlearn: 0.5897644\ttotal: 1m 20s\tremaining: 3m 18s\n",
      "271:\tlearn: 0.5897256\ttotal: 1m 21s\tremaining: 3m 17s\n",
      "272:\tlearn: 0.5896877\ttotal: 1m 21s\tremaining: 3m 17s\n",
      "273:\tlearn: 0.5896472\ttotal: 1m 21s\tremaining: 3m 17s\n",
      "274:\tlearn: 0.5895984\ttotal: 1m 22s\tremaining: 3m 16s\n",
      "275:\tlearn: 0.5895496\ttotal: 1m 22s\tremaining: 3m 16s\n",
      "276:\tlearn: 0.5895036\ttotal: 1m 22s\tremaining: 3m 16s\n",
      "277:\tlearn: 0.5894541\ttotal: 1m 22s\tremaining: 3m 15s\n",
      "278:\tlearn: 0.5894216\ttotal: 1m 23s\tremaining: 3m 15s\n",
      "279:\tlearn: 0.5893782\ttotal: 1m 23s\tremaining: 3m 15s\n",
      "280:\tlearn: 0.5893462\ttotal: 1m 23s\tremaining: 3m 14s\n",
      "281:\tlearn: 0.5893125\ttotal: 1m 24s\tremaining: 3m 14s\n",
      "282:\tlearn: 0.5892712\ttotal: 1m 24s\tremaining: 3m 14s\n",
      "283:\tlearn: 0.5892179\ttotal: 1m 24s\tremaining: 3m 14s\n",
      "284:\tlearn: 0.5891672\ttotal: 1m 25s\tremaining: 3m 13s\n",
      "285:\tlearn: 0.5891044\ttotal: 1m 25s\tremaining: 3m 13s\n",
      "286:\tlearn: 0.5890635\ttotal: 1m 25s\tremaining: 3m 13s\n",
      "287:\tlearn: 0.5890208\ttotal: 1m 25s\tremaining: 3m 13s\n",
      "288:\tlearn: 0.5889775\ttotal: 1m 26s\tremaining: 3m 12s\n",
      "289:\tlearn: 0.5889427\ttotal: 1m 26s\tremaining: 3m 12s\n",
      "290:\tlearn: 0.5889021\ttotal: 1m 26s\tremaining: 3m 12s\n",
      "291:\tlearn: 0.5888544\ttotal: 1m 27s\tremaining: 3m 11s\n",
      "292:\tlearn: 0.5887974\ttotal: 1m 27s\tremaining: 3m 11s\n",
      "293:\tlearn: 0.5887616\ttotal: 1m 27s\tremaining: 3m 11s\n",
      "294:\tlearn: 0.5887088\ttotal: 1m 28s\tremaining: 3m 10s\n",
      "295:\tlearn: 0.5886612\ttotal: 1m 28s\tremaining: 3m 10s\n",
      "296:\tlearn: 0.5886097\ttotal: 1m 28s\tremaining: 3m 10s\n",
      "297:\tlearn: 0.5885717\ttotal: 1m 28s\tremaining: 3m 10s\n",
      "298:\tlearn: 0.5885262\ttotal: 1m 29s\tremaining: 3m 9s\n",
      "299:\tlearn: 0.5884794\ttotal: 1m 29s\tremaining: 3m 9s\n",
      "300:\tlearn: 0.5884383\ttotal: 1m 29s\tremaining: 3m 9s\n",
      "301:\tlearn: 0.5883947\ttotal: 1m 30s\tremaining: 3m 8s\n",
      "302:\tlearn: 0.5883578\ttotal: 1m 30s\tremaining: 3m 8s\n",
      "303:\tlearn: 0.5883067\ttotal: 1m 30s\tremaining: 3m 8s\n",
      "304:\tlearn: 0.5882684\ttotal: 1m 31s\tremaining: 3m 8s\n",
      "305:\tlearn: 0.5882222\ttotal: 1m 31s\tremaining: 3m 7s\n",
      "306:\tlearn: 0.5881752\ttotal: 1m 31s\tremaining: 3m 7s\n",
      "307:\tlearn: 0.5881170\ttotal: 1m 31s\tremaining: 3m 7s\n",
      "308:\tlearn: 0.5880550\ttotal: 1m 32s\tremaining: 3m 6s\n",
      "309:\tlearn: 0.5880184\ttotal: 1m 32s\tremaining: 3m 6s\n",
      "310:\tlearn: 0.5879838\ttotal: 1m 32s\tremaining: 3m 6s\n",
      "311:\tlearn: 0.5879459\ttotal: 1m 33s\tremaining: 3m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312:\tlearn: 0.5878893\ttotal: 1m 33s\tremaining: 3m 5s\n",
      "313:\tlearn: 0.5878420\ttotal: 1m 33s\tremaining: 3m 5s\n",
      "314:\tlearn: 0.5877953\ttotal: 1m 34s\tremaining: 3m 5s\n",
      "315:\tlearn: 0.5877440\ttotal: 1m 34s\tremaining: 3m 5s\n",
      "316:\tlearn: 0.5877057\ttotal: 1m 34s\tremaining: 3m 4s\n",
      "317:\tlearn: 0.5876644\ttotal: 1m 35s\tremaining: 3m 4s\n",
      "318:\tlearn: 0.5876280\ttotal: 1m 35s\tremaining: 3m 4s\n",
      "319:\tlearn: 0.5875819\ttotal: 1m 35s\tremaining: 3m 3s\n",
      "320:\tlearn: 0.5875407\ttotal: 1m 35s\tremaining: 3m 3s\n",
      "321:\tlearn: 0.5874986\ttotal: 1m 36s\tremaining: 3m 3s\n",
      "322:\tlearn: 0.5874652\ttotal: 1m 36s\tremaining: 3m 2s\n",
      "323:\tlearn: 0.5874204\ttotal: 1m 36s\tremaining: 3m 2s\n",
      "324:\tlearn: 0.5873625\ttotal: 1m 37s\tremaining: 3m 2s\n",
      "325:\tlearn: 0.5873238\ttotal: 1m 37s\tremaining: 3m 2s\n",
      "326:\tlearn: 0.5872858\ttotal: 1m 37s\tremaining: 3m 1s\n",
      "327:\tlearn: 0.5872523\ttotal: 1m 38s\tremaining: 3m 1s\n",
      "328:\tlearn: 0.5872129\ttotal: 1m 38s\tremaining: 3m 1s\n",
      "329:\tlearn: 0.5871549\ttotal: 1m 38s\tremaining: 3m\n",
      "330:\tlearn: 0.5871188\ttotal: 1m 38s\tremaining: 3m\n",
      "331:\tlearn: 0.5870830\ttotal: 1m 39s\tremaining: 3m\n",
      "332:\tlearn: 0.5870307\ttotal: 1m 39s\tremaining: 2m 59s\n",
      "333:\tlearn: 0.5869988\ttotal: 1m 39s\tremaining: 2m 59s\n",
      "334:\tlearn: 0.5869607\ttotal: 1m 40s\tremaining: 2m 59s\n",
      "335:\tlearn: 0.5869073\ttotal: 1m 40s\tremaining: 2m 58s\n",
      "336:\tlearn: 0.5868673\ttotal: 1m 40s\tremaining: 2m 58s\n",
      "337:\tlearn: 0.5868291\ttotal: 1m 40s\tremaining: 2m 58s\n",
      "338:\tlearn: 0.5867853\ttotal: 1m 41s\tremaining: 2m 57s\n",
      "339:\tlearn: 0.5867337\ttotal: 1m 41s\tremaining: 2m 57s\n",
      "340:\tlearn: 0.5867018\ttotal: 1m 41s\tremaining: 2m 57s\n",
      "341:\tlearn: 0.5866700\ttotal: 1m 42s\tremaining: 2m 56s\n",
      "342:\tlearn: 0.5866230\ttotal: 1m 42s\tremaining: 2m 56s\n",
      "343:\tlearn: 0.5865857\ttotal: 1m 42s\tremaining: 2m 56s\n",
      "344:\tlearn: 0.5865511\ttotal: 1m 43s\tremaining: 2m 56s\n",
      "345:\tlearn: 0.5864955\ttotal: 1m 43s\tremaining: 2m 55s\n",
      "346:\tlearn: 0.5864545\ttotal: 1m 43s\tremaining: 2m 55s\n",
      "347:\tlearn: 0.5864103\ttotal: 1m 43s\tremaining: 2m 55s\n",
      "348:\tlearn: 0.5863647\ttotal: 1m 44s\tremaining: 2m 55s\n",
      "349:\tlearn: 0.5863271\ttotal: 1m 44s\tremaining: 2m 54s\n",
      "350:\tlearn: 0.5862951\ttotal: 1m 44s\tremaining: 2m 54s\n",
      "351:\tlearn: 0.5862588\ttotal: 1m 45s\tremaining: 2m 54s\n",
      "352:\tlearn: 0.5862241\ttotal: 1m 45s\tremaining: 2m 53s\n",
      "353:\tlearn: 0.5861890\ttotal: 1m 45s\tremaining: 2m 53s\n",
      "354:\tlearn: 0.5861544\ttotal: 1m 46s\tremaining: 2m 53s\n",
      "355:\tlearn: 0.5861097\ttotal: 1m 46s\tremaining: 2m 52s\n",
      "356:\tlearn: 0.5860788\ttotal: 1m 46s\tremaining: 2m 52s\n",
      "357:\tlearn: 0.5860416\ttotal: 1m 46s\tremaining: 2m 52s\n",
      "358:\tlearn: 0.5860115\ttotal: 1m 47s\tremaining: 2m 52s\n",
      "359:\tlearn: 0.5859717\ttotal: 1m 47s\tremaining: 2m 51s\n",
      "360:\tlearn: 0.5859364\ttotal: 1m 47s\tremaining: 2m 51s\n",
      "361:\tlearn: 0.5859007\ttotal: 1m 48s\tremaining: 2m 51s\n",
      "362:\tlearn: 0.5858558\ttotal: 1m 48s\tremaining: 2m 50s\n",
      "363:\tlearn: 0.5858202\ttotal: 1m 48s\tremaining: 2m 50s\n",
      "364:\tlearn: 0.5857924\ttotal: 1m 49s\tremaining: 2m 50s\n",
      "365:\tlearn: 0.5857451\ttotal: 1m 49s\tremaining: 2m 50s\n",
      "366:\tlearn: 0.5857069\ttotal: 1m 49s\tremaining: 2m 49s\n",
      "367:\tlearn: 0.5856683\ttotal: 1m 49s\tremaining: 2m 49s\n",
      "368:\tlearn: 0.5856395\ttotal: 1m 50s\tremaining: 2m 49s\n",
      "369:\tlearn: 0.5856062\ttotal: 1m 50s\tremaining: 2m 48s\n",
      "370:\tlearn: 0.5855743\ttotal: 1m 50s\tremaining: 2m 48s\n",
      "371:\tlearn: 0.5855411\ttotal: 1m 51s\tremaining: 2m 48s\n",
      "372:\tlearn: 0.5854990\ttotal: 1m 51s\tremaining: 2m 47s\n",
      "373:\tlearn: 0.5854703\ttotal: 1m 51s\tremaining: 2m 47s\n",
      "374:\tlearn: 0.5854349\ttotal: 1m 51s\tremaining: 2m 47s\n",
      "375:\tlearn: 0.5854096\ttotal: 1m 52s\tremaining: 2m 46s\n",
      "376:\tlearn: 0.5853750\ttotal: 1m 52s\tremaining: 2m 46s\n",
      "377:\tlearn: 0.5853413\ttotal: 1m 52s\tremaining: 2m 46s\n",
      "378:\tlearn: 0.5853043\ttotal: 1m 53s\tremaining: 2m 46s\n",
      "379:\tlearn: 0.5852779\ttotal: 1m 53s\tremaining: 2m 45s\n",
      "380:\tlearn: 0.5852331\ttotal: 1m 53s\tremaining: 2m 45s\n",
      "381:\tlearn: 0.5852018\ttotal: 1m 54s\tremaining: 2m 45s\n",
      "382:\tlearn: 0.5851678\ttotal: 1m 54s\tremaining: 2m 44s\n",
      "383:\tlearn: 0.5851346\ttotal: 1m 54s\tremaining: 2m 44s\n",
      "384:\tlearn: 0.5851011\ttotal: 1m 54s\tremaining: 2m 44s\n",
      "385:\tlearn: 0.5850569\ttotal: 1m 55s\tremaining: 2m 43s\n",
      "386:\tlearn: 0.5850173\ttotal: 1m 55s\tremaining: 2m 43s\n",
      "387:\tlearn: 0.5849855\ttotal: 1m 55s\tremaining: 2m 43s\n",
      "388:\tlearn: 0.5849433\ttotal: 1m 56s\tremaining: 2m 42s\n",
      "389:\tlearn: 0.5849138\ttotal: 1m 56s\tremaining: 2m 42s\n",
      "390:\tlearn: 0.5848777\ttotal: 1m 56s\tremaining: 2m 42s\n",
      "391:\tlearn: 0.5848529\ttotal: 1m 56s\tremaining: 2m 42s\n",
      "392:\tlearn: 0.5848211\ttotal: 1m 57s\tremaining: 2m 41s\n",
      "393:\tlearn: 0.5847825\ttotal: 1m 57s\tremaining: 2m 41s\n",
      "394:\tlearn: 0.5847508\ttotal: 1m 57s\tremaining: 2m 41s\n",
      "395:\tlearn: 0.5847200\ttotal: 1m 58s\tremaining: 2m 40s\n",
      "396:\tlearn: 0.5846832\ttotal: 1m 58s\tremaining: 2m 40s\n",
      "397:\tlearn: 0.5846472\ttotal: 1m 58s\tremaining: 2m 40s\n",
      "398:\tlearn: 0.5846140\ttotal: 1m 59s\tremaining: 2m 40s\n",
      "399:\tlearn: 0.5845688\ttotal: 1m 59s\tremaining: 2m 39s\n",
      "400:\tlearn: 0.5845437\ttotal: 1m 59s\tremaining: 2m 39s\n",
      "401:\tlearn: 0.5845099\ttotal: 2m\tremaining: 2m 39s\n",
      "402:\tlearn: 0.5844741\ttotal: 2m\tremaining: 2m 38s\n",
      "403:\tlearn: 0.5844469\ttotal: 2m\tremaining: 2m 38s\n",
      "404:\tlearn: 0.5844107\ttotal: 2m\tremaining: 2m 38s\n",
      "405:\tlearn: 0.5843718\ttotal: 2m 1s\tremaining: 2m 38s\n",
      "406:\tlearn: 0.5843385\ttotal: 2m 1s\tremaining: 2m 37s\n",
      "407:\tlearn: 0.5842988\ttotal: 2m 1s\tremaining: 2m 37s\n",
      "408:\tlearn: 0.5842648\ttotal: 2m 2s\tremaining: 2m 37s\n",
      "409:\tlearn: 0.5842331\ttotal: 2m 2s\tremaining: 2m 36s\n",
      "410:\tlearn: 0.5842022\ttotal: 2m 2s\tremaining: 2m 36s\n",
      "411:\tlearn: 0.5841704\ttotal: 2m 3s\tremaining: 2m 36s\n",
      "412:\tlearn: 0.5841437\ttotal: 2m 3s\tremaining: 2m 35s\n",
      "413:\tlearn: 0.5841128\ttotal: 2m 3s\tremaining: 2m 35s\n",
      "414:\tlearn: 0.5840713\ttotal: 2m 3s\tremaining: 2m 35s\n",
      "415:\tlearn: 0.5840400\ttotal: 2m 4s\tremaining: 2m 34s\n",
      "416:\tlearn: 0.5839997\ttotal: 2m 4s\tremaining: 2m 34s\n",
      "417:\tlearn: 0.5839638\ttotal: 2m 4s\tremaining: 2m 34s\n",
      "418:\tlearn: 0.5839356\ttotal: 2m 5s\tremaining: 2m 34s\n",
      "419:\tlearn: 0.5839045\ttotal: 2m 5s\tremaining: 2m 33s\n",
      "420:\tlearn: 0.5838820\ttotal: 2m 5s\tremaining: 2m 33s\n",
      "421:\tlearn: 0.5838507\ttotal: 2m 5s\tremaining: 2m 33s\n",
      "422:\tlearn: 0.5838106\ttotal: 2m 6s\tremaining: 2m 32s\n",
      "423:\tlearn: 0.5837762\ttotal: 2m 6s\tremaining: 2m 32s\n",
      "424:\tlearn: 0.5837510\ttotal: 2m 6s\tremaining: 2m 32s\n",
      "425:\tlearn: 0.5837147\ttotal: 2m 7s\tremaining: 2m 31s\n",
      "426:\tlearn: 0.5836816\ttotal: 2m 7s\tremaining: 2m 31s\n",
      "427:\tlearn: 0.5836506\ttotal: 2m 7s\tremaining: 2m 31s\n",
      "428:\tlearn: 0.5836209\ttotal: 2m 8s\tremaining: 2m 31s\n",
      "429:\tlearn: 0.5835968\ttotal: 2m 8s\tremaining: 2m 30s\n",
      "430:\tlearn: 0.5835648\ttotal: 2m 8s\tremaining: 2m 30s\n",
      "431:\tlearn: 0.5835337\ttotal: 2m 8s\tremaining: 2m 30s\n",
      "432:\tlearn: 0.5835051\ttotal: 2m 9s\tremaining: 2m 29s\n",
      "433:\tlearn: 0.5834810\ttotal: 2m 9s\tremaining: 2m 29s\n",
      "434:\tlearn: 0.5834506\ttotal: 2m 9s\tremaining: 2m 29s\n",
      "435:\tlearn: 0.5834167\ttotal: 2m 10s\tremaining: 2m 28s\n",
      "436:\tlearn: 0.5833859\ttotal: 2m 10s\tremaining: 2m 28s\n",
      "437:\tlearn: 0.5833611\ttotal: 2m 10s\tremaining: 2m 28s\n",
      "438:\tlearn: 0.5833330\ttotal: 2m 10s\tremaining: 2m 27s\n",
      "439:\tlearn: 0.5833059\ttotal: 2m 11s\tremaining: 2m 27s\n",
      "440:\tlearn: 0.5832725\ttotal: 2m 11s\tremaining: 2m 27s\n",
      "441:\tlearn: 0.5832421\ttotal: 2m 11s\tremaining: 2m 26s\n",
      "442:\tlearn: 0.5832157\ttotal: 2m 12s\tremaining: 2m 26s\n",
      "443:\tlearn: 0.5831815\ttotal: 2m 12s\tremaining: 2m 26s\n",
      "444:\tlearn: 0.5831581\ttotal: 2m 12s\tremaining: 2m 26s\n",
      "445:\tlearn: 0.5831275\ttotal: 2m 12s\tremaining: 2m 25s\n",
      "446:\tlearn: 0.5830930\ttotal: 2m 13s\tremaining: 2m 25s\n",
      "447:\tlearn: 0.5830626\ttotal: 2m 13s\tremaining: 2m 25s\n",
      "448:\tlearn: 0.5830314\ttotal: 2m 13s\tremaining: 2m 24s\n",
      "449:\tlearn: 0.5829912\ttotal: 2m 14s\tremaining: 2m 24s\n",
      "450:\tlearn: 0.5829561\ttotal: 2m 14s\tremaining: 2m 24s\n",
      "451:\tlearn: 0.5829293\ttotal: 2m 14s\tremaining: 2m 23s\n",
      "452:\tlearn: 0.5828979\ttotal: 2m 14s\tremaining: 2m 23s\n",
      "453:\tlearn: 0.5828583\ttotal: 2m 15s\tremaining: 2m 23s\n",
      "454:\tlearn: 0.5828234\ttotal: 2m 15s\tremaining: 2m 23s\n",
      "455:\tlearn: 0.5827901\ttotal: 2m 15s\tremaining: 2m 22s\n",
      "456:\tlearn: 0.5827609\ttotal: 2m 16s\tremaining: 2m 22s\n",
      "457:\tlearn: 0.5827312\ttotal: 2m 16s\tremaining: 2m 22s\n",
      "458:\tlearn: 0.5826939\ttotal: 2m 16s\tremaining: 2m 21s\n",
      "459:\tlearn: 0.5826634\ttotal: 2m 17s\tremaining: 2m 21s\n",
      "460:\tlearn: 0.5826362\ttotal: 2m 17s\tremaining: 2m 21s\n",
      "461:\tlearn: 0.5826065\ttotal: 2m 17s\tremaining: 2m 21s\n",
      "462:\tlearn: 0.5825654\ttotal: 2m 18s\tremaining: 2m 20s\n",
      "463:\tlearn: 0.5825395\ttotal: 2m 18s\tremaining: 2m 20s\n",
      "464:\tlearn: 0.5825135\ttotal: 2m 18s\tremaining: 2m 20s\n",
      "465:\tlearn: 0.5824839\ttotal: 2m 18s\tremaining: 2m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466:\tlearn: 0.5824566\ttotal: 2m 19s\tremaining: 2m 19s\n",
      "467:\tlearn: 0.5824165\ttotal: 2m 19s\tremaining: 2m 19s\n",
      "468:\tlearn: 0.5823906\ttotal: 2m 19s\tremaining: 2m 18s\n",
      "469:\tlearn: 0.5823666\ttotal: 2m 20s\tremaining: 2m 18s\n",
      "470:\tlearn: 0.5823333\ttotal: 2m 20s\tremaining: 2m 18s\n",
      "471:\tlearn: 0.5823074\ttotal: 2m 20s\tremaining: 2m 18s\n",
      "472:\tlearn: 0.5822797\ttotal: 2m 21s\tremaining: 2m 17s\n",
      "473:\tlearn: 0.5822409\ttotal: 2m 21s\tremaining: 2m 17s\n",
      "474:\tlearn: 0.5822196\ttotal: 2m 21s\tremaining: 2m 17s\n",
      "475:\tlearn: 0.5821921\ttotal: 2m 22s\tremaining: 2m 16s\n",
      "476:\tlearn: 0.5821552\ttotal: 2m 22s\tremaining: 2m 16s\n",
      "477:\tlearn: 0.5821285\ttotal: 2m 22s\tremaining: 2m 16s\n",
      "478:\tlearn: 0.5820935\ttotal: 2m 22s\tremaining: 2m 16s\n",
      "479:\tlearn: 0.5820640\ttotal: 2m 23s\tremaining: 2m 15s\n",
      "480:\tlearn: 0.5820350\ttotal: 2m 23s\tremaining: 2m 15s\n",
      "481:\tlearn: 0.5820117\ttotal: 2m 23s\tremaining: 2m 15s\n",
      "482:\tlearn: 0.5819847\ttotal: 2m 24s\tremaining: 2m 14s\n",
      "483:\tlearn: 0.5819542\ttotal: 2m 24s\tremaining: 2m 14s\n",
      "484:\tlearn: 0.5819275\ttotal: 2m 24s\tremaining: 2m 14s\n",
      "485:\tlearn: 0.5819024\ttotal: 2m 25s\tremaining: 2m 14s\n",
      "486:\tlearn: 0.5818701\ttotal: 2m 25s\tremaining: 2m 13s\n",
      "487:\tlearn: 0.5818436\ttotal: 2m 25s\tremaining: 2m 13s\n",
      "488:\tlearn: 0.5818138\ttotal: 2m 25s\tremaining: 2m 13s\n",
      "489:\tlearn: 0.5817799\ttotal: 2m 26s\tremaining: 2m 12s\n",
      "490:\tlearn: 0.5817566\ttotal: 2m 26s\tremaining: 2m 12s\n",
      "491:\tlearn: 0.5817307\ttotal: 2m 26s\tremaining: 2m 12s\n",
      "492:\tlearn: 0.5817006\ttotal: 2m 27s\tremaining: 2m 11s\n",
      "493:\tlearn: 0.5816687\ttotal: 2m 27s\tremaining: 2m 11s\n",
      "494:\tlearn: 0.5816279\ttotal: 2m 27s\tremaining: 2m 11s\n",
      "495:\tlearn: 0.5815990\ttotal: 2m 28s\tremaining: 2m 11s\n",
      "496:\tlearn: 0.5815735\ttotal: 2m 28s\tremaining: 2m 10s\n",
      "497:\tlearn: 0.5815469\ttotal: 2m 28s\tremaining: 2m 10s\n",
      "498:\tlearn: 0.5815241\ttotal: 2m 28s\tremaining: 2m 10s\n",
      "499:\tlearn: 0.5814928\ttotal: 2m 29s\tremaining: 2m 9s\n",
      "500:\tlearn: 0.5814633\ttotal: 2m 29s\tremaining: 2m 9s\n",
      "501:\tlearn: 0.5814327\ttotal: 2m 29s\tremaining: 2m 9s\n",
      "502:\tlearn: 0.5814016\ttotal: 2m 30s\tremaining: 2m 9s\n",
      "503:\tlearn: 0.5813731\ttotal: 2m 30s\tremaining: 2m 8s\n",
      "504:\tlearn: 0.5813460\ttotal: 2m 30s\tremaining: 2m 8s\n",
      "505:\tlearn: 0.5813179\ttotal: 2m 31s\tremaining: 2m 8s\n",
      "506:\tlearn: 0.5812925\ttotal: 2m 31s\tremaining: 2m 7s\n",
      "507:\tlearn: 0.5812666\ttotal: 2m 31s\tremaining: 2m 7s\n",
      "508:\tlearn: 0.5812357\ttotal: 2m 32s\tremaining: 2m 7s\n",
      "509:\tlearn: 0.5812029\ttotal: 2m 32s\tremaining: 2m 6s\n",
      "510:\tlearn: 0.5811765\ttotal: 2m 32s\tremaining: 2m 6s\n",
      "511:\tlearn: 0.5811443\ttotal: 2m 32s\tremaining: 2m 6s\n",
      "512:\tlearn: 0.5811143\ttotal: 2m 33s\tremaining: 2m 6s\n",
      "513:\tlearn: 0.5810871\ttotal: 2m 33s\tremaining: 2m 5s\n",
      "514:\tlearn: 0.5810559\ttotal: 2m 33s\tremaining: 2m 5s\n",
      "515:\tlearn: 0.5810321\ttotal: 2m 34s\tremaining: 2m 5s\n",
      "516:\tlearn: 0.5810014\ttotal: 2m 34s\tremaining: 2m 4s\n",
      "517:\tlearn: 0.5809747\ttotal: 2m 34s\tremaining: 2m 4s\n",
      "518:\tlearn: 0.5809537\ttotal: 2m 35s\tremaining: 2m 4s\n",
      "519:\tlearn: 0.5809312\ttotal: 2m 35s\tremaining: 2m 4s\n",
      "520:\tlearn: 0.5809061\ttotal: 2m 35s\tremaining: 2m 3s\n",
      "521:\tlearn: 0.5808808\ttotal: 2m 35s\tremaining: 2m 3s\n",
      "522:\tlearn: 0.5808547\ttotal: 2m 36s\tremaining: 2m 3s\n",
      "523:\tlearn: 0.5808283\ttotal: 2m 36s\tremaining: 2m 2s\n",
      "524:\tlearn: 0.5808024\ttotal: 2m 36s\tremaining: 2m 2s\n",
      "525:\tlearn: 0.5807764\ttotal: 2m 37s\tremaining: 2m 2s\n",
      "526:\tlearn: 0.5807554\ttotal: 2m 37s\tremaining: 2m 1s\n",
      "527:\tlearn: 0.5807283\ttotal: 2m 37s\tremaining: 2m 1s\n",
      "528:\tlearn: 0.5807049\ttotal: 2m 38s\tremaining: 2m 1s\n",
      "529:\tlearn: 0.5806718\ttotal: 2m 38s\tremaining: 2m 1s\n",
      "530:\tlearn: 0.5806517\ttotal: 2m 38s\tremaining: 2m\n",
      "531:\tlearn: 0.5806227\ttotal: 2m 38s\tremaining: 2m\n",
      "532:\tlearn: 0.5805954\ttotal: 2m 39s\tremaining: 2m\n",
      "533:\tlearn: 0.5805743\ttotal: 2m 39s\tremaining: 1m 59s\n",
      "534:\tlearn: 0.5805503\ttotal: 2m 39s\tremaining: 1m 59s\n",
      "535:\tlearn: 0.5805189\ttotal: 2m 40s\tremaining: 1m 59s\n",
      "536:\tlearn: 0.5804887\ttotal: 2m 40s\tremaining: 1m 58s\n",
      "537:\tlearn: 0.5804550\ttotal: 2m 40s\tremaining: 1m 58s\n",
      "538:\tlearn: 0.5804270\ttotal: 2m 40s\tremaining: 1m 58s\n",
      "539:\tlearn: 0.5803986\ttotal: 2m 41s\tremaining: 1m 57s\n",
      "540:\tlearn: 0.5803666\ttotal: 2m 41s\tremaining: 1m 57s\n",
      "541:\tlearn: 0.5803341\ttotal: 2m 41s\tremaining: 1m 57s\n",
      "542:\tlearn: 0.5803112\ttotal: 2m 42s\tremaining: 1m 57s\n",
      "543:\tlearn: 0.5802852\ttotal: 2m 42s\tremaining: 1m 56s\n",
      "544:\tlearn: 0.5802585\ttotal: 2m 42s\tremaining: 1m 56s\n",
      "545:\tlearn: 0.5802272\ttotal: 2m 43s\tremaining: 1m 56s\n",
      "546:\tlearn: 0.5802036\ttotal: 2m 43s\tremaining: 1m 55s\n",
      "547:\tlearn: 0.5801803\ttotal: 2m 43s\tremaining: 1m 55s\n",
      "548:\tlearn: 0.5801515\ttotal: 2m 44s\tremaining: 1m 55s\n",
      "549:\tlearn: 0.5801254\ttotal: 2m 44s\tremaining: 1m 55s\n",
      "550:\tlearn: 0.5800972\ttotal: 2m 44s\tremaining: 1m 54s\n",
      "551:\tlearn: 0.5800660\ttotal: 2m 44s\tremaining: 1m 54s\n",
      "552:\tlearn: 0.5800409\ttotal: 2m 45s\tremaining: 1m 54s\n",
      "553:\tlearn: 0.5800170\ttotal: 2m 45s\tremaining: 1m 53s\n",
      "554:\tlearn: 0.5799880\ttotal: 2m 45s\tremaining: 1m 53s\n",
      "555:\tlearn: 0.5799635\ttotal: 2m 46s\tremaining: 1m 53s\n",
      "556:\tlearn: 0.5799365\ttotal: 2m 46s\tremaining: 1m 52s\n",
      "557:\tlearn: 0.5799066\ttotal: 2m 46s\tremaining: 1m 52s\n",
      "558:\tlearn: 0.5798810\ttotal: 2m 46s\tremaining: 1m 52s\n",
      "559:\tlearn: 0.5798625\ttotal: 2m 47s\tremaining: 1m 51s\n",
      "560:\tlearn: 0.5798313\ttotal: 2m 47s\tremaining: 1m 51s\n",
      "561:\tlearn: 0.5798014\ttotal: 2m 47s\tremaining: 1m 51s\n",
      "562:\tlearn: 0.5797767\ttotal: 2m 48s\tremaining: 1m 51s\n",
      "563:\tlearn: 0.5797487\ttotal: 2m 48s\tremaining: 1m 50s\n",
      "564:\tlearn: 0.5797188\ttotal: 2m 48s\tremaining: 1m 50s\n",
      "565:\tlearn: 0.5796916\ttotal: 2m 49s\tremaining: 1m 50s\n",
      "566:\tlearn: 0.5796665\ttotal: 2m 49s\tremaining: 1m 49s\n",
      "567:\tlearn: 0.5796418\ttotal: 2m 49s\tremaining: 1m 49s\n",
      "568:\tlearn: 0.5796164\ttotal: 2m 49s\tremaining: 1m 49s\n",
      "569:\tlearn: 0.5795854\ttotal: 2m 50s\tremaining: 1m 49s\n",
      "570:\tlearn: 0.5795614\ttotal: 2m 50s\tremaining: 1m 48s\n",
      "571:\tlearn: 0.5795324\ttotal: 2m 50s\tremaining: 1m 48s\n",
      "572:\tlearn: 0.5795042\ttotal: 2m 51s\tremaining: 1m 48s\n",
      "573:\tlearn: 0.5794855\ttotal: 2m 51s\tremaining: 1m 47s\n",
      "574:\tlearn: 0.5794512\ttotal: 2m 51s\tremaining: 1m 47s\n",
      "575:\tlearn: 0.5794269\ttotal: 2m 52s\tremaining: 1m 47s\n",
      "576:\tlearn: 0.5793923\ttotal: 2m 52s\tremaining: 1m 46s\n",
      "577:\tlearn: 0.5793673\ttotal: 2m 52s\tremaining: 1m 46s\n",
      "578:\tlearn: 0.5793444\ttotal: 2m 52s\tremaining: 1m 46s\n",
      "579:\tlearn: 0.5793189\ttotal: 2m 53s\tremaining: 1m 46s\n",
      "580:\tlearn: 0.5792931\ttotal: 2m 53s\tremaining: 1m 45s\n",
      "581:\tlearn: 0.5792660\ttotal: 2m 53s\tremaining: 1m 45s\n",
      "582:\tlearn: 0.5792418\ttotal: 2m 54s\tremaining: 1m 45s\n",
      "583:\tlearn: 0.5792221\ttotal: 2m 54s\tremaining: 1m 44s\n",
      "584:\tlearn: 0.5791907\ttotal: 2m 54s\tremaining: 1m 44s\n",
      "585:\tlearn: 0.5791630\ttotal: 2m 55s\tremaining: 1m 44s\n",
      "586:\tlearn: 0.5791404\ttotal: 2m 55s\tremaining: 1m 43s\n",
      "587:\tlearn: 0.5791109\ttotal: 2m 55s\tremaining: 1m 43s\n",
      "588:\tlearn: 0.5790917\ttotal: 2m 55s\tremaining: 1m 43s\n",
      "589:\tlearn: 0.5790652\ttotal: 2m 56s\tremaining: 1m 43s\n",
      "590:\tlearn: 0.5790408\ttotal: 2m 56s\tremaining: 1m 42s\n",
      "591:\tlearn: 0.5790150\ttotal: 2m 56s\tremaining: 1m 42s\n",
      "592:\tlearn: 0.5789832\ttotal: 2m 57s\tremaining: 1m 42s\n",
      "593:\tlearn: 0.5789595\ttotal: 2m 57s\tremaining: 1m 41s\n",
      "594:\tlearn: 0.5789354\ttotal: 2m 57s\tremaining: 1m 41s\n",
      "595:\tlearn: 0.5789116\ttotal: 2m 58s\tremaining: 1m 41s\n",
      "596:\tlearn: 0.5788880\ttotal: 2m 58s\tremaining: 1m 40s\n",
      "597:\tlearn: 0.5788626\ttotal: 2m 58s\tremaining: 1m 40s\n",
      "598:\tlearn: 0.5788387\ttotal: 2m 58s\tremaining: 1m 40s\n",
      "599:\tlearn: 0.5788166\ttotal: 2m 59s\tremaining: 1m 40s\n",
      "600:\tlearn: 0.5788000\ttotal: 2m 59s\tremaining: 1m 39s\n",
      "601:\tlearn: 0.5787739\ttotal: 2m 59s\tremaining: 1m 39s\n",
      "602:\tlearn: 0.5787516\ttotal: 3m\tremaining: 1m 39s\n",
      "603:\tlearn: 0.5787278\ttotal: 3m\tremaining: 1m 38s\n",
      "604:\tlearn: 0.5786999\ttotal: 3m\tremaining: 1m 38s\n",
      "605:\tlearn: 0.5786759\ttotal: 3m\tremaining: 1m 38s\n",
      "606:\tlearn: 0.5786499\ttotal: 3m 1s\tremaining: 1m 37s\n",
      "607:\tlearn: 0.5786201\ttotal: 3m 1s\tremaining: 1m 37s\n",
      "608:\tlearn: 0.5786010\ttotal: 3m 1s\tremaining: 1m 37s\n",
      "609:\tlearn: 0.5785795\ttotal: 3m 2s\tremaining: 1m 37s\n",
      "610:\tlearn: 0.5785523\ttotal: 3m 2s\tremaining: 1m 36s\n",
      "611:\tlearn: 0.5785299\ttotal: 3m 2s\tremaining: 1m 36s\n",
      "612:\tlearn: 0.5785047\ttotal: 3m 3s\tremaining: 1m 36s\n",
      "613:\tlearn: 0.5784782\ttotal: 3m 3s\tremaining: 1m 35s\n",
      "614:\tlearn: 0.5784480\ttotal: 3m 3s\tremaining: 1m 35s\n",
      "615:\tlearn: 0.5784227\ttotal: 3m 3s\tremaining: 1m 35s\n",
      "616:\tlearn: 0.5783942\ttotal: 3m 4s\tremaining: 1m 35s\n",
      "617:\tlearn: 0.5783689\ttotal: 3m 4s\tremaining: 1m 34s\n",
      "618:\tlearn: 0.5783459\ttotal: 3m 4s\tremaining: 1m 34s\n",
      "619:\tlearn: 0.5783243\ttotal: 3m 5s\tremaining: 1m 34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620:\tlearn: 0.5782964\ttotal: 3m 5s\tremaining: 1m 33s\n",
      "621:\tlearn: 0.5782735\ttotal: 3m 5s\tremaining: 1m 33s\n",
      "622:\tlearn: 0.5782467\ttotal: 3m 6s\tremaining: 1m 33s\n",
      "623:\tlearn: 0.5782222\ttotal: 3m 6s\tremaining: 1m 32s\n",
      "624:\tlearn: 0.5781968\ttotal: 3m 6s\tremaining: 1m 32s\n",
      "625:\tlearn: 0.5781721\ttotal: 3m 6s\tremaining: 1m 32s\n",
      "626:\tlearn: 0.5781518\ttotal: 3m 7s\tremaining: 1m 31s\n",
      "627:\tlearn: 0.5781288\ttotal: 3m 7s\tremaining: 1m 31s\n",
      "628:\tlearn: 0.5781013\ttotal: 3m 7s\tremaining: 1m 31s\n",
      "629:\tlearn: 0.5780765\ttotal: 3m 8s\tremaining: 1m 31s\n",
      "630:\tlearn: 0.5780549\ttotal: 3m 8s\tremaining: 1m 30s\n",
      "631:\tlearn: 0.5780307\ttotal: 3m 8s\tremaining: 1m 30s\n",
      "632:\tlearn: 0.5780065\ttotal: 3m 8s\tremaining: 1m 30s\n",
      "633:\tlearn: 0.5779829\ttotal: 3m 9s\tremaining: 1m 29s\n",
      "634:\tlearn: 0.5779568\ttotal: 3m 9s\tremaining: 1m 29s\n",
      "635:\tlearn: 0.5779280\ttotal: 3m 9s\tremaining: 1m 29s\n",
      "636:\tlearn: 0.5779061\ttotal: 3m 10s\tremaining: 1m 29s\n",
      "637:\tlearn: 0.5778859\ttotal: 3m 10s\tremaining: 1m 28s\n",
      "638:\tlearn: 0.5778587\ttotal: 3m 10s\tremaining: 1m 28s\n",
      "639:\tlearn: 0.5778301\ttotal: 3m 11s\tremaining: 1m 28s\n",
      "640:\tlearn: 0.5778068\ttotal: 3m 11s\tremaining: 1m 27s\n",
      "641:\tlearn: 0.5777835\ttotal: 3m 11s\tremaining: 1m 27s\n",
      "642:\tlearn: 0.5777597\ttotal: 3m 12s\tremaining: 1m 27s\n",
      "643:\tlearn: 0.5777381\ttotal: 3m 12s\tremaining: 1m 26s\n",
      "644:\tlearn: 0.5777122\ttotal: 3m 12s\tremaining: 1m 26s\n",
      "645:\tlearn: 0.5776909\ttotal: 3m 12s\tremaining: 1m 26s\n",
      "646:\tlearn: 0.5776691\ttotal: 3m 13s\tremaining: 1m 26s\n",
      "647:\tlearn: 0.5776438\ttotal: 3m 13s\tremaining: 1m 25s\n",
      "648:\tlearn: 0.5776243\ttotal: 3m 13s\tremaining: 1m 25s\n",
      "649:\tlearn: 0.5776033\ttotal: 3m 14s\tremaining: 1m 25s\n",
      "650:\tlearn: 0.5775807\ttotal: 3m 14s\tremaining: 1m 24s\n",
      "651:\tlearn: 0.5775498\ttotal: 3m 14s\tremaining: 1m 24s\n",
      "652:\tlearn: 0.5775254\ttotal: 3m 15s\tremaining: 1m 24s\n",
      "653:\tlearn: 0.5775040\ttotal: 3m 15s\tremaining: 1m 23s\n",
      "654:\tlearn: 0.5774753\ttotal: 3m 15s\tremaining: 1m 23s\n",
      "655:\tlearn: 0.5774507\ttotal: 3m 15s\tremaining: 1m 23s\n",
      "656:\tlearn: 0.5774275\ttotal: 3m 16s\tremaining: 1m 23s\n",
      "657:\tlearn: 0.5774044\ttotal: 3m 16s\tremaining: 1m 22s\n",
      "658:\tlearn: 0.5773782\ttotal: 3m 16s\tremaining: 1m 22s\n",
      "659:\tlearn: 0.5773514\ttotal: 3m 17s\tremaining: 1m 22s\n",
      "660:\tlearn: 0.5773306\ttotal: 3m 17s\tremaining: 1m 21s\n",
      "661:\tlearn: 0.5773050\ttotal: 3m 17s\tremaining: 1m 21s\n",
      "662:\tlearn: 0.5772803\ttotal: 3m 17s\tremaining: 1m 21s\n",
      "663:\tlearn: 0.5772557\ttotal: 3m 18s\tremaining: 1m 20s\n",
      "664:\tlearn: 0.5772310\ttotal: 3m 18s\tremaining: 1m 20s\n",
      "665:\tlearn: 0.5772096\ttotal: 3m 18s\tremaining: 1m 20s\n",
      "666:\tlearn: 0.5771787\ttotal: 3m 19s\tremaining: 1m 19s\n",
      "667:\tlearn: 0.5771549\ttotal: 3m 19s\tremaining: 1m 19s\n",
      "668:\tlearn: 0.5771332\ttotal: 3m 19s\tremaining: 1m 19s\n",
      "669:\tlearn: 0.5771099\ttotal: 3m 19s\tremaining: 1m 19s\n",
      "670:\tlearn: 0.5770850\ttotal: 3m 20s\tremaining: 1m 18s\n",
      "671:\tlearn: 0.5770666\ttotal: 3m 20s\tremaining: 1m 18s\n",
      "672:\tlearn: 0.5770358\ttotal: 3m 20s\tremaining: 1m 18s\n",
      "673:\tlearn: 0.5770069\ttotal: 3m 21s\tremaining: 1m 17s\n",
      "674:\tlearn: 0.5769754\ttotal: 3m 21s\tremaining: 1m 17s\n",
      "675:\tlearn: 0.5769563\ttotal: 3m 21s\tremaining: 1m 17s\n",
      "676:\tlearn: 0.5769338\ttotal: 3m 21s\tremaining: 1m 16s\n",
      "677:\tlearn: 0.5769092\ttotal: 3m 22s\tremaining: 1m 16s\n",
      "678:\tlearn: 0.5768830\ttotal: 3m 22s\tremaining: 1m 16s\n",
      "679:\tlearn: 0.5768609\ttotal: 3m 22s\tremaining: 1m 16s\n",
      "680:\tlearn: 0.5768362\ttotal: 3m 23s\tremaining: 1m 15s\n",
      "681:\tlearn: 0.5768154\ttotal: 3m 23s\tremaining: 1m 15s\n",
      "682:\tlearn: 0.5767924\ttotal: 3m 23s\tremaining: 1m 15s\n",
      "683:\tlearn: 0.5767683\ttotal: 3m 24s\tremaining: 1m 14s\n",
      "684:\tlearn: 0.5767483\ttotal: 3m 24s\tremaining: 1m 14s\n",
      "685:\tlearn: 0.5767208\ttotal: 3m 24s\tremaining: 1m 14s\n",
      "686:\tlearn: 0.5766984\ttotal: 3m 24s\tremaining: 1m 13s\n",
      "687:\tlearn: 0.5766704\ttotal: 3m 25s\tremaining: 1m 13s\n",
      "688:\tlearn: 0.5766428\ttotal: 3m 25s\tremaining: 1m 13s\n",
      "689:\tlearn: 0.5766188\ttotal: 3m 25s\tremaining: 1m 13s\n",
      "690:\tlearn: 0.5765969\ttotal: 3m 26s\tremaining: 1m 12s\n",
      "691:\tlearn: 0.5765722\ttotal: 3m 26s\tremaining: 1m 12s\n",
      "692:\tlearn: 0.5765490\ttotal: 3m 26s\tremaining: 1m 12s\n",
      "693:\tlearn: 0.5765246\ttotal: 3m 27s\tremaining: 1m 11s\n",
      "694:\tlearn: 0.5765014\ttotal: 3m 27s\tremaining: 1m 11s\n",
      "695:\tlearn: 0.5764842\ttotal: 3m 27s\tremaining: 1m 11s\n",
      "696:\tlearn: 0.5764654\ttotal: 3m 27s\tremaining: 1m 10s\n",
      "697:\tlearn: 0.5764462\ttotal: 3m 28s\tremaining: 1m 10s\n",
      "698:\tlearn: 0.5764184\ttotal: 3m 28s\tremaining: 1m 10s\n",
      "699:\tlearn: 0.5763984\ttotal: 3m 28s\tremaining: 1m 10s\n",
      "700:\tlearn: 0.5763721\ttotal: 3m 28s\tremaining: 1m 9s\n",
      "701:\tlearn: 0.5763491\ttotal: 3m 29s\tremaining: 1m 9s\n",
      "702:\tlearn: 0.5763276\ttotal: 3m 29s\tremaining: 1m 9s\n",
      "703:\tlearn: 0.5763092\ttotal: 3m 29s\tremaining: 1m 8s\n",
      "704:\tlearn: 0.5762846\ttotal: 3m 30s\tremaining: 1m 8s\n",
      "705:\tlearn: 0.5762615\ttotal: 3m 30s\tremaining: 1m 8s\n",
      "706:\tlearn: 0.5762392\ttotal: 3m 30s\tremaining: 1m 7s\n",
      "707:\tlearn: 0.5762194\ttotal: 3m 30s\tremaining: 1m 7s\n",
      "708:\tlearn: 0.5762008\ttotal: 3m 31s\tremaining: 1m 7s\n",
      "709:\tlearn: 0.5761791\ttotal: 3m 31s\tremaining: 1m 7s\n",
      "710:\tlearn: 0.5761575\ttotal: 3m 31s\tremaining: 1m 6s\n",
      "711:\tlearn: 0.5761279\ttotal: 3m 32s\tremaining: 1m 6s\n",
      "712:\tlearn: 0.5761017\ttotal: 3m 32s\tremaining: 1m 6s\n",
      "713:\tlearn: 0.5760771\ttotal: 3m 32s\tremaining: 1m 5s\n",
      "714:\tlearn: 0.5760591\ttotal: 3m 32s\tremaining: 1m 5s\n",
      "715:\tlearn: 0.5760311\ttotal: 3m 33s\tremaining: 1m 5s\n",
      "716:\tlearn: 0.5760084\ttotal: 3m 33s\tremaining: 1m 4s\n",
      "717:\tlearn: 0.5759824\ttotal: 3m 33s\tremaining: 1m 4s\n",
      "718:\tlearn: 0.5759573\ttotal: 3m 34s\tremaining: 1m 4s\n",
      "719:\tlearn: 0.5759348\ttotal: 3m 34s\tremaining: 1m 4s\n",
      "720:\tlearn: 0.5759089\ttotal: 3m 34s\tremaining: 1m 3s\n",
      "721:\tlearn: 0.5758847\ttotal: 3m 35s\tremaining: 1m 3s\n",
      "722:\tlearn: 0.5758584\ttotal: 3m 35s\tremaining: 1m 3s\n",
      "723:\tlearn: 0.5758344\ttotal: 3m 35s\tremaining: 1m 2s\n",
      "724:\tlearn: 0.5758106\ttotal: 3m 36s\tremaining: 1m 2s\n",
      "725:\tlearn: 0.5757899\ttotal: 3m 36s\tremaining: 1m 2s\n",
      "726:\tlearn: 0.5757670\ttotal: 3m 36s\tremaining: 1m 1s\n",
      "727:\tlearn: 0.5757447\ttotal: 3m 37s\tremaining: 1m 1s\n",
      "728:\tlearn: 0.5757223\ttotal: 3m 37s\tremaining: 1m 1s\n",
      "729:\tlearn: 0.5756961\ttotal: 3m 37s\tremaining: 1m 1s\n",
      "730:\tlearn: 0.5756740\ttotal: 3m 37s\tremaining: 1m\n",
      "731:\tlearn: 0.5756561\ttotal: 3m 38s\tremaining: 1m\n",
      "732:\tlearn: 0.5756355\ttotal: 3m 38s\tremaining: 1m\n",
      "733:\tlearn: 0.5756120\ttotal: 3m 38s\tremaining: 59.9s\n",
      "734:\tlearn: 0.5755889\ttotal: 3m 39s\tremaining: 59.6s\n",
      "735:\tlearn: 0.5755606\ttotal: 3m 39s\tremaining: 59.3s\n",
      "736:\tlearn: 0.5755363\ttotal: 3m 39s\tremaining: 59s\n",
      "737:\tlearn: 0.5755145\ttotal: 3m 39s\tremaining: 58.7s\n",
      "738:\tlearn: 0.5754922\ttotal: 3m 40s\tremaining: 58.4s\n",
      "739:\tlearn: 0.5754696\ttotal: 3m 40s\tremaining: 58.1s\n",
      "740:\tlearn: 0.5754481\ttotal: 3m 40s\tremaining: 57.8s\n",
      "741:\tlearn: 0.5754180\ttotal: 3m 41s\tremaining: 57.5s\n",
      "742:\tlearn: 0.5753980\ttotal: 3m 41s\tremaining: 57.2s\n",
      "743:\tlearn: 0.5753732\ttotal: 3m 41s\tremaining: 56.9s\n",
      "744:\tlearn: 0.5753487\ttotal: 3m 42s\tremaining: 56.6s\n",
      "745:\tlearn: 0.5753305\ttotal: 3m 42s\tremaining: 56.3s\n",
      "746:\tlearn: 0.5753101\ttotal: 3m 42s\tremaining: 56s\n",
      "747:\tlearn: 0.5752841\ttotal: 3m 42s\tremaining: 55.7s\n",
      "748:\tlearn: 0.5752652\ttotal: 3m 43s\tremaining: 55.4s\n",
      "749:\tlearn: 0.5752472\ttotal: 3m 43s\tremaining: 55.1s\n",
      "750:\tlearn: 0.5752270\ttotal: 3m 43s\tremaining: 54.8s\n",
      "751:\tlearn: 0.5752050\ttotal: 3m 44s\tremaining: 54.5s\n",
      "752:\tlearn: 0.5751807\ttotal: 3m 44s\tremaining: 54.2s\n",
      "753:\tlearn: 0.5751563\ttotal: 3m 44s\tremaining: 53.9s\n",
      "754:\tlearn: 0.5751324\ttotal: 3m 44s\tremaining: 53.6s\n",
      "755:\tlearn: 0.5751156\ttotal: 3m 45s\tremaining: 53.3s\n",
      "756:\tlearn: 0.5750911\ttotal: 3m 45s\tremaining: 53s\n",
      "757:\tlearn: 0.5750660\ttotal: 3m 45s\tremaining: 52.7s\n",
      "758:\tlearn: 0.5750435\ttotal: 3m 46s\tremaining: 52.4s\n",
      "759:\tlearn: 0.5750180\ttotal: 3m 46s\tremaining: 52.1s\n",
      "760:\tlearn: 0.5749946\ttotal: 3m 46s\tremaining: 51.8s\n",
      "761:\tlearn: 0.5749703\ttotal: 3m 46s\tremaining: 51.5s\n",
      "762:\tlearn: 0.5749497\ttotal: 3m 47s\tremaining: 51.2s\n",
      "763:\tlearn: 0.5749319\ttotal: 3m 47s\tremaining: 50.9s\n",
      "764:\tlearn: 0.5748977\ttotal: 3m 47s\tremaining: 50.6s\n",
      "765:\tlearn: 0.5748786\ttotal: 3m 48s\tremaining: 50.3s\n",
      "766:\tlearn: 0.5748603\ttotal: 3m 48s\tremaining: 50s\n",
      "767:\tlearn: 0.5748396\ttotal: 3m 48s\tremaining: 49.7s\n",
      "768:\tlearn: 0.5748107\ttotal: 3m 48s\tremaining: 49.4s\n",
      "769:\tlearn: 0.5747906\ttotal: 3m 49s\tremaining: 49.1s\n",
      "770:\tlearn: 0.5747670\ttotal: 3m 49s\tremaining: 48.8s\n",
      "771:\tlearn: 0.5747443\ttotal: 3m 49s\tremaining: 48.5s\n",
      "772:\tlearn: 0.5747258\ttotal: 3m 50s\tremaining: 48.2s\n",
      "773:\tlearn: 0.5747028\ttotal: 3m 50s\tremaining: 47.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774:\tlearn: 0.5746800\ttotal: 3m 50s\tremaining: 47.6s\n",
      "775:\tlearn: 0.5746533\ttotal: 3m 50s\tremaining: 47.3s\n",
      "776:\tlearn: 0.5746282\ttotal: 3m 51s\tremaining: 47s\n",
      "777:\tlearn: 0.5746079\ttotal: 3m 51s\tremaining: 46.7s\n",
      "778:\tlearn: 0.5745858\ttotal: 3m 51s\tremaining: 46.4s\n",
      "779:\tlearn: 0.5745630\ttotal: 3m 52s\tremaining: 46.1s\n",
      "780:\tlearn: 0.5745442\ttotal: 3m 52s\tremaining: 45.8s\n",
      "781:\tlearn: 0.5745240\ttotal: 3m 52s\tremaining: 45.5s\n",
      "782:\tlearn: 0.5745070\ttotal: 3m 52s\tremaining: 45.2s\n",
      "783:\tlearn: 0.5744849\ttotal: 3m 53s\tremaining: 44.9s\n",
      "784:\tlearn: 0.5744664\ttotal: 3m 53s\tremaining: 44.6s\n",
      "785:\tlearn: 0.5744476\ttotal: 3m 53s\tremaining: 44.3s\n",
      "786:\tlearn: 0.5744302\ttotal: 3m 54s\tremaining: 44s\n",
      "787:\tlearn: 0.5744087\ttotal: 3m 54s\tremaining: 43.7s\n",
      "788:\tlearn: 0.5743862\ttotal: 3m 54s\tremaining: 43.4s\n",
      "789:\tlearn: 0.5743622\ttotal: 3m 54s\tremaining: 43.1s\n",
      "790:\tlearn: 0.5743489\ttotal: 3m 55s\tremaining: 42.8s\n",
      "791:\tlearn: 0.5743313\ttotal: 3m 55s\tremaining: 42.5s\n",
      "792:\tlearn: 0.5743078\ttotal: 3m 55s\tremaining: 42.2s\n",
      "793:\tlearn: 0.5742828\ttotal: 3m 56s\tremaining: 41.9s\n",
      "794:\tlearn: 0.5742639\ttotal: 3m 56s\tremaining: 41.6s\n",
      "795:\tlearn: 0.5742400\ttotal: 3m 56s\tremaining: 41.3s\n",
      "796:\tlearn: 0.5742167\ttotal: 3m 56s\tremaining: 41s\n",
      "797:\tlearn: 0.5741953\ttotal: 3m 57s\tremaining: 40.7s\n",
      "798:\tlearn: 0.5741709\ttotal: 3m 57s\tremaining: 40.4s\n",
      "799:\tlearn: 0.5741519\ttotal: 3m 57s\tremaining: 40.1s\n",
      "800:\tlearn: 0.5741315\ttotal: 3m 58s\tremaining: 39.8s\n",
      "801:\tlearn: 0.5741076\ttotal: 3m 58s\tremaining: 39.5s\n",
      "802:\tlearn: 0.5740847\ttotal: 3m 58s\tremaining: 39.2s\n",
      "803:\tlearn: 0.5740628\ttotal: 3m 58s\tremaining: 38.9s\n",
      "804:\tlearn: 0.5740446\ttotal: 3m 59s\tremaining: 38.6s\n",
      "805:\tlearn: 0.5740256\ttotal: 3m 59s\tremaining: 38.3s\n",
      "806:\tlearn: 0.5740011\ttotal: 3m 59s\tremaining: 38s\n",
      "807:\tlearn: 0.5739796\ttotal: 4m\tremaining: 37.7s\n",
      "808:\tlearn: 0.5739577\ttotal: 4m\tremaining: 37.4s\n",
      "809:\tlearn: 0.5739390\ttotal: 4m\tremaining: 37.1s\n",
      "810:\tlearn: 0.5739209\ttotal: 4m\tremaining: 36.8s\n",
      "811:\tlearn: 0.5738968\ttotal: 4m 1s\tremaining: 36.5s\n",
      "812:\tlearn: 0.5738772\ttotal: 4m 1s\tremaining: 36.3s\n",
      "813:\tlearn: 0.5738609\ttotal: 4m 1s\tremaining: 35.9s\n",
      "814:\tlearn: 0.5738366\ttotal: 4m 2s\tremaining: 35.7s\n",
      "815:\tlearn: 0.5738123\ttotal: 4m 2s\tremaining: 35.4s\n",
      "816:\tlearn: 0.5737850\ttotal: 4m 2s\tremaining: 35.1s\n",
      "817:\tlearn: 0.5737614\ttotal: 4m 3s\tremaining: 34.8s\n",
      "818:\tlearn: 0.5737425\ttotal: 4m 3s\tremaining: 34.5s\n",
      "819:\tlearn: 0.5737210\ttotal: 4m 3s\tremaining: 34.2s\n",
      "820:\tlearn: 0.5736949\ttotal: 4m 3s\tremaining: 33.9s\n",
      "821:\tlearn: 0.5736766\ttotal: 4m 4s\tremaining: 33.6s\n",
      "822:\tlearn: 0.5736543\ttotal: 4m 4s\tremaining: 33.3s\n",
      "823:\tlearn: 0.5736318\ttotal: 4m 4s\tremaining: 33s\n",
      "824:\tlearn: 0.5736081\ttotal: 4m 5s\tremaining: 32.7s\n",
      "825:\tlearn: 0.5735849\ttotal: 4m 5s\tremaining: 32.4s\n",
      "826:\tlearn: 0.5735641\ttotal: 4m 5s\tremaining: 32.1s\n",
      "827:\tlearn: 0.5735435\ttotal: 4m 5s\tremaining: 31.8s\n",
      "828:\tlearn: 0.5735239\ttotal: 4m 6s\tremaining: 31.5s\n",
      "829:\tlearn: 0.5735012\ttotal: 4m 6s\tremaining: 31.2s\n",
      "830:\tlearn: 0.5734784\ttotal: 4m 6s\tremaining: 30.9s\n",
      "831:\tlearn: 0.5734561\ttotal: 4m 7s\tremaining: 30.6s\n",
      "832:\tlearn: 0.5734380\ttotal: 4m 7s\tremaining: 30.3s\n",
      "833:\tlearn: 0.5734099\ttotal: 4m 7s\tremaining: 30s\n",
      "834:\tlearn: 0.5733889\ttotal: 4m 7s\tremaining: 29.7s\n",
      "835:\tlearn: 0.5733667\ttotal: 4m 8s\tremaining: 29.4s\n",
      "836:\tlearn: 0.5733449\ttotal: 4m 8s\tremaining: 29.1s\n",
      "837:\tlearn: 0.5733201\ttotal: 4m 8s\tremaining: 28.8s\n",
      "838:\tlearn: 0.5733012\ttotal: 4m 9s\tremaining: 28.5s\n",
      "839:\tlearn: 0.5732754\ttotal: 4m 9s\tremaining: 28.2s\n",
      "840:\tlearn: 0.5732571\ttotal: 4m 9s\tremaining: 27.9s\n",
      "841:\tlearn: 0.5732346\ttotal: 4m 10s\tremaining: 27.6s\n",
      "842:\tlearn: 0.5732172\ttotal: 4m 10s\tremaining: 27.3s\n",
      "843:\tlearn: 0.5732016\ttotal: 4m 10s\tremaining: 27s\n",
      "844:\tlearn: 0.5731825\ttotal: 4m 10s\tremaining: 26.7s\n",
      "845:\tlearn: 0.5731636\ttotal: 4m 11s\tremaining: 26.4s\n",
      "846:\tlearn: 0.5731434\ttotal: 4m 11s\tremaining: 26.1s\n",
      "847:\tlearn: 0.5731213\ttotal: 4m 11s\tremaining: 25.8s\n",
      "848:\tlearn: 0.5731010\ttotal: 4m 11s\tremaining: 25.5s\n",
      "849:\tlearn: 0.5730727\ttotal: 4m 12s\tremaining: 25.2s\n",
      "850:\tlearn: 0.5730491\ttotal: 4m 12s\tremaining: 24.9s\n",
      "851:\tlearn: 0.5730215\ttotal: 4m 12s\tremaining: 24.6s\n",
      "852:\tlearn: 0.5729984\ttotal: 4m 13s\tremaining: 24.3s\n",
      "853:\tlearn: 0.5729774\ttotal: 4m 13s\tremaining: 24s\n",
      "854:\tlearn: 0.5729600\ttotal: 4m 13s\tremaining: 23.7s\n",
      "855:\tlearn: 0.5729414\ttotal: 4m 14s\tremaining: 23.4s\n",
      "856:\tlearn: 0.5729191\ttotal: 4m 14s\tremaining: 23.1s\n",
      "857:\tlearn: 0.5728982\ttotal: 4m 14s\tremaining: 22.8s\n",
      "858:\tlearn: 0.5728803\ttotal: 4m 14s\tremaining: 22.6s\n",
      "859:\tlearn: 0.5728571\ttotal: 4m 15s\tremaining: 22.3s\n",
      "860:\tlearn: 0.5728341\ttotal: 4m 15s\tremaining: 22s\n",
      "861:\tlearn: 0.5728089\ttotal: 4m 15s\tremaining: 21.7s\n",
      "862:\tlearn: 0.5727890\ttotal: 4m 16s\tremaining: 21.4s\n",
      "863:\tlearn: 0.5727698\ttotal: 4m 16s\tremaining: 21.1s\n",
      "864:\tlearn: 0.5727468\ttotal: 4m 16s\tremaining: 20.8s\n",
      "865:\tlearn: 0.5727254\ttotal: 4m 17s\tremaining: 20.5s\n",
      "866:\tlearn: 0.5726995\ttotal: 4m 17s\tremaining: 20.2s\n",
      "867:\tlearn: 0.5726768\ttotal: 4m 17s\tremaining: 19.9s\n",
      "868:\tlearn: 0.5726547\ttotal: 4m 17s\tremaining: 19.6s\n",
      "869:\tlearn: 0.5726348\ttotal: 4m 18s\tremaining: 19.3s\n",
      "870:\tlearn: 0.5726145\ttotal: 4m 18s\tremaining: 19s\n",
      "871:\tlearn: 0.5725956\ttotal: 4m 18s\tremaining: 18.7s\n",
      "872:\tlearn: 0.5725818\ttotal: 4m 19s\tremaining: 18.4s\n",
      "873:\tlearn: 0.5725582\ttotal: 4m 19s\tremaining: 18.1s\n",
      "874:\tlearn: 0.5725404\ttotal: 4m 19s\tremaining: 17.8s\n",
      "875:\tlearn: 0.5725172\ttotal: 4m 19s\tremaining: 17.5s\n",
      "876:\tlearn: 0.5724869\ttotal: 4m 20s\tremaining: 17.2s\n",
      "877:\tlearn: 0.5724649\ttotal: 4m 20s\tremaining: 16.9s\n",
      "878:\tlearn: 0.5724454\ttotal: 4m 20s\tremaining: 16.6s\n",
      "879:\tlearn: 0.5724219\ttotal: 4m 21s\tremaining: 16.3s\n",
      "880:\tlearn: 0.5724013\ttotal: 4m 21s\tremaining: 16s\n",
      "881:\tlearn: 0.5723733\ttotal: 4m 21s\tremaining: 15.7s\n",
      "882:\tlearn: 0.5723557\ttotal: 4m 22s\tremaining: 15.4s\n",
      "883:\tlearn: 0.5723311\ttotal: 4m 22s\tremaining: 15.1s\n",
      "884:\tlearn: 0.5723105\ttotal: 4m 22s\tremaining: 14.8s\n",
      "885:\tlearn: 0.5722891\ttotal: 4m 22s\tremaining: 14.5s\n",
      "886:\tlearn: 0.5722671\ttotal: 4m 23s\tremaining: 14.2s\n",
      "887:\tlearn: 0.5722483\ttotal: 4m 23s\tremaining: 14s\n",
      "888:\tlearn: 0.5722233\ttotal: 4m 23s\tremaining: 13.7s\n",
      "889:\tlearn: 0.5722063\ttotal: 4m 24s\tremaining: 13.4s\n",
      "890:\tlearn: 0.5721863\ttotal: 4m 24s\tremaining: 13.1s\n",
      "891:\tlearn: 0.5721619\ttotal: 4m 24s\tremaining: 12.8s\n",
      "892:\tlearn: 0.5721419\ttotal: 4m 25s\tremaining: 12.5s\n",
      "893:\tlearn: 0.5721230\ttotal: 4m 25s\tremaining: 12.2s\n",
      "894:\tlearn: 0.5721032\ttotal: 4m 25s\tremaining: 11.9s\n",
      "895:\tlearn: 0.5720785\ttotal: 4m 25s\tremaining: 11.6s\n",
      "896:\tlearn: 0.5720584\ttotal: 4m 26s\tremaining: 11.3s\n",
      "897:\tlearn: 0.5720405\ttotal: 4m 26s\tremaining: 11s\n",
      "898:\tlearn: 0.5720240\ttotal: 4m 26s\tremaining: 10.7s\n",
      "899:\tlearn: 0.5720083\ttotal: 4m 27s\tremaining: 10.4s\n",
      "900:\tlearn: 0.5719842\ttotal: 4m 27s\tremaining: 10.1s\n",
      "901:\tlearn: 0.5719610\ttotal: 4m 27s\tremaining: 9.79s\n",
      "902:\tlearn: 0.5719449\ttotal: 4m 27s\tremaining: 9.5s\n",
      "903:\tlearn: 0.5719271\ttotal: 4m 28s\tremaining: 9.2s\n",
      "904:\tlearn: 0.5719071\ttotal: 4m 28s\tremaining: 8.9s\n",
      "905:\tlearn: 0.5718873\ttotal: 4m 28s\tremaining: 8.61s\n",
      "906:\tlearn: 0.5718725\ttotal: 4m 29s\tremaining: 8.31s\n",
      "907:\tlearn: 0.5718537\ttotal: 4m 29s\tremaining: 8.01s\n",
      "908:\tlearn: 0.5718375\ttotal: 4m 29s\tremaining: 7.71s\n",
      "909:\tlearn: 0.5718227\ttotal: 4m 29s\tremaining: 7.42s\n",
      "910:\tlearn: 0.5718021\ttotal: 4m 30s\tremaining: 7.12s\n",
      "911:\tlearn: 0.5717760\ttotal: 4m 30s\tremaining: 6.82s\n",
      "912:\tlearn: 0.5717529\ttotal: 4m 30s\tremaining: 6.53s\n",
      "913:\tlearn: 0.5717322\ttotal: 4m 31s\tremaining: 6.23s\n",
      "914:\tlearn: 0.5717129\ttotal: 4m 31s\tremaining: 5.93s\n",
      "915:\tlearn: 0.5716909\ttotal: 4m 31s\tremaining: 5.64s\n",
      "916:\tlearn: 0.5716691\ttotal: 4m 32s\tremaining: 5.34s\n",
      "917:\tlearn: 0.5716482\ttotal: 4m 32s\tremaining: 5.04s\n",
      "918:\tlearn: 0.5716243\ttotal: 4m 32s\tremaining: 4.75s\n",
      "919:\tlearn: 0.5716022\ttotal: 4m 32s\tremaining: 4.45s\n",
      "920:\tlearn: 0.5715761\ttotal: 4m 33s\tremaining: 4.15s\n",
      "921:\tlearn: 0.5715566\ttotal: 4m 33s\tremaining: 3.86s\n",
      "922:\tlearn: 0.5715347\ttotal: 4m 33s\tremaining: 3.56s\n",
      "923:\tlearn: 0.5715125\ttotal: 4m 34s\tremaining: 3.26s\n",
      "924:\tlearn: 0.5714945\ttotal: 4m 34s\tremaining: 2.97s\n",
      "925:\tlearn: 0.5714740\ttotal: 4m 34s\tremaining: 2.67s\n",
      "926:\tlearn: 0.5714564\ttotal: 4m 35s\tremaining: 2.37s\n",
      "927:\tlearn: 0.5714341\ttotal: 4m 35s\tremaining: 2.08s\n",
      "928:\tlearn: 0.5714147\ttotal: 4m 35s\tremaining: 1.78s\n",
      "929:\tlearn: 0.5713934\ttotal: 4m 35s\tremaining: 1.48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930:\tlearn: 0.5713728\ttotal: 4m 36s\tremaining: 1.19s\n",
      "931:\tlearn: 0.5713509\ttotal: 4m 36s\tremaining: 890ms\n",
      "932:\tlearn: 0.5713278\ttotal: 4m 36s\tremaining: 594ms\n",
      "933:\tlearn: 0.5713124\ttotal: 4m 37s\tremaining: 297ms\n",
      "934:\tlearn: 0.5712925\ttotal: 4m 37s\tremaining: 0us\n",
      "[LightGBM] [Info] Number of positive: 106442, number of negative: 2893558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.931119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21993\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000000, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function preprocess_data at 0x000002310EBB9940&gt;)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  Index([&#x27;close_difference&#x27;, &#x27;enc_loans_account_cur&#x27;,\n",
       "       &#x27;enc_loans_account_cur_0_count&#x27;, &#x27;enc_loans_account_cur_1_count&#x27;,\n",
       "       &#x27;enc_loans_account_cur_2_count&#x27;, &#x27;enc_loans_account_cur_3_count&#x27;,\n",
       "       &#x27;en...\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=4,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=3,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=873,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=None, ...)),\n",
       "                                              (&#x27;lgbm&#x27;,\n",
       "                                               LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                              learning_rate=0.04778428283852397,\n",
       "                                                              max_depth=10,\n",
       "                                                              n_estimators=437,\n",
       "                                                              num_leaves=81))],\n",
       "                                  voting=&#x27;soft&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function preprocess_data at 0x000002310EBB9940&gt;)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  Index([&#x27;close_difference&#x27;, &#x27;enc_loans_account_cur&#x27;,\n",
       "       &#x27;enc_loans_account_cur_0_count&#x27;, &#x27;enc_loans_account_cur_1_count&#x27;,\n",
       "       &#x27;enc_loans_account_cur_2_count&#x27;, &#x27;enc_loans_account_cur_3_count&#x27;,\n",
       "       &#x27;en...\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=4,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=3,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=873,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=None, ...)),\n",
       "                                              (&#x27;lgbm&#x27;,\n",
       "                                               LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                              learning_rate=0.04778428283852397,\n",
       "                                                              max_depth=10,\n",
       "                                                              n_estimators=437,\n",
       "                                                              num_leaves=81))],\n",
       "                                  voting=&#x27;soft&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function preprocess_data at 0x000002310EBB9940&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;close_difference&#x27;, &#x27;enc_loans_account_cur&#x27;,\n",
       "       &#x27;enc_loans_account_cur_0_count&#x27;, &#x27;enc_loans_account_cur_1_count&#x27;,\n",
       "       &#x27;enc_loans_account_cur_2_count&#x27;, &#x27;enc_loans_account_cur_3_count&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type_0_count&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type_1_count&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type_2_count&#x27;,\n",
       "       ...\n",
       "       &#x27;pre_util_3_count&#x27;, &#x27;pre_util_4_count&#x27;, &#x27;pre_util_5_count&#x27;,\n",
       "       &#x27;pre_util_6_count&#x27;, &#x27;pre_util_7_count&#x27;, &#x27;pre_util_8_count&#x27;,\n",
       "       &#x27;pre_util_9_count&#x27;, &#x27;rn&#x27;, &#x27;term_difference&#x27;, &#x27;total_overdue_count&#x27;],\n",
       "      dtype=&#x27;object&#x27;, length=199)),\n",
       "                                (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;has_no_debt_flag&#x27;, &#x27;has_overdue_flag&#x27;,\n",
       "                                  &#x27;fclose_flag&#x27;, &#x27;pclose_flag&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;close_difference&#x27;, &#x27;enc_loans_account_cur&#x27;,\n",
       "       &#x27;enc_loans_account_cur_0_count&#x27;, &#x27;enc_loans_account_cur_1_count&#x27;,\n",
       "       &#x27;enc_loans_account_cur_2_count&#x27;, &#x27;enc_loans_account_cur_3_count&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type_0_count&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type_1_count&#x27;,\n",
       "       &#x27;enc_loans_account_holder_type_2_count&#x27;,\n",
       "       ...\n",
       "       &#x27;pre_util_3_count&#x27;, &#x27;pre_util_4_count&#x27;, &#x27;pre_util_5_count&#x27;,\n",
       "       &#x27;pre_util_6_count&#x27;, &#x27;pre_util_7_count&#x27;, &#x27;pre_util_8_count&#x27;,\n",
       "       &#x27;pre_util_9_count&#x27;, &#x27;rn&#x27;, &#x27;term_difference&#x27;, &#x27;total_overdue_count&#x27;],\n",
       "      dtype=&#x27;object&#x27;, length=199)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>[&#x27;has_no_debt_flag&#x27;, &#x27;has_overdue_flag&#x27;, &#x27;fclose_flag&#x27;, &#x27;pclose_flag&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;catboost&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x00000231103F2690&gt;),\n",
       "                             (&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.7385982319190237,\n",
       "                                            device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, g...\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=4,\n",
       "                                            max_leaves=None, min_child_weight=3,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=873, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...)),\n",
       "                             (&#x27;lgbm&#x27;,\n",
       "                              LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                             learning_rate=0.04778428283852397,\n",
       "                                             max_depth=10, n_estimators=437,\n",
       "                                             num_leaves=81))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>catboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x00000231103F2690&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7385982319190237, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.09607318384069156,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=873, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, learning_rate=0.04778428283852397,\n",
       "               max_depth=10, n_estimators=437, num_leaves=81)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 FunctionTransformer(func=<function preprocess_data at 0x000002310EBB9940>)),\n",
       "                ('scaler',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  Index(['close_difference', 'enc_loans_account_cur',\n",
       "       'enc_loans_account_cur_0_count', 'enc_loans_account_cur_1_count',\n",
       "       'enc_loans_account_cur_2_count', 'enc_loans_account_cur_3_count',\n",
       "       'en...\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=4,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=3,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=873,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=None, ...)),\n",
       "                                              ('lgbm',\n",
       "                                               LGBMClassifier(class_weight='balanced',\n",
       "                                                              learning_rate=0.04778428283852397,\n",
       "                                                              max_depth=10,\n",
       "                                                              n_estimators=437,\n",
       "                                                              num_leaves=81))],\n",
       "                                  voting='soft'))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def preprocess_data(X):\n",
    "    columns_to_transform = ['enc_paym_11', 'enc_paym_20', 'enc_paym_24']\n",
    "    for column in columns_to_transform:\n",
    "        X[column] = X[column].replace(value_mapping)\n",
    "\n",
    "    enc_paym_columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "    for status in range(4):\n",
    "        X[f'enc_paym_status_{status}'] = np.sum(X[enc_paym_columns].values == status, axis=1)\n",
    "    X.drop(enc_paym_columns, axis=1, inplace=True)\n",
    "\n",
    "    # Дополнительные вычисления\n",
    "    X[\"total_overdue_count\"] = X[[\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"]].sum(axis=1)\n",
    "    X.drop([\"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\"], axis=1, inplace=True)\n",
    "\n",
    "    # Создание признаков\n",
    "    X[\"has_no_debt_flag\"] = X[\"is_zero_util\"] & X[\"is_zero_over2limit\"] & X[\"is_zero_maxover2limit\"]\n",
    "    X.drop([\"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\"], axis=1, inplace=True)\n",
    "    X[\"has_overdue_flag\"] = 1 - (X[[\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"]].all(axis=1))\n",
    "    X.drop([\"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\"], axis=1, inplace=True)\n",
    "    X[\"term_difference\"] = X[\"pre_pterm\"] - X[\"pre_fterm\"]\n",
    "    X[\"close_difference\"] = X[\"pre_till_pclose\"] - X[\"pre_till_fclose\"]\n",
    "    X.drop([\"pre_fterm\", \"pre_pterm\", \"pre_till_fclose\", \"pre_till_pclose\"], axis=1, inplace=True)\n",
    "    def create_count_columns(df, columns_to_count):\n",
    "        for column in columns_to_count:\n",
    "            if column in df.columns and pd.api.types.is_numeric_dtype(df[column]):\n",
    "                unique_values = df[column].unique()\n",
    "                for value in unique_values:\n",
    "                    df[f'{column}_{value}_count'] = (df[column] == value).astype(int)\n",
    "        return df\n",
    "    # Обработка числовых признаков\n",
    "    columns_to_agg = ['pre_since_opened', 'pre_since_confirmed', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ', 'pre_loans_outstanding', 'pre_loans_total_overdue', 'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_util', 'pre_over2limit', 'pre_maxover2limit', 'enc_loans_account_holder_type', 'enc_loans_credit_status', 'enc_loans_credit_type', 'enc_loans_account_cur']\n",
    "    X = create_count_columns(X, columns_to_agg)\n",
    "\n",
    "    # Группировка и агрегация\n",
    "    X = X.groupby('id').agg({\n",
    "        'has_no_debt_flag': 'median',\n",
    "        'has_overdue_flag': 'median',\n",
    "        'pclose_flag': 'median',\n",
    "        'fclose_flag': 'median',\n",
    "        **{col: 'sum' for col in X.columns if col.endswith('_count')},\n",
    "        **{col: 'mean' for col in X.columns if col not in ['has_no_debt_flag', 'has_overdue_flag', 'id', 'fclose_flag', 'pclose_flag']}\n",
    "    }).reset_index()\n",
    "    X.drop([\"id\"], axis=1, inplace=True)\n",
    "    return X\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), features_to_scale),\n",
    "        ('passthrough', 'passthrough', ['has_no_debt_flag', 'has_overdue_flag', 'fclose_flag', 'pclose_flag'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocess', FunctionTransformer(preprocess_data, validate=False)),\n",
    "    ('scaler', preprocessor),\n",
    "    ('classifier', VotingClassifier(estimators=[\n",
    "        ('catboost', CatBoostClassifier(class_weights=class_weights_dict, iterations=935, learning_rate=0.05312609024208735, depth=6, l2_leaf_reg=1)),\n",
    "        ('xgb', XGBClassifier(scale_pos_weight=class_weights_dict[1] / class_weights_dict[0], n_estimators=873, learning_rate=0.09607318384069156, max_depth=4, min_child_weight=3, subsample=0.6109521676209237, colsample_bytree=0.73859823191902369)),\n",
    "        ('lgbm', LGBMClassifier(class_weight='balanced', n_estimators=437, learning_rate=0.04778428283852397, max_depth=10, num_leaves=81))\n",
    "    ], voting='soft'))\n",
    "])\n",
    "\n",
    "X = pd.read_parquet(\"train_data\")\n",
    "y = pd.read_csv(\"train_target.csv\", index_col=\"id\")\n",
    "\n",
    "pipeline.fit(X, y[\"flag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "190a41aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_pipeline.pkl']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(pipeline, 'model_pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
